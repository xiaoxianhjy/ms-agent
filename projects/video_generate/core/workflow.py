import os
import re
import json
import sys
import subprocess
import tempfile
import shutil
import time
import ast
import numpy as np
import uuid
from PIL import Image, ImageDraw, ImageFont
from typing import List, Dict, Tuple
from openai import OpenAI

# æ¸…é™¤ç»“æ„åŒ–
def clean_content(text):
    if not isinstance(text, str):
        return text
    return re.sub(r'ã€/?[^ã€‘]+ã€‘', '', text)


video_agent_dir = os.path.dirname(os.path.abspath(__file__))
if video_agent_dir not in sys.path:
    sys.path.insert(0, video_agent_dir)

# å¯¼å…¥å¢å¼ºè´¨é‡ä¿è¯ç³»ç»Ÿ
try:
    from .enhanced_quality_system import (
        VisualQualityAssessment,
        AnimationContentMatcher
    )
    QUALITY_SYSTEM_AVAILABLE = True
    print("æˆåŠŸå¯¼å…¥å¢å¼ºè´¨é‡ä¿è¯ç³»ç»Ÿ")
except ImportError as e:
    QUALITY_SYSTEM_AVAILABLE = False
    print(f"è´¨é‡ä¿è¯ç³»ç»Ÿå¯¼å…¥å¤±è´¥: {e}")

# å¯¼å…¥å¢å¼ºæç¤ºè¯ç³»ç»Ÿ
try:
    from .enhanced_manim_prompts import EnhancedManimPromptSystem
    ENHANCED_PROMPTS_AVAILABLE = True
    print("æˆåŠŸå¯¼å…¥å¢å¼ºæç¤ºè¯ç³»ç»Ÿ")
except ImportError as e:
    ENHANCED_PROMPTS_AVAILABLE = False
    print(f"å¢å¼ºæç¤ºè¯ç³»ç»Ÿå¯¼å…¥å¤±è´¥: {e}")

# å¯¼å…¥æ–°çš„è´¨é‡æ§åˆ¶ç³»ç»Ÿ
try:
    from .manim_quality_controller import ManimQualityController
    from .optimized_manim_prompts import OptimizedManimPrompts
    OPTIMIZED_QUALITY_AVAILABLE = True
    print("æˆåŠŸå¯¼å…¥ä¼˜åŒ–è´¨é‡æ§åˆ¶ç³»ç»Ÿ")
except ImportError as e:
    OPTIMIZED_QUALITY_AVAILABLE = False
    print(f"ä¼˜åŒ–è´¨é‡æ§åˆ¶ç³»ç»Ÿå¯¼å…¥å¤±è´¥: {e}")

# å¯¼å…¥èƒŒæ™¯å›¾ç”Ÿæˆå·¥å…·ç±»
try:
    from .background_image import BackgroundImageGenerator
    BACKGROUNDIMAGE_AVAILABLE = True
    print("æˆåŠŸå¯¼å…¥èƒŒæ™¯å›¾ç”Ÿæˆå™¨")
except ImportError as e:
    print(f"æ— æ³•å¯¼å…¥èƒŒæ™¯å›¾ç”Ÿæˆå™¨: {e}")
    BACKGROUNDIMAGE_AVAILABLE = False



# å¯¼å…¥å¹³è¡¡ç©ºé—´çº¦æŸç³»ç»Ÿ
try:
    from .balanced_spatial_system import BalancedSpatialSystem
    BALANCED_SPATIAL_AVAILABLE = True
    print("æˆåŠŸå¯¼å…¥å¹³è¡¡ç©ºé—´çº¦æŸç³»ç»Ÿ")
except ImportError as e:
    BALANCED_SPATIAL_AVAILABLE = False
    print(f"å¹³è¡¡ç©ºé—´çº¦æŸç³»ç»Ÿå¯¼å…¥å¤±è´¥: {e}")



# å¯¼å…¥æ–°çš„åŠ¨ç”»åˆ¶ä½œæ¨¡å¼ç³»ç»Ÿ
try:
    from .animation_production_modes import (
        AnimationProductionMode, AnimationStatus, AnimationTask,
        AnimationTaskManager, PlaceholderGenerator
    )
    # å»¶è¿Ÿå¯¼å…¥ AnimationStudio é¿å…å¾ªç¯ä¾èµ–
    HUMAN_ANIMATION_AVAILABLE = True
    print("æˆåŠŸå¯¼å…¥äººå·¥æ§åˆ¶åŠ¨ç”»åˆ¶ä½œç³»ç»Ÿ")
except ImportError as e:
    HUMAN_ANIMATION_AVAILABLE = False
    print(f"äººå·¥æ§åˆ¶åŠ¨ç”»åˆ¶ä½œç³»ç»Ÿå¯¼å…¥å¤±è´¥: {e}")


# é­”æ­æ¨¡å‹é…ç½®
MODAI_TOKEN = os.environ.get('MODELSCOPE_API_KEY')
if not os.environ.get('MODELSCOPE_API_KEY'):
    print("ä½¿ç”¨å†…ç½®APIå¯†é’¥")

OPENAI_CLIENT = OpenAI(
    base_url='https://api-inference.modelscope.cn/v1',
    api_key=MODAI_TOKEN,
)


def modai_model_request(prompt, model="Qwen/Qwen3-Coder-480B-A35B-Instruct", max_tokens=512, temperature=0.8, system_prompt=None, max_retries=3, messages=None, role="user"):
    """
    é€šç”¨æ¨¡å‹è¯·æ±‚ï¼Œè¿™é‡ŒåæœŸèƒ½æ‹“å±•æ›´å¤šçš„æ¨¡å‹çš„ï¼Œå¸¦é‡è¯•æœºåˆ¶çš„
    """
    if messages is None:
        messages = []
        if system_prompt:
            messages.append({"role": "system", "content": system_prompt})
        messages.append({"role": role, "content": prompt})

    for attempt in range(max_retries):
        try:
            response = OPENAI_CLIENT.chat.completions.create(
                model=model,
                messages=messages,
                temperature=temperature,
                max_tokens=max_tokens
            )
            
            # è·å–æ¶ˆæ¯å¯¹è±¡
            message = response.choices[0].message
            
            # æœ‰æ—¶å€™APIä¼šè¿”å›å¥‡æ€ªçš„ç¿»è¯‘é”™è¯¯ï¼Œéœ€è¦ç‰¹åˆ«å¤„ç†
            if message.content and ("The user wants me to translate" in message.content or "The user wants me to act as" in message.content):
                print(f"[API DEBUG] æ£€æµ‹åˆ°ç¿»è¯‘é”™è¯¯å“åº”ï¼Œå°è¯•ä½¿ç”¨reasoning_content")
                if hasattr(message, 'reasoning_content') and message.reasoning_content and message.reasoning_content.strip():
                    return message.reasoning_content.strip()
            
            # JSONä»»åŠ¡çš„ç‰¹æ®Šå¤„ç†ï¼Œcontentç©ºäº†ä½†reasoningé‡Œæœ‰ä¸œè¥¿
            if not message.content and hasattr(message, 'reasoning_content') and message.reasoning_content:
                if '"sentences"' in message.reasoning_content or 'JSON' in prompt:
                    print(f"[API DEBUG] JSONä»»åŠ¡æ£€æµ‹åˆ°ï¼Œä»reasoning_contentæå–ç»“æœ")
                    return message.reasoning_content.strip()
            
            # æ­£å¸¸æƒ…å†µï¼šä¼˜å…ˆæ£€æŸ¥ contentï¼Œå¦‚æœä¸ºç©ºåˆ™æ£€æŸ¥ reasoning_content
            if message.content and message.content.strip():
                return message.content.strip()
            elif hasattr(message, 'reasoning_content') and message.reasoning_content and message.reasoning_content.strip():
                return message.reasoning_content.strip()
            
            # å¦‚æœéƒ½ä¸ºç©ºï¼Œè¿”å›ç©ºå†…å®¹æç¤º
            print(f"APIè¿”å›ç©ºå†…å®¹ï¼Œç¬¬{attempt+1}æ¬¡")
            if attempt < max_retries - 1:
                time.sleep((attempt + 1) * 2)
            else:
                return None
                
        except Exception as e:
            print(f"APIè°ƒç”¨å¤±è´¥ï¼Œç¬¬{attempt+1}æ¬¡: {e}")
            if attempt < max_retries - 1:
                time.sleep((attempt + 1) * 2)
            else:
                print("APIå¤šæ¬¡å¤±è´¥ï¼Œè¿”å›é»˜è®¤å†…å®¹")
                return "APIè°ƒç”¨å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å†…å®¹"


def fix_common_manim_issues(code):
    """
    ä¿®å¤å¸¸è§çš„ Manim ä»£ç é—®é¢˜
    """
    if not code:
        return code
    
    # ä¿®å¤TRANSPARENTå¸¸é‡é—®é¢˜
    if 'TRANSPARENT' in code and 'import' not in code.split('TRANSPARENT')[0].split('\n')[-1]:
        # TRANSPARENTä¸æ˜¯ä»manimå¯¼å…¥çš„ï¼Œæ”¹æˆé€æ˜èƒŒæ™¯çš„æ­£ç¡®å†™æ³•
        code = code.replace('= TRANSPARENT', '= "#00000000"')  # é€æ˜èƒŒæ™¯çš„ RGBA è¡¨ç¤º
        code = code.replace('(TRANSPARENT)', '("#00000000")')
        code = code.replace(' TRANSPARENT ', ' "#00000000" ')
    
    return code


def clean_llm_code_output(code):
    """
    æ¸…ç†LLMè¾“å‡ºä¸­çš„Markdownæ ¼å¼æ ‡è®°å’Œå¤šä½™å†…å®¹ï¼Œæ™ºèƒ½æå–çº¯Pythonä»£ç 
    """
    if not code:
        return code
    
    # é¦–å…ˆå°è¯•ä»markdownä»£ç å—ä¸­æå–ä»£ç 
    code = extract_python_code_from_markdown(code)
    
    # ä¿®å¤å¸¸è§çš„ Manim é”™è¯¯
    code = fix_common_manim_issues(code)
    
    # ç§»é™¤é¦–å°¾ç©ºç™½å­—ç¬¦
    code = code.strip()
    
    # å†æ¬¡æ¸…ç†å¯èƒ½æ®‹ç•™çš„markdownæ ‡è®°
    if code.startswith('```python'):
        code = code[9:].strip()
    elif code.startswith('```'):
        code = code[3:].strip()
    
    if code.endswith('```'):
        code = code[:-3].strip()
    
    # æŒ‰è¡Œå¤„ç†ï¼Œç§»é™¤éPythonä»£ç è¡Œ
    lines = code.split('\n')
    cleaned_lines = []
    in_python_code = False
    
    for line in lines:
        stripped_line = line.strip()
        
        # ç©ºè¡Œå¤„ç†ï¼šä»£ç å—é‡Œçš„è¦ä¿ç•™ï¼Œå¤–é¢çš„è·³è¿‡
        if not stripped_line:
            if in_python_code:
                cleaned_lines.append(line)
            continue
            
        # æ£€æµ‹æ˜¯å¦ä¸ºPythonä»£ç è¡Œ
        if is_python_code_line(stripped_line):
            in_python_code = True
            cleaned_lines.append(line)
        elif in_python_code and (stripped_line.startswith(' ') or stripped_line.startswith('\t')):
            # ç¼©è¿›è¡Œï¼Œå¯èƒ½æ˜¯ä»£ç çš„ä¸€éƒ¨åˆ†
            cleaned_lines.append(line)
        elif stripped_line.startswith('#') and not contains_chinese(stripped_line):
            # è‹±æ–‡æ³¨é‡Šä¿ç•™
            cleaned_lines.append(line)
        elif in_python_code and any(stripped_line.startswith(kw) for kw in ['def ', 'class ', 'if ', 'for ', 'while ', 'try:', 'except', 'finally:', 'with ', 'self.', 'return', 'import', 'from']):
            # Pythonå…³é”®å­—è¡Œ
            cleaned_lines.append(line)
        elif contains_chinese(stripped_line) and not is_python_code_line(stripped_line):
            # åŒ…å«ä¸­æ–‡ä¸”ä¸æ˜¯Pythonä»£ç çš„è¡Œï¼Œè·³è¿‡
            continue
        elif stripped_line.startswith('```') or 'ä¿®å¤' in stripped_line or 'è¯´æ˜' in stripped_line or 'é—®é¢˜' in stripped_line or stripped_line == '`':
            # æ˜æ˜¾çš„markdownæˆ–è¯´æ˜æ–‡å­—ï¼Œè·³è¿‡
            continue
        else:
            # å…¶ä»–å¯èƒ½çš„ä»£ç è¡Œ
            if in_python_code:
                cleaned_lines.append(line)
    
    result = '\n'.join(cleaned_lines).strip()
    
    # æœ€åæ¸…ç†å¯èƒ½æ®‹ç•™çš„markdownå­—ç¬¦
    while result.endswith('`') or result.endswith('\\'):
        if result.endswith('`'):
            result = result[:-1].strip()
        elif result.endswith('\\'):
            result = result[:-1].strip()
    
    return result


def extract_python_code_from_markdown(text):
    """
    ä»markdownæ ¼å¼æ–‡æœ¬ä¸­æå–Pythonä»£ç å—
    """
    import re
    
    # åŒ¹é…```python...```ä»£ç å—
    python_blocks = re.findall(r'```python\n(.*?)\n```', text, re.DOTALL)
    if python_blocks:
        return python_blocks[0]
    
    # åŒ¹é…```...```ä»£ç å—
    code_blocks = re.findall(r'```\n(.*?)\n```', text, re.DOTALL)
    if code_blocks:
        # é€‰æ‹©æœ€å¯èƒ½æ˜¯Pythonä»£ç çš„å—ï¼ˆåŒ…å«from manim importç­‰ï¼‰
        for block in code_blocks:
            if 'from manim import' in block or 'class Scene' in block:
                return block
        return code_blocks[0]
    
    # åŒ¹é…æ²¡æœ‰æ¢è¡Œçš„```ä»£ç å—
    simple_blocks = re.findall(r'```(.*?)```', text, re.DOTALL)
    if simple_blocks:
        for block in simple_blocks:
            if 'from manim import' in block or 'class Scene' in block:
                return block
        return simple_blocks[0]
    
    # å¦‚æœæ²¡æ‰¾åˆ°ä»£ç å—ï¼Œè¿”å›åŸæ–‡æœ¬
    return text


def contains_chinese(text):
    """
    æ£€æµ‹æ–‡æœ¬æ˜¯å¦åŒ…å«ä¸­æ–‡å­—ç¬¦
    """
    import re
    return bool(re.search(r'[\u4e00-\u9fff]', text))


def is_python_code_line(line):
    """
    åˆ¤æ–­ä¸€è¡Œæ˜¯å¦ä¸ºPythonä»£ç 
    """
    line = line.strip()
    if not line:
        return False
    
    # Pythonå…³é”®å­—å’Œå¸¸è§è¯­æ³•
    python_indicators = [
        'from ', 'import ', 'def ', 'class ', 'if ', 'elif ', 'else:', 
        'for ', 'while ', 'try:', 'except', 'finally:', 'with ',
        'return', 'yield', 'break', 'continue', 'pass', 'raise',
        'self.', '= ', '== ', '!= ', '< ', '> ', '<= ', '>= ',
        'and ', 'or ', 'not ', 'in ', 'is ', 'lambda',
        '__init__', '__str__', '__repr__'
    ]
    
    # æ£€æŸ¥æ˜¯å¦ä»¥Pythonè¯­æ³•å¼€å§‹
    if any(line.startswith(indicator) for indicator in python_indicators):
        return True
    
    # æ£€æŸ¥æ˜¯å¦åŒ…å«Pythonè¯­æ³•
    if any(indicator in line for indicator in ['()', '[]', '{}', ' = ', 'self.', 'def ', 'class ']):
        return True
    
    # å¦‚æœåŒ…å«ä¸­æ–‡ï¼Œå¾ˆå¯èƒ½ä¸æ˜¯ä»£ç 
    if contains_chinese(line):
        return False
    
    # æ£€æŸ¥æ˜¯å¦ä¸ºèµ‹å€¼ã€å‡½æ•°è°ƒç”¨ç­‰
    if '=' in line or '(' in line and ')' in line:
        return True
    
    return False


def edge_tts_generate(text, output_file, speaker = 'male'):
    """
    ç›´æ¥ç”¨ edge-tts é€»è¾‘ç”ŸæˆéŸ³é¢‘ï¼Œä¸ä¾èµ– FreeTTSGenerator ç±»ã€‚
    """

    try:
        import edge_tts
        import asyncio
        from pydub import AudioSegment

        # æ–‡æœ¬é¢„å¤„ç†å’ŒéªŒè¯
        if not text or not text.strip():
            print(f"TTSæ–‡æœ¬ä¸ºç©ºï¼Œè·³è¿‡ç”Ÿæˆ: '{text}'")
            return False

        text = text.strip()
        print(f"TTSç”Ÿæˆæ–‡æœ¬: '{text}' (é•¿åº¦: {len(text)})")

        VOICE_CHOICES = {
            'male': ('zh-CN-YunjianNeural', {'rate': '+0%', 'pitch': '+0Hz'}),  # ğŸ”§ æ”¹ä¸ºç”¨æˆ·æŒ‡å®šçš„å£°éŸ³
            'female': ('zh-CN-XiaoxiaoNeural', {'rate': '+5%', 'pitch': '+30Hz'}),
            'narrator': ('zh-CN-YunyangNeural', {'rate': '-5%', 'pitch': '-20Hz'}),
            'uncle': ('zh-CN-YunyeNeural', {'rate': '-5%', 'pitch': '-50Hz'}),
            'yunjian': ('zh-CN-YunjianNeural', {'rate': '+0%'})  # ğŸ”§ ä¿æŒåŸå§‹è¯­é€Ÿå’ŒéŸ³è°ƒ
        }

        voice, params = VOICE_CHOICES.get(speaker, VOICE_CHOICES['male'])
        rate = params.get('rate', '+0%')
        pitch = params.get('pitch', '+0Hz')
        output_dir = os.path.dirname(output_file) or '.'
        os.makedirs(output_dir, exist_ok=True)
        print(f"ä½¿ç”¨è¯­éŸ³: {voice}, è¯­é€Ÿ: {rate}, éŸ³è°ƒ: {pitch}")
        # ä¸åˆ†æ®µè½ï¼Œç›´æ¥å¤„ç†æ•´ä¸ªæ–‡æœ¬
        temp_file = os.path.join(output_dir, f"temp_tts_{uuid.uuid4()}.mp3")

        try:
            communicate = edge_tts.Communicate(
                text=text,
                voice=voice,
                rate=rate,
                pitch=pitch
            )

            async def generate_audio():
                audio_data = b''
                chunk_count = 0
                async for chunk in communicate.stream():
                    if chunk["type"] == "audio":
                        audio_data += chunk["data"]
                        chunk_count += 1

                print(f"æ¥æ”¶åˆ° {chunk_count} ä¸ªéŸ³é¢‘å—ï¼Œæ€»å¤§å°: {len(audio_data)} å­—èŠ‚")

                if len(audio_data) > 0:
                    with open(temp_file, "wb") as f:
                        f.write(audio_data)
                    return True
                else:
                    print(f"æ²¡æœ‰æ¥æ”¶åˆ°éŸ³é¢‘æ•°æ®")
                    return False

            # å¼‚æ­¥ç”Ÿæˆï¼ˆå…¼å®¹å·²æœ‰äº‹ä»¶å¾ªç¯çš„ç¯å¢ƒï¼‰
            def _run_coro_in_new_loop(coro):
                import threading
                result_container = {"result": False}
                def _target():
                    new_loop = asyncio.new_event_loop()
                    try:
                        asyncio.set_event_loop(new_loop)
                        result_container["result"] = new_loop.run_until_complete(coro)
                    finally:
                        try:
                            new_loop.run_until_complete(new_loop.shutdown_asyncgens())
                        except Exception:
                            pass
                        new_loop.close()
                t = threading.Thread(target=_target, daemon=True)
                t.start()
                t.join()
                return result_container["result"]

            try:
                loop = asyncio.get_event_loop()
                is_running = loop.is_running()
            except RuntimeError:
                # æ²¡æœ‰äº‹ä»¶å¾ªç¯
                loop = None
                is_running = False

            if is_running:
                # åœ¨å·²æœ‰äº‹ä»¶å¾ªç¯ä¸‹ï¼Œå¼€å¯æ–°çº¿ç¨‹çš„æ–°äº‹ä»¶å¾ªç¯æ‰§è¡Œ
                success = _run_coro_in_new_loop(generate_audio())
            else:
                # æ— äº‹ä»¶å¾ªç¯ï¼Œç›´æ¥è¿è¡Œ
                success = asyncio.run(generate_audio())
            if success and os.path.exists(temp_file) and os.path.getsize(temp_file) > 0:
                # éªŒè¯éŸ³é¢‘æ–‡ä»¶
                try:
                    audio_segment = AudioSegment.from_mp3(temp_file)
                    audio_segment.export(output_file, format="mp3")
                    print(f"éŸ³é¢‘æ–‡ä»¶ç”ŸæˆæˆåŠŸ: {output_file} (æ—¶é•¿: {len(audio_segment)/1000:.1f}ç§’)")
                    # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                    if os.path.exists(temp_file):
                        os.remove(temp_file)

                    return True
                except Exception as audio_error:
                    print(f"éŸ³é¢‘å¤„ç†å¤±è´¥: {audio_error}")
                    return False
            else:
                print(f"éŸ³é¢‘ç”Ÿæˆå¤±è´¥æˆ–æ–‡ä»¶ä¸ºç©º")
                return False
        except Exception as comm_error:
            print(f"Edge TTSé€šä¿¡å¤±è´¥: {comm_error}")
            return False
    except Exception as e:
        print(f"TTSç”Ÿæˆå¤±è´¥: {e}")
        return False


def get_audio_duration(audio_path):
    """
    è·å–éŸ³é¢‘æ–‡ä»¶æ—¶é•¿
    """

    try:
        from moviepy.editor import AudioFileClip
        audio_clip = AudioFileClip(audio_path)
        duration = audio_clip.duration
        audio_clip.close()
        return duration
    except Exception as e:
        print(f"æ— æ³•è·å–éŸ³é¢‘æ—¶é•¿: {e}")
        return 5.0  # é»˜è®¤å€¼


#éŸ³é¢‘å¤±è´¥çš„å›é€€æ–¹æ¡ˆ
def create_silent_audio(output_path, duration = 5.0):
    """
    åˆ›å»ºé™éŸ³éŸ³é¢‘ä½œä¸ºå›é€€æ–¹æ¡ˆ
    """

    try:
        from moviepy.editor import AudioClip
        import numpy as np

        def make_frame(t):
            return np.array([0.0, 0.0]) 

        audio = AudioClip(make_frame, duration=duration, fps=44100)
        audio.write_audiofile(output_path, verbose=False, logger=None)
        audio.close()
        return True
    except Exception as e:
        print(f"é™éŸ³éŸ³é¢‘åˆ›å»ºå¤±è´¥: {e}")

        # å›é€€æ–¹æ¡ˆï¼šåˆ›å»ºç©ºæ–‡ä»¶
        try:
            with open(output_path, 'w') as f:
                f.write("")
            return True
        except:
            return False


# äºŒæ¬¡æ£€æŸ¥å’Œå¢å¼ºåŠ¨ç”»å†…å®¹
def optimize_animation(segment_content, segment_type, main_theme, context_segments, total_segments, segment_index):
    """
    æ™ºèƒ½åŠ¨ç”»ä¼˜åŒ–å™¨ - å¯¹åŠ¨ç”»å†…å®¹è¿›è¡ŒäºŒæ¬¡æ£€æŸ¥å’Œä¼˜åŒ–
    """

    print(f"å¯åŠ¨æ™ºèƒ½åŠ¨ç”»ä¼˜åŒ–å™¨ - æ®µè½{segment_index + 1}")
    # æ„å»ºä¸Šä¸‹æ–‡ä¿¡æ¯
    prev_context = ""
    next_context = ""
    if segment_index > 0:
        prev_segments = context_segments[max(0, segment_index-2):segment_index]
        prev_context = " ".join([seg.get('content', '') for seg in prev_segments])

    if segment_index < len(total_segments) - 1:
        next_segments = context_segments[segment_index+1:segment_index+3]
        next_context = " ".join([seg.get('content', '') for seg in next_segments])

    optimization_prompt = f"""ä½ æ˜¯é¡¶çº§çš„ç§‘æ™®æ•™è‚²åŠ¨ç”»å¯¼æ¼”ï¼Œè¯·å¯¹ä»¥ä¸‹åŠ¨ç”»æ®µè½è¿›è¡Œæ™ºèƒ½åˆ†æå’Œä¼˜åŒ–å»ºè®®ï¼š

**åŸºæœ¬ä¿¡æ¯**ï¼š
- ä¸»é¢˜ï¼š{main_theme}
- å½“å‰æ®µè½ç±»å‹ï¼š{segment_type}
- å½“å‰å†…å®¹ï¼š{segment_content}
- æ®µè½ä½ç½®ï¼šç¬¬{segment_index + 1}æ®µ / å…±{len(total_segments)}æ®µ

**ä¸Šä¸‹æ–‡**ï¼š
- å‰æ–‡å†…å®¹ï¼š{prev_context[-200:] if prev_context else 'æ— '}
- åæ–‡å†…å®¹ï¼š{next_context[:200] if next_context else 'æ— '}

**ä¼˜åŒ–ä»»åŠ¡**ï¼š
1. **å†…å®¹åˆ†æ**ï¼šåˆ†æè¿™æ®µå†…å®¹çš„æ ¸å¿ƒæ¦‚å¿µã€æƒ…æ„Ÿè‰²å½©ã€æ•™å­¦ä»·å€¼
2. **åŠ¨ç”»å»ºè®®**ï¼šåŸºäºå†…å®¹ç‰¹ç‚¹å’Œä¸Šä¸‹æ–‡ï¼Œå»ºè®®æœ€åˆé€‚çš„åŠ¨ç”»å…ƒç´ å’Œè§†è§‰æ•ˆæœ
3. **æ–‡æ¡ˆä¼˜åŒ–**ï¼šå¦‚æœæ–‡æ¡ˆä¸å¤Ÿç”ŸåŠ¨æˆ–æœ‰é—®é¢˜ï¼Œæå‡ºä¼˜åŒ–å»ºè®®
4. **ä¸»é¢˜å‘¼åº”**ï¼šç¡®ä¿ä¸æ•´ä½“ä¸»é¢˜{main_theme}ä¿æŒä¸€è‡´

è¯·ä»¥JSONæ ¼å¼è¿”å›ä¼˜åŒ–å»ºè®®ï¼š
{{
    "content_analysis": {{
        "core_concepts": ["æ¦‚å¿µ1", "æ¦‚å¿µ2"],
        "emotional_tone": "å¹½é»˜/ä¸¥è‚ƒ/æ¿€åŠ¨ç­‰",
        "teaching_value": "æ•™å­¦ä»·å€¼æè¿°",
        "visual_opportunities": ["å¯è§†åŒ–æœºä¼š1", "å¯è§†åŒ–æœºä¼š2"]
    }},
    "animation_recommendations": {{
        "primary_elements": ["ä¸»è¦åŠ¨ç”»å…ƒç´ "],
        "visual_effects": ["è§†è§‰æ•ˆæœ"],
        "color_scheme": "å»ºè®®è‰²å½©æ–¹æ¡ˆ",
        "animation_style": "åŠ¨ç”»é£æ ¼å»ºè®®",
        "timing_suggestions": "æ—¶é—´èŠ‚å¥å»ºè®®"
    }},
    "script_optimization": {{
        "needs_improvement": true/false,
        "optimized_content": "ä¼˜åŒ–åçš„æ–‡æ¡ˆï¼ˆå¦‚æœéœ€è¦ï¼‰",
        "improvement_reasons": ["æ”¹è¿›åŸå› "]
    }},
    "context_integration": {{
        "connects_to_previous": "ä¸å‰æ–‡çš„è¿æ¥ç‚¹",
        "prepares_for_next": "ä¸ºåæ–‡çš„é“ºå«",
        "theme_alignment": "ä¸ä¸»é¢˜çš„å‘¼åº”"
    }}
}}"""

    try:
        result = modai_model_request(optimization_prompt, model="Qwen/Qwen3-Coder-480B-A35B-Instruct",max_tokens=800,temperature=0.6)
        print(f"APIè¿”å›åŸå§‹ç»“æœ: {result[:200]}...")

        # å°è¯•è§£æJSON
        import json

        # æ¸…ç†å¯èƒ½çš„markdownæ ¼å¼
        if "```json" in result:
            result = result.split("```json")[1].split("```")[0].strip()
        elif "```" in result:
            result = result.split("```")[1].split("```")[0].strip()

        # å°è¯•ä¿®å¤å¸¸è§çš„JSONæ ¼å¼é—®é¢˜
        if not result.startswith('{'):
            # æ‰¾åˆ°ç¬¬ä¸€ä¸ª{
            start_idx = result.find('{')
            if start_idx != -1:
                result = result[start_idx:]

        if not result.endswith('}'):
            # æ‰¾åˆ°æœ€åä¸€ä¸ª}
            end_idx = result.rfind('}')
            if end_idx != -1:
                result = result[:end_idx+1]

        # æ£€æŸ¥æ˜¯å¦æœ‰æœªé—­åˆçš„å­—ç¬¦ä¸²
        quote_count = result.count('"')
        if quote_count % 2 != 0:
            last_quote_pos = result.rfind('"')
            for i in range(last_quote_pos + 1, len(result)):
                if result[i] in [',', '}', ']']:
                    result = result[:i] + '"' + result[i:]
                    print(f"ä¿®å¤äº†æœªé—­åˆçš„å­—ç¬¦ä¸²ï¼Œåœ¨ä½ç½® {i} æ·»åŠ å¼•å·")
                    break

            if quote_count == result.count('"'): 
                result = result.rstrip() + '"}'
                print(f"åœ¨æœ«å°¾æ·»åŠ ç¼ºå¤±çš„å¼•å·å’Œæ‹¬å·")

        # å¤„ç†ç¼ºå¤±çš„é€—å·å’Œæ‹¬å·
        lines = result.split('\n')
        cleaned_lines = []
        for line in lines:
            line = line.strip()
            if line and not line.endswith(('", ', '",', '"', '}', ']')):
                if '"' in line and not line.endswith('"'):
                    line = line + '"'
            cleaned_lines.append(line)
        result = '\n'.join(cleaned_lines)

        if not result.endswith('}'):
            result = result.rstrip().rstrip(',') + '\n    }\n}'
            print(f"æ·»åŠ ç¼ºå¤±çš„ç»“æŸç»“æ„")
        
        # ä½¿ç”¨æœ¬åœ°çš„JSONè§£æå‡½æ•°
        def extract_json_with_fallback(text, default_value):
            try:
                # å°è¯•ä»markdownä»£ç å—ä¸­æå–JSON
                json_match = re.search(r'```json\s*(\{.*?\})\s*```', text, re.DOTALL)
                if json_match:
                    json_str = json_match.group(1)
                else:
                    json_str = text.strip()
                return json.loads(json_str)
            except (json.JSONDecodeError, AttributeError, TypeError) as e:
                print(f"JSONè§£æå¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å€¼: {e}")
                return default_value
        
        optimization_data = extract_json_with_fallback(result.strip(), {
            "content_analysis": {
                "core_concepts": ["MCP TOOL CALLING", "å·¥å…·è°ƒç”¨"],
                "emotional_tone": "å¹½é»˜ç§‘æ™®",
                "teaching_value": "è§£é‡ŠAIå·¥å…·è°ƒç”¨æœºåˆ¶"
            },
            "animation_recommendations": {
                "primary_style": "æ¼”ç¤ºåŠ¨ç”»",
                "visual_elements": ["å·¥å…·å›¾æ ‡", "è°ƒç”¨æµç¨‹"],
                "timing_strategy": "èŠ‚å¥ç´§å‡‘"
            }
        })
        
        core_concepts_count = len(optimization_data.get('content_analysis', {}).get('core_concepts', []))
        print(f"æ™ºèƒ½åˆ†æå®Œæˆï¼Œå‘ç° {core_concepts_count} ä¸ªæ ¸å¿ƒæ¦‚å¿µ")
        return optimization_data
        
    except Exception as e:
        print(f"åˆ†æè¿‡ç¨‹å¼‚å¸¸: {e}")
        print(f"åŸå§‹è¿”å›: {result[:500]}...")

        try:
            print("å°è¯•å¼ºåŒ–JSONä¿®å¤...")
            # 1: å°è¯•æå–ä¸»è¦ç»“æ„
            content_analysis_match = re.search(r'"content_analysis":\s*\{([^}]*)\}', result, re.DOTALL)
            animation_match = re.search(r'"animation_recommendations":\s*\{([^}]*)\}', result, re.DOTALL)

            if content_analysis_match or animation_match:
                print("é€šè¿‡æ­£åˆ™è¡¨è¾¾å¼æå–éƒ¨åˆ†æ•°æ®")
                # æ„å»ºåŸºæœ¬çš„JSONç»“æ„
                repair_data = {
                    "content_analysis": {
                        "core_concepts": ["MCP TOOL CALLING", "å·¥å…·è°ƒç”¨"],
                        "emotional_tone": "å¹½é»˜ç§‘æ™®",
                        "teaching_value": "è§£é‡ŠAIå·¥å…·è°ƒç”¨æœºåˆ¶",
                        "visual_opportunities": ["æµç¨‹å›¾", "åŠ¨ç”»æ¼”ç¤º"]
                    },

                    "animation_recommendations": {
                        "primary_elements": ["å·¥å…·è°ƒç”¨æµç¨‹", "APIæ¥å£åŠ¨ç”»"],
                        "visual_effects": ["è¿æ¥çº¿åŠ¨ç”»", "æ•°æ®æµ"],
                        "color_scheme": "ç§‘æŠ€è“é…æ©™è‰²",
                        "animation_style": "ç°ä»£æ‰å¹³",
                        "timing_suggestions": "35-45ç§’èŠ‚å¥"
                    },

                    "script_optimization": {
                        "needs_improvement": False,
                        "optimized_content": segment_content,
                        "improvement_reasons": []
                    },

                    "context_integration": {
                        "connects_to_previous": "AIåŸºç¡€èƒ½åŠ›",
                        "prepares_for_next": "å®é™…åº”ç”¨æ¡ˆä¾‹",
                        "theme_alignment": "MCP TOOL CALLINGæ ¸å¿ƒæœºåˆ¶"
                    }
                }

                if content_analysis_match:
                    content_text = content_analysis_match.group(1)
                    concepts_match = re.search(r'"core_concepts":\s*\[(.*?)\]', content_text, re.DOTALL)
                    if concepts_match:
                        concepts_str = concepts_match.group(1)
                        concepts = re.findall(r'"([^"]*)"', concepts_str)
                        if concepts:
                            repair_data["content_analysis"]["core_concepts"] = concepts[:4]
                print(f"JSONä¿®å¤æˆåŠŸï¼Œä½¿ç”¨éƒ¨åˆ†æå–çš„æ•°æ®")
                return repair_data
        except Exception as repair_e:
            print(f"JSONä¿®å¤ä¹Ÿå¤±è´¥: {repair_e}")

        # è¿”å›åŸºç¡€åˆ†æç»“æœ
        return {
            "content_analysis": {
                "core_concepts": ["æ¦‚ç‡é¢„æµ‹", "è¯­è¨€æ¨¡å‹"],
                "emotional_tone": "ç§‘æ™®",
                "teaching_value": "è§£é‡ŠAIå·¥ä½œåŸç†",
                "visual_opportunities": ["å…¬å¼å±•ç¤º", "æ¦‚ç‡å›¾"]
            },
            "animation_recommendations": {
                "primary_elements": ["å…¬å¼åŠ¨ç”»", "æ¦‚ç‡å±•ç¤º"],
                "visual_effects": ["æ¸å…¥", "é«˜äº®"],
                "color_scheme": "ç§‘æŠ€è“è‰²",
                "animation_style": "ç°ä»£ç§‘æ™®",
                "timing_suggestions": "ç¨³å®šèŠ‚å¥"
            },
            "script_optimization": {
                "needs_improvement": False,
                "optimized_content": segment_content,
                "improvement_reasons": []
            },
            "context_integration": {
                "connects_to_previous": "è®­ç»ƒè¿‡ç¨‹",
                "prepares_for_next": "åº”ç”¨æ•ˆæœ", 
                "theme_alignment": "AIæ ¸å¿ƒåŸç†"
            }
        }
    except Exception as e:
        print(f"æ™ºèƒ½ä¼˜åŒ–å¤±è´¥: {e}")
        return {"error": str(e)}


def enhanced_script_and_animation_generator(original_content, content_type, main_theme,optimization_data, class_name) :
    """
    åŸºäºä¼˜åŒ–å»ºè®®ç”Ÿæˆå¢å¼ºçš„æ–‡æ¡ˆå’ŒåŠ¨ç”»ä»£ç 
    """
    print(f"ç”Ÿæˆå¢å¼ºç‰ˆæ–‡æ¡ˆå’ŒåŠ¨ç”»...")
    script_opt = optimization_data.get('script_optimization', {})
    anim_rec = optimization_data.get('animation_recommendations', {})
    content_analysis = optimization_data.get('content_analysis', {})
    
    if script_opt.get('needs_improvement', False):
        optimized_script = script_opt.get('optimized_content', original_content)
        print(f"æ–‡æ¡ˆå·²ä¼˜åŒ–: {script_opt.get('improvement_reasons', [])}")
    else:
        optimized_script = original_content

    # ç”Ÿæˆå¢å¼ºåŠ¨ç”»ä»£ç 
    enhanced_animation_prompt = f"""ä½ æ˜¯é¡¶çº§ManimåŠ¨ç”»ä¸“å®¶ï¼Œè¯·åŸºäºä»¥ä¸‹è¯¦ç»†åˆ†æåˆ›å»ºéœ‡æ’¼çš„ç§‘æ™®æ•™è‚²åŠ¨ç”»ï¼š

**åŠ¨ç”»è§„æ ¼**ï¼š
- ç±»åï¼š{class_name}
- å†…å®¹ç±»å‹ï¼š{content_type}
- ä¸»é¢˜ï¼š{main_theme}

**æ–‡æ¡ˆå†…å®¹**ï¼š
{optimized_script}

**æ™ºèƒ½åˆ†æç»“æœ**ï¼š
- æ ¸å¿ƒæ¦‚å¿µï¼š{content_analysis.get('core_concepts', [])}
- æƒ…æ„Ÿè‰²å½©ï¼š{content_analysis.get('emotional_tone', 'è½»æ¾ç§‘æ™®')}
- å¯è§†åŒ–æœºä¼šï¼š{content_analysis.get('visual_opportunities', [])}

**åŠ¨ç”»å»ºè®®**ï¼š
- ä¸»è¦å…ƒç´ ï¼š{anim_rec.get('primary_elements', [])}
- è§†è§‰æ•ˆæœï¼š{anim_rec.get('visual_effects', [])}
- è‰²å½©æ–¹æ¡ˆï¼š{anim_rec.get('color_scheme', 'å¤šå½©ç”ŸåŠ¨')}
- åŠ¨ç”»é£æ ¼ï¼š{anim_rec.get('animation_style', 'ç°ä»£ç§‘æ™®')}
- æ—¶é—´èŠ‚å¥ï¼š{anim_rec.get('timing_suggestions', 'èˆ’ç¼“æµç•…')}

**åˆ›ä½œè¦æ±‚**ï¼š
1. **å†…å®¹ä¸°å¯Œ**ï¼šå……åˆ†ä½“ç°æ–‡æ¡ˆä¸­çš„æ‰€æœ‰ç²¾å½©å†…å®¹ï¼Œä¸è¦ç®€åŒ–
2. **è§†è§‰éœ‡æ’¼**ï¼šä½¿ç”¨å¤šç§åŠ¨ç”»æ•ˆæœã€é¢œè‰²æ¸å˜ã€ç²’å­æ•ˆæœç­‰
3. **æ•™å­¦æ¸…æ™°**ï¼šé‡ç‚¹çªå‡ºï¼Œå±‚æ¬¡åˆ†æ˜ï¼Œæ˜“äºç†è§£
4. **å¹½é»˜ç”ŸåŠ¨**ï¼šä½“ç°æ–‡æ¡ˆçš„å¹½é»˜æ„Ÿå’Œç”ŸåŠ¨æ€§
5. **æŠ€æœ¯ç²¾æ¹›**ï¼šä½¿ç”¨é«˜çº§ManimæŠ€æœ¯ï¼Œé¿å…ç®€å•å±•ç¤º

è¯·ç”Ÿæˆå®Œæ•´çš„Manimä»£ç ï¼Œè®©è¿™ä¸ªåŠ¨ç”»æˆä¸ºæ•™å­¦è§†é¢‘ä¸­çš„äº®ç‚¹ï¼"""

    try:
        enhanced_code = modai_model_request(enhanced_animation_prompt,model="Qwen/Qwen3-Coder-480B-A35B-Instruct",max_tokens=1500,temperature=0.7)
        print(f"å¢å¼ºåŠ¨ç”»ä»£ç ç”Ÿæˆå®Œæˆ")
        return optimized_script, enhanced_code.strip()
    except Exception as e:
        print(f"å¢å¼ºåŠ¨ç”»ç”Ÿæˆå¤±è´¥: {e}")
        return optimized_script, ""


# åŠ¨ç”»åˆ¤æ–­
def should_add_animation_elements(content, content_type, context_info=None):
    """
    æ™ºèƒ½åˆ¤æ–­æ˜¯å¦éœ€è¦æ·»åŠ åŠ¨ç”»å…ƒç´ ï¼Œä»¥åŠæ·»åŠ ä»€ä¹ˆç±»å‹çš„å…ƒç´ 
    """

    context_info = context_info or {}
    animation_elements = {
        'use_formula': False,
        'use_code': False, 
        'use_chart': False,
        'use_diagram': False,
        'use_comparison': False,
        'use_emoji': False,
        'use_bubble': False,
        'suggested_elements': []
    }

    content_lower = content.lower()

    # å…¬å¼ç›¸å…³è§¦å‘è¯
    formula_triggers = ['ç­‰äº', 'è®¡ç®—', 'ç®—æ³•', 'æ•°å­¦', 'æ–¹ç¨‹', 'å‡½æ•°', 'å˜é‡', 'å‚æ•°', 'æ±‚è§£', 'ç»“æœæ˜¯']
    if any(trigger in content for trigger in formula_triggers) or '=' in content:
        animation_elements['use_formula'] = True
        animation_elements['suggested_elements'].append('mathematical_notation')

    # ä»£ç ç›¸å…³è§¦å‘è¯  
    code_triggers = ['ç¨‹åº', 'ä»£ç ', 'ç¼–ç¨‹', 'å‡½æ•°', 'å˜é‡', 'ç®—æ³•å®ç°', 'ä»£ç ç¤ºä¾‹', 'ç¼–å†™', 'è¿è¡Œ']
    if any(trigger in content for trigger in code_triggers):
        animation_elements['use_code'] = True
        animation_elements['suggested_elements'].append('code_snippet')

    # å›¾è¡¨ç›¸å…³è§¦å‘è¯
    chart_triggers = ['æ•°æ®', 'ç»Ÿè®¡', 'å¢é•¿', 'ä¸‹é™', 'æ¯”è¾ƒ', 'è¶‹åŠ¿', 'å æ¯”', 'ç™¾åˆ†æ¯”', 'æ’è¡Œ']
    if any(trigger in content for trigger in chart_triggers):
        animation_elements['use_chart'] = True
        animation_elements['suggested_elements'].append('data_visualization')

    # å¯¹æ¯”ç›¸å…³è§¦å‘è¯
    comparison_triggers = ['ä¸åŒ', 'åŒºåˆ«', 'å¯¹æ¯”', 'ç›¸æ¯”', 'è€Œ', 'ä½†æ˜¯', 'ç„¶è€Œ', 'ä¼˜ç¼ºç‚¹', 'ä¼˜åŠ¿']
    if any(trigger in content for trigger in comparison_triggers):
        animation_elements['use_comparison'] = True
        animation_elements['suggested_elements'].append('comparison_layout')
    # æƒ…æ„Ÿå’Œè¶£å‘³å…ƒç´ åˆ¤æ–­

    emotion_triggers = ['æœ‰è¶£', 'ç¥å¥‡', 'æƒŠäºº', 'å‰å®³', 'é…·', 'æ£’', 'å“‡', 'çœŸçš„']
    if any(trigger in content for trigger in emotion_triggers):
        animation_elements['use_emoji'] = True
        animation_elements['use_bubble'] = True
        animation_elements['suggested_elements'].extend(['emoji_reaction', 'speech_bubble'])

    # åŸºäºå†…å®¹ç±»å‹çš„é»˜è®¤å»ºè®®
    type_defaults = {
        'definition': ['concept_highlight', 'definition_card'],
        'example': ['case_study', 'step_by_step'],
        'explanation': ['flow_diagram', 'cause_effect'],
        'emphasis': ['highlight_effect', 'attention_grabber']
    }

    if content_type in type_defaults:
        animation_elements['suggested_elements'].extend(type_defaults[content_type])

    return animation_elements


# è‹±æ–‡ç¿»è¯‘åŠŸèƒ½
def translate_text_to_english(text):
    """
    å°†ä¸­æ–‡æ–‡æœ¬ç¿»è¯‘ä¸ºè‹±æ–‡
    """

    prompt = """

# è§’è‰²
ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„ç¿»è¯‘ä¸“å®¶ï¼Œæ“…é•¿å°†ä¸­æ–‡æ–‡æœ¬å‡†ç¡®æµç•…åœ°ç¿»è¯‘æˆè‹±æ–‡ã€‚

## æŠ€èƒ½
- æ¥æ”¶åˆ°ä¸­æ–‡å†…å®¹åï¼Œå°†å…¶å‡†ç¡®ç¿»è¯‘æˆè‹±æ–‡ï¼Œç¡®ä¿è¯‘æ–‡ä¿æŒåŸæ–‡çš„æ„ä¹‰ã€è¯­æ°”å’Œé£æ ¼ã€‚
- å……åˆ†è€ƒè™‘ä¸­æ–‡çš„è¯­å¢ƒå’Œæ–‡åŒ–å†…æ¶µï¼Œä½¿è‹±æ–‡è¡¨è¾¾æ—¢å¿ å®åŸæ–‡åˆç¬¦åˆè‹±è¯­ä¹ æƒ¯ã€‚
- ç¦æ­¢åŒä¸€å¥å­ç”Ÿæˆå¤šä»½è¯‘æ–‡ã€‚
- è¾“å‡ºå†…å®¹éœ€ç¬¦åˆè‹±è¯­è¯­æ³•è§„èŒƒï¼Œè¡¨è¾¾æ¸…æ™°ã€æµç•…ï¼Œå¹¶å…·æœ‰è‰¯å¥½çš„å¯è¯»æ€§ã€‚
- å‡†ç¡®ä¼ è¾¾åŸæ–‡æ‰€æœ‰ä¿¡æ¯ï¼Œé¿å…éšæ„æ·»åŠ æˆ–åˆ å‡å†…å®¹ã€‚
- ä»…æä¾›ä¸ä¸­æ–‡åˆ°è‹±æ–‡ç¿»è¯‘ç›¸å…³çš„æœåŠ¡ã€‚
- åªè¾“å‡ºç¿»è¯‘ç»“æœï¼Œä¸è¦ä»»ä½•è¯´æ˜ã€‚

"""

    try:
        print(f"[ç¿»è¯‘DEBUG] åŸæ–‡: {text[:50]}...")
        full_prompt = f"{prompt}\nåŸæ–‡ï¼š{text}\nè¯‘æ–‡ï¼š"
        print(f"[ç¿»è¯‘DEBUG] å®Œæ•´æç¤ºè¯: {full_prompt[:100]}...")
        result = modai_model_request(full_prompt, model="Qwen/Qwen3-Coder-480B-A35B-Instruct", max_tokens=512, temperature=0.3)
        print(f"[ç¿»è¯‘DEBUG] ç¿»è¯‘ç»“æœ: {result}")
        print(f"[ç¿»è¯‘DEBUG] ç»“æœç±»å‹: {type(result)}")
        return result.strip() if result else ""
    except Exception as e:
        print(f"è‹±æ–‡ç¿»è¯‘å¤±è´¥: {e}")
        return ""


def enhanced_generate_manim_code(content_type, content, class_name, surrounding_text = "", total_duration = 8.0, context_info = None):
    """
    å¢å¼ºç‰ˆåŠ¨ç”»ä»£ç ç”Ÿæˆ - é›†æˆæ™ºèƒ½å…ƒç´ åˆ¤æ–­å’Œä¸°å¯ŒåŠ¨ç”»æ•ˆæœ
    """

    context_info = context_info or {}
    
    animation_elements = should_add_animation_elements(content, content_type, context_info)
    intro_time = total_duration * 0.15
    main_time = total_duration * 0.7

    if content_type == 'definition':
        content_lines = split_content_into_lines(content, max_chars_per_line=12, max_lines=6)
        content_display = '\\n'.join(content_lines)
        prompt = f"""ä½ æ˜¯ä¸“ä¸šçš„æ•™è‚²åŠ¨ç”»è®¾è®¡å¸ˆã€‚åˆ›å»ºä¸€ä¸ªç”ŸåŠ¨æœ‰è¶£çš„å®šä¹‰å±•ç¤ºåŠ¨ç”»ï¼š

**å®šä¹‰å†…å®¹**: {content}
**æ™ºèƒ½å»ºè®®å…ƒç´ **: {animation_elements['suggested_elements']}
**ä½¿ç”¨è¡¨æƒ…ç¬¦å·**: {'æ˜¯' if animation_elements['use_emoji'] else 'å¦'}
**ä½¿ç”¨æ°”æ³¡å¯¹è¯**: {'æ˜¯' if animation_elements['use_bubble'] else 'å¦'}
**æ€»æ—¶é•¿**: {total_duration:.1f}ç§’

è®¾è®¡è¦æ±‚ï¼š
1. ç±»åå¿…é¡»æ˜¯ {class_name}
2. é£æ ¼ï¼šè½»æ¾ç§‘æ™®ï¼Œä¸“ä¸šä¸”æœ‰è¶£
3. è‰²å½©ï¼šæ·±è‰²ä¸»ä½“æ–‡å­— + é²œè‰³å¼ºè°ƒè‰² + ç™½è‰²èƒŒæ™¯é€‚é…
4. åŠ¨ç”»ä¸°å¯Œåº¦ï¼š
   - æ–‡å­—å‡ºç°ç”¨Writeæˆ–FadeIné…åˆè½»å¾®bouncing
   - é‡è¦è¯æ±‡é—ªçƒæˆ–é¢œè‰²å˜åŒ–
   - é€‚å½“æ·»åŠ Indicateã€Circumscribeç­‰å¼ºè°ƒåŠ¨ç”»
   - å¯ä»¥æ·»åŠ å°å›¾æ ‡ã€ç®­å¤´ã€è£…é¥°å…ƒç´ 

è¯·ç”Ÿæˆå®Œæ•´Manimä»£ç ï¼Œç¡®ä¿åŠ¨ç”»ç”ŸåŠ¨ã€ä¿¡æ¯æ¸…æ™°ã€èŠ‚å¥èˆ’é€‚ï¼š"""

    elif content_type == 'formula':
        prompt = f"""åˆ›å»ºä¸€ä¸ªå¼•äººå…¥èƒœçš„å…¬å¼å±•ç¤ºåŠ¨ç”»ï¼š

**å…¬å¼å†…å®¹**: {content}
**æ™ºèƒ½å…ƒç´ å»ºè®®**: {animation_elements['suggested_elements']}

è®¾è®¡è¦æ±‚ï¼š
1. ç±»å: {class_name}
2. æ ¸å¿ƒç­–ç•¥ï¼šä¼˜å…ˆç”¨Textï¼ŒMathTexä½œä¸ºå¢å¼ºï¼ˆé¿å…LaTeXé—®é¢˜ï¼‰
3. è§†è§‰ä¸°å¯Œï¼šå…¬å¼åˆ†æ­¥éª¤å‡ºç°ï¼Œç­‰å·è¿ç®—ç¬¦ç‰¹æ®Šå¼ºè°ƒ
4. è¶£å‘³å…ƒç´ ï¼š{'æ·»åŠ è®¡ç®—æ°”æ³¡å’Œè¡¨æƒ…ç¬¦å·' if animation_elements['use_bubble'] else 'ä½¿ç”¨ç®€æ´é£æ ¼'}

è¯·ç”Ÿæˆå®Œæ•´ä»£ç ï¼š"""
        
    elif content_type == 'code':
        prompt = f"""è®¾è®¡ä¸€ä¸ªç¼–ç¨‹æ•™å­¦åŠ¨ç”»ï¼š

**ä»£ç å†…å®¹**: {content}
**æ™ºèƒ½å»ºè®®**: {animation_elements['suggested_elements']}

è¦æ±‚ï¼š
1. ç±»å: {class_name}  
2. ä»£ç å±•ç¤ºï¼šç”¨Textç±»ï¼ˆfont="Courier"ï¼‰è€ŒéCodeç±»
3. è¯­æ³•é«˜äº®ï¼šå…³é”®å­—è“è‰²ã€å˜é‡ç»¿è‰²ã€å­—ç¬¦ä¸²æ©™è‰²
4. æ‰§è¡Œæ¨¡æ‹Ÿï¼šç”¨ç®­å¤´ã€é«˜äº®ç­‰å±•ç¤ºç¨‹åºè¿è¡Œæµç¨‹

è¯·åˆ›å»ºç”ŸåŠ¨çš„ä»£ç æ•™å­¦åŠ¨ç”»ï¼š"""

    else:
        prompt = f"""åˆ›å»º{content_type}ç±»å‹çš„æ•™å­¦åŠ¨ç”»ï¼š

**å†…å®¹**: {content}
**å»ºè®®å…ƒç´ **: {animation_elements['suggested_elements']}
**æ—¶é•¿**: {total_duration:.1f}ç§’

è¦æ±‚ï¼š
1. ç±»å: {class_name}
2. è§†è§‰ä¸°å¯Œï¼šå¤šè‰²å½©ã€å¤šå±‚æ¬¡ã€å¤šåŠ¨ç”»æ•ˆæœ
3. é‡ç‚¹çªå‡ºï¼šå…³é”®ä¿¡æ¯ç”¨ç‰¹æ®Šé¢œè‰²å’ŒåŠ¨ç”»

è¯·åˆ›å»ºå¼•äººå…¥èƒœçš„åŠ¨ç”»ï¼š"""
        
    try:
        result = modai_model_request(prompt, model="Qwen/Qwen3-Coder-480B-A35B-Instruct", max_tokens=1200, temperature=0.8)
        return result.strip()
    except Exception as e:
        print(f"å¢å¼ºåŠ¨ç”»ç”Ÿæˆå¤±è´¥: {e}")
        return create_simple_manim_scene(content_type, content, class_name, "")


def create_manual_background(title_text = "", output_dir = "output", topic=None):
    """é»˜è®¤èƒŒæ™¯æ ·å¼"""

    from PIL import Image, ImageDraw, ImageFont
    import os
    import time
    import textwrap

    os.makedirs(output_dir, exist_ok=True)
    width, height = 1920, 1080
    background_color = (255, 255, 255)
    title_color = (0, 0, 0)

    config = {
        'title_font_size': 50,
        'subtitle_font_size': 54,
        'title_max_width': 15,
        'subtitle_color': (0, 0, 0),
        'line_spacing': 15,
        'padding': 50,
        'line_width': 8,
        'subtitle_offset': 40,
        'line_position_offset': 190
    }

    image = Image.new('RGB', (width, height), background_color)
    draw = ImageDraw.Draw(image)

    def _get_font(size):
        script_dir = os.path.dirname(os.path.abspath(__file__))
        import matplotlib.font_manager as fm
        font_names = ['SimHei', 'WenQuanYi Micro Hei', 'Heiti TC', 'Microsoft YaHei']
        # é¦–å…ˆå°è¯•åŠ è½½æœ¬åœ°å­—ä½“æ–‡ä»¶
        local_font = os.path.join(script_dir, 'asset', 'å­—å°é­‚æ‰¶æ‘‡æ‰‹ä¹¦(å•†ç”¨éœ€æˆæƒ).ttf')
        try:
            return ImageFont.truetype(local_font, size)
        except Exception as e:
            print(f"æœ¬åœ°å­—ä½“åŠ è½½å¤±è´¥: {local_font}, é”™è¯¯: {str(e)}")
        # å°è¯•ä½¿ç”¨matplotlibæŸ¥æ‰¾ç³»ç»Ÿä¸­çš„ä¸­æ–‡å­—ä½“
        for font_name in font_names:
            try:
                font_path = fm.findfont(fm.FontProperties(family=font_name))
                return ImageFont.truetype(font_path, size)
            except Exception as e:
                print(f"æ— æ³•æ‰¾åˆ°å­—ä½“: {font_name}, é”™è¯¯: {str(e)}")
                continue

        print("æ‰€æœ‰å­—ä½“åŠ è½½å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å­—ä½“")
        return ImageFont.load_default()


    title_font = _get_font(config['title_font_size'])
    subtitle_font = _get_font(config['subtitle_font_size'])

    title_display = title_text or "AIçŸ¥è¯†ç§‘æ™®"
    title_lines = textwrap.wrap(title_display, width=config['title_max_width'])
    y_position = config['padding']
    for line in title_lines:
        bbox = draw.textbbox((0, 0), line, font=title_font)
        draw.text(
            (config['padding'], y_position),
            line,
            font=title_font,
            fill=title_color
        )
        y_position += (bbox[3] - bbox[1]) + config['line_spacing']
    subtitle_lines = ["ç¡¬æ ¸çŸ¥è¯†åˆ†äº«", "é­”æ­ç¤¾åŒºå‡ºå“"]
    y_position = config['padding']
    for i, line in enumerate(subtitle_lines):
        bbox = draw.textbbox((0, 0), line, font=subtitle_font)
        x_offset = width - bbox[2] - (config['padding'] + 30) + (i * config['subtitle_offset'])
        draw.text(
            (x_offset, y_position),
            line,
            font=subtitle_font,
            fill=config['subtitle_color']
        )
        y_position += bbox[3] - bbox[1] + 5 

    line_y = height - config['padding'] - config['line_position_offset']
    draw.line([
        (0, line_y),
        (width, line_y)
    ], fill=(0, 0, 0), width=config['line_width'])

    if topic:
        # æ¸…ç†topicä¸­çš„ç‰¹æ®Šå­—ç¬¦ï¼Œé¿å…è·¯å¾„é—®é¢˜
        import re
        safe_topic = re.sub(r'[^\w\u4e00-\u9fff\-_]', '_', topic)  # åªä¿ç•™å­—æ¯ã€æ•°å­—ã€ä¸­æ–‡ã€æ¨ªçº¿ã€ä¸‹åˆ’çº¿
        safe_topic = safe_topic[:50]  # é™åˆ¶é•¿åº¦
        theme_dir = os.path.join(output_dir, safe_topic)
        os.makedirs(theme_dir, exist_ok=True)
        output_path = os.path.join(theme_dir, f'background_{uuid.uuid4()}.png')
    else:
        os.makedirs(output_dir, exist_ok=True)
        output_path = os.path.join(output_dir, f'background_{uuid.uuid4()}.png')
    image.save(output_path)
    print(f"ä½¿ç”¨ç»Ÿä¸€èƒŒæ™¯æ ·å¼ç”Ÿæˆ: {output_path}")
    return output_path


def create_subtitle_image(text, width=1720, height=120, font_size=28, text_color='black', bg_color='rgba(0,0,0,0)'):
    """ä½¿ç”¨PILåˆ›å»ºå­—å¹•å›¾ç‰‡ï¼Œè‡ªåŠ¨é€‚åº”é«˜åº¦"""

    print(f"[å­—å¹•ç”Ÿæˆ] å¼€å§‹åˆ›å»ºå­—å¹•å›¾ç‰‡ï¼Œæ–‡æœ¬: {text[:30]}{'...' if len(text) > 30 else ''}")
    from PIL import Image, ImageDraw, ImageFont
    try:
        font = ImageFont.truetype("msyh.ttc", font_size)
    except:
        try:
            font = ImageFont.truetype("arial.ttf", font_size)
        except:
            font = ImageFont.load_default()

    def split_long_text_for_subtitles(text, max_chars_per_subtitle=50):
        """å°†é•¿æ–‡æœ¬æ™ºèƒ½åˆ†å‰²æˆå¤šä¸ªå­—å¹•ç‰‡æ®µ"""
        if len(text) <= max_chars_per_subtitle:
            return [text]
        # æŒ‰å¥å­åˆ†å‰²
        sentences = re.split(r'([ã€‚ï¼ï¼Ÿï¼›ï¼Œã€])', text)
        subtitle_parts = []
        current_part = ""
        for sentence in sentences:
            if not sentence.strip():
                continue
            test_part = current_part + sentence
            if len(test_part) <= max_chars_per_subtitle:
                current_part = test_part
            else:
                if current_part:
                    subtitle_parts.append(current_part.strip())
                current_part = sentence

        if current_part.strip():
            subtitle_parts.append(current_part.strip())
        return subtitle_parts

    def smart_wrap_text(text, font, max_width, max_lines=2):
        """æ¢è¡Œé€»è¾‘æ”¹è¿›"""
        lines = []

        sample_char_width = ImageDraw.Draw(Image.new('RGB', (1, 1))).textbbox((0, 0), "ä¸­", font=font)[2]
        chars_per_line = int((max_width * 0.9) // sample_char_width)
        total_capacity = chars_per_line * max_lines
        if len(text) > total_capacity:
            truncate_pos = total_capacity - 3 
            punctuation = ['ã€‚', 'ï¼', 'ï¼Ÿ', 'ï¼›', 'ï¼Œ', 'ã€']
            best_cut = truncate_pos

            for i in range(min(len(text), truncate_pos), max(0, truncate_pos - 20), -1):
                if text[i] in punctuation:
                    best_cut = i + 1
                    break
            text = text[:best_cut]

        # æŒ‰æ ‡ç‚¹ç¬¦å·åˆ†å¥
        import re
        sentences = re.split(r'([ã€‚ï¼ï¼Ÿï¼›ï¼Œã€])', text)
        current_line = ""
        for part in sentences:
            if not part.strip():
                continue

            test_line = current_line + part
            bbox = ImageDraw.Draw(Image.new('RGB', (1, 1))).textbbox((0, 0), test_line, font=font)
            line_width = bbox[2] - bbox[0]
            if line_width <= max_width * 0.9 and len(lines) < max_lines:
                current_line = test_line
            else:
                if current_line.strip() and len(lines) < max_lines:
                    lines.append(current_line.strip())
                    current_line = part
                elif len(lines) >= max_lines:
                    break
        if current_line.strip() and len(lines) < max_lines:
            lines.append(current_line.strip())
        final_lines = []
        for line in lines:
            if len(final_lines) >= max_lines:
                break

            bbox = ImageDraw.Draw(Image.new('RGB', (1, 1))).textbbox((0, 0), line, font=font)
            line_width = bbox[2] - bbox[0]
            if line_width <= max_width * 0.9:
                final_lines.append(line)
            else:
                chars = list(line)
                temp_line = ""
                for char in chars:
                    if len(final_lines) >= max_lines:
                        break

                    test_line = temp_line + char
                    bbox = ImageDraw.Draw(Image.new('RGB', (1, 1))).textbbox((0, 0), test_line, font=font)
                    test_width = bbox[2] - bbox[0]

                    if test_width <= max_width * 0.9:
                        temp_line = test_line
                    else:
                        if temp_line and len(final_lines) < max_lines:
                            final_lines.append(temp_line)
                        temp_line = char

                if temp_line and len(final_lines) < max_lines:
                    final_lines.append(temp_line)

        return final_lines[:max_lines] 

    min_font_size = 18
    max_height = 400
    original_font_size = font_size
    lines = []

    while font_size >= min_font_size:
        try:
            if font_size != original_font_size:
                font = ImageFont.truetype("msyh.ttc", font_size)
        except:
            font = ImageFont.load_default()

        lines = smart_wrap_text(text, font, width, max_lines=2)
        line_height = font_size + 8 
        total_text_height = len(lines) * line_height

        all_lines_fit = True
        for line in lines:
            bbox = ImageDraw.Draw(Image.new('RGB', (1, 1))).textbbox((0, 0), line, font=font)
            line_width = bbox[2] - bbox[0]
            if line_width > width * 0.95: 
                all_lines_fit = False
                break

        if total_text_height <= height and all_lines_fit:
            break
        elif total_text_height <= max_height and all_lines_fit:
            height = min(total_text_height + 20, max_height)
            break
        else:
            font_size = int(font_size * 0.9)

    line_height = font_size + 8
    total_text_height = len(lines) * line_height
    actual_height = total_text_height + 16 
    img = Image.new('RGBA', (width, actual_height), bg_color)
    draw = ImageDraw.Draw(img)
    y_start = 8
    for i, line in enumerate(lines):
        if not line.strip():
            continue

        bbox = draw.textbbox((0, 0), line, font=font)
        text_width = bbox[2] - bbox[0]
        x = max(0, (width - text_width) // 2) 
        y = y_start + i * line_height

        if y + line_height <= actual_height and x >= 0 and x + text_width <= width:
            draw.text((x, y), line, fill=text_color, font=font)
    print(f"[å­—å¹•ç”Ÿæˆ] å­—å¹•å›¾ç‰‡åˆ›å»ºå®Œæˆï¼Œå°ºå¯¸: {width}x{actual_height}")
    return img, actual_height


def split_content_into_lines(text, max_chars_per_line = 20, max_lines = 4):
    import re

    text = re.sub(r'([ï¼Œã€‚ï¼›ï¼ï¼Ÿã€])', r'\1\n', text)
    fragments = [f.strip() for f in text.split('\n') if f.strip()]
    lines = []
    current_line = ""

    for fragment in fragments:
        if len(fragment) > max_chars_per_line:
            words = list(fragment) 
            temp_line = current_line

            for char in words:
                if len(temp_line + char) <= max_chars_per_line:
                    temp_line += char
                else:
                    if temp_line:
                        lines.append(temp_line)
                        temp_line = char

                    if len(lines) >= max_lines - 1:
                        break
            current_line = temp_line

        else:
            test_line = current_line + fragment if not current_line else current_line + fragment
            if len(test_line) <= max_chars_per_line:
                current_line = test_line
            else:
                if current_line:
                    lines.append(current_line)
                current_line = fragment

                if len(lines) >= max_lines - 1:
                    break

    if current_line and len(lines) < max_lines:
        lines.append(current_line)

    if len(lines) > max_lines:
        last_lines = lines[max_lines-1:]
        combined_last = ''.join(last_lines)

        if len(combined_last) > max_chars_per_line * 1.5:
            combined_last = combined_last[:int(max_chars_per_line * 1.5)] + "..."
        lines = lines[:max_lines-1] + [combined_last]

    return lines[:max_lines] 


def create_bilingual_subtitle_image(zh_text, en_text = "", width = 1720, height = 120):
    """
    åˆ›å»ºåŒè¯­å­—å¹•
    """

    try:
        import tempfile
        from PIL import Image, ImageDraw, ImageFont

        zh_font_size = 32  
        en_font_size = 22  
        zh_en_gap = 6     

        try:
            zh_font = ImageFont.truetype("msyh.ttc", zh_font_size)
            en_font = ImageFont.truetype("arial.ttf", en_font_size)
        except:
            zh_font = ImageFont.load_default()
            en_font = ImageFont.load_default()
        # ç”Ÿæˆä¸­æ–‡å­—å¹•
        zh_img, zh_height = create_subtitle_image(zh_text, width, height, zh_font_size, 'black')

        # ç”Ÿæˆè‹±æ–‡å­—å¹•
        if en_text.strip():
            en_img, en_height = create_subtitle_image(en_text, width, height, en_font_size, 'gray')
            total_height = zh_height + en_height + zh_en_gap

            combined_img = Image.new('RGBA', (width, total_height), (0, 0, 0, 0))
            combined_img.paste(zh_img, (0, 0), zh_img)
            combined_img.paste(en_img, (0, zh_height + zh_en_gap), en_img)
            final_img = combined_img
            final_height = total_height
        else:
            final_img = zh_img
            final_height = zh_height

        temp_path = os.path.join(tempfile.gettempdir(), f'subtitle_{uuid.uuid4()}.png')
        final_img.save(temp_path)
        print(f"[å­—å¹•ç”Ÿæˆ] åŒè¯­å­—å¹•å›¾ç‰‡å·²ä¿å­˜åˆ°: {temp_path}")
        return temp_path, final_height
    except Exception as e:
        print(f"å­—å¹•ç”Ÿæˆå¤±è´¥: {e}")
        try:
            import tempfile
            from PIL import Image, ImageDraw, ImageFont
            img = Image.new('RGBA', (width, 100), (0, 0, 0, 0))
            draw = ImageDraw.Draw(img)
            font = ImageFont.load_default()
            draw.text((50, 30), zh_text[:50], fill=(255, 255, 255), font=font)
            temp_path = os.path.join(tempfile.gettempdir(), f'subtitle_fallback_{uuid.uuid4()}.png')
            img.save(temp_path)
            print(f"[å­—å¹•ç”Ÿæˆ] å›é€€å­—å¹•å›¾ç‰‡å·²ä¿å­˜åˆ°: {temp_path}")
            return temp_path, 100
        except:
            return "", 100


def add_background_music(video_path, output_path, music_volume = 0.1):
    """
    ä¸ºè§†é¢‘æ·»åŠ èƒŒæ™¯éŸ³ä¹
    """

    try:
        from moviepy.editor import VideoFileClip, AudioFileClip, CompositeAudioClip
        import moviepy.audio.fx.all as afx

        video = VideoFileClip(video_path)
        bg_music_path = os.path.join(os.path.dirname(__file__), "asset", "bg_audio.mp3")
        if os.path.exists(bg_music_path):
            bg_music = AudioFileClip(bg_music_path)
            if bg_music.duration < video.duration:
                bg_music = afx.audio_loop(bg_music, duration=video.duration)
            else:
                bg_music = bg_music.subclip(0, video.duration)
            bg_music = bg_music.volumex(music_volume)

            if video.audio:
                final_audio = CompositeAudioClip([video.audio, bg_music])
            else:
                final_audio = bg_music
            final_video = video.set_audio(final_audio)
        else:
            print("æœªæ‰¾åˆ°èƒŒæ™¯éŸ³ä¹æ–‡ä»¶ï¼Œè·³è¿‡èƒŒæ™¯éŸ³ä¹")
            final_video = video

        final_video.write_videofile(
            output_path,
            codec="libx264",
            audio_codec="aac",
            fps=24,
            verbose=False,
            logger=None,
            audio_bitrate="192k"
        )

        print(f"èƒŒæ™¯éŸ³ä¹åˆæˆå®Œæˆ: {output_path}")
        return output_path
    except Exception as e:
        print(f"èƒŒæ™¯éŸ³ä¹åˆæˆå¤±è´¥: {e}")
        try:
            shutil.copy2(video_path, output_path)
            return output_path
        except:
            return video_path


def split_text_by_punctuation(text):
    """
    ä½¿ç”¨LLMæ™ºèƒ½åˆ†å¥
    """

    text = re.sub(r'\s+', ' ', text).strip()
    prompt = f"""è¯·å°†ä»¥ä¸‹æ–‡æœ¬æ™ºèƒ½åˆ†å¥ï¼Œç¡®ä¿ï¼š
1. æ¯ä¸ªå¥å­è¯­ä¹‰å®Œæ•´ï¼Œä¸ç ´åé€»è¾‘
2. æ ‡ç‚¹ç¬¦å·ä¿æŒåœ¨å¥å­æœ«å°¾ï¼Œä¸è¦åˆ†ç¦»  
3. æ¯å¥é•¿åº¦é€‚ä¸­ï¼šè‡³å°‘10-15ä¸ªå­—ï¼Œæœ€å¤š35-40ä¸ªå­—
4. ä¼˜å…ˆåœ¨è‡ªç„¶è¯­ä¹‰è¾¹ç•Œåˆ†å¥ï¼ˆå¦‚ï¼šå› æ­¤ã€æ‰€ä»¥ã€ä½†æ˜¯ã€è€Œä¸”ç­‰è¿æ¥è¯å‰åï¼‰
5. ä¿æŒåŸæ–‡æ„æ€ä¸å˜

æ–‡æœ¬ï¼š{text}

è¯·è¿”å›JSONæ ¼å¼çš„å¥å­åˆ—è¡¨ï¼Œæ ¼å¼ï¼š
{{"sentences": ["å¥å­1", "å¥å­2", "å¥å­3"]}}"""

    try:
        response = modai_model_request(prompt, max_tokens=1024, temperature=0.1)
        
        # å¦‚æœresponseä¸ºç©ºï¼Œç›´æ¥ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼å¤„ç†
        if not response or not response.strip():
            print("LLMè¿”å›ç©ºå“åº”ï¼Œä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼å¤„ç†...")
            raise Exception("Empty response from LLM")
        
        import json
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«æ¨ç†è¿‡ç¨‹è€ŒéJSONç­”æ¡ˆ
        if "æˆ‘éœ€è¦å°†ç»™å®šçš„æ–‡æœ¬æ™ºèƒ½åˆ†å¥" in response and '{"sentences"' not in response:
            print("æ£€æµ‹åˆ°æ¨ç†è¿‡ç¨‹å“åº”ï¼Œå°è¯•æå–JSONéƒ¨åˆ†...")
            # æŸ¥æ‰¾æ˜¯å¦æœ‰éšè—çš„JSONéƒ¨åˆ†
            json_match = re.search(r'\{[^}]*"sentences"[^}]*\}', response, re.DOTALL)
            if json_match:
                response = json_match.group(0)
                print(f"æ‰¾åˆ°JSONç‰‡æ®µ: {response[:100]}...")
            else:
                print("æœªæ‰¾åˆ°æœ‰æ•ˆJSONï¼Œä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼å¤„ç†...")
                raise Exception("No valid JSON found in reasoning response")
        
        if '```json' in response:
            response = response.split('```json')[1].split('```')[0]
        elif '```' in response:
            response = response.split('```')[1].split('```')[0]

        response = response.strip()
        if not response.startswith('{'):
            start_idx = response.find('{')
            if start_idx != -1:
                response = response[start_idx:]

        if not response.endswith('}'):
            end_idx = response.rfind('}')
            if end_idx != -1:
                response = response[:end_idx+1]

        quote_count = response.count('"')
        if quote_count % 2 != 0:
            last_quote_pos = response.rfind('"')
            for i in range(last_quote_pos + 1, len(response)):
                if response[i] in [',', '}', ']']:
                    response = response[:i] + '"' + response[i:]
                    break
        
        # ä½¿ç”¨æœ¬åœ°çš„JSONè§£æå‡½æ•°
        def extract_json_with_fallback(text, default_value):
            try:
                # å°è¯•ä»markdownä»£ç å—ä¸­æå–JSON
                json_match = re.search(r'```json\s*(\{.*?\})\s*```', text, re.DOTALL)
                if json_match:
                    json_str = json_match.group(1)
                else:
                    json_str = text.strip()
                return json.loads(json_str)
            except (json.JSONDecodeError, AttributeError, TypeError) as e:
                print(f"JSONè§£æå¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å€¼: {e}")
                return default_value
        result = extract_json_with_fallback(response, {'sentences': []})
        
        # å¤„ç†ä¸åŒçš„è¿”å›ç±»å‹
        if isinstance(result, dict):
            sentences = result.get('sentences', [])
        elif isinstance(result, list):
            # å¦‚æœè¿”å›çš„æ˜¯åˆ—è¡¨ï¼Œç›´æ¥ä½¿ç”¨
            sentences = result
        else:
            sentences = []
        
        segments = []
        for sentence in sentences:
            sentence = str(sentence).strip()
            if len(sentence) > 3: 
                segments.append({
                    'type': 'text',
                    'content': sentence
                })
        
        segments = []
        for sentence in sentences:
            sentence = str(sentence).strip()
            if len(sentence) > 3: 
                segments.append({
                    'type': 'text',
                    'content': sentence
                })

        if not segments:
            raise Exception("LLMåˆ†å¥è¿”å›ä¸ºç©º")
        print(f"LLMæ™ºèƒ½åˆ†å¥æˆåŠŸï¼Œå…±åˆ†å‡º {len(segments)} ä¸ªå¥å­")
        return segments
        
    except Exception as e:
        print(f"LLMè¿”å›æ ¼å¼é”™è¯¯: {e}")
        print(f"åŸå§‹å“åº”: {response[:200]}...")
        
        try:
            sentences_match = re.search(r'"sentences":\s*\[(.*?)\]', response, re.DOTALL)
            if sentences_match:
                sentences_str = sentences_match.group(1)
                sentences = []
                sentence_matches = re.findall(r'"([^"]*)"', sentences_str)
                for sentence in sentence_matches:
                    if len(sentence.strip()) > 3:
                        sentences.append(sentence.strip())

                if sentences:
                    segments = []
                    for sentence in sentences:
                        segments.append({
                            'type': 'text',
                            'content': sentence
                        })

                    print(f"JSONä¿®å¤æˆåŠŸï¼Œæå–åˆ° {len(segments)} ä¸ªå¥å­")
                    return segments
        except Exception as repair_e:
            print(f"JSONä¿®å¤ä¹Ÿå¤±è´¥: {repair_e}")
    except Exception as e:
        print(f"LLMæ™ºèƒ½åˆ†å¥å¤±è´¥: {e}")

    print("ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼å¤„ç†...")
    sentence_pattern = r'[^ã€‚ï¼ï¼Ÿï¼›â€¦!?]*?[ã€‚ï¼ï¼Ÿï¼›â€¦!?]'
    sentences = re.findall(sentence_pattern, text)

    remaining_text = text
    for sentence in sentences:
        remaining_text = remaining_text.replace(sentence, '', 1)

    if remaining_text.strip():
        sentences.append(remaining_text.strip())

    segments = []
    for sentence in sentences:
        sentence = sentence.strip()
        if len(sentence) > 3: 
            segments.append({
                'type': 'text',
                'content': sentence
            })

    print(f"æ­£åˆ™è¡¨è¾¾å¼åˆ†å¥å®Œæˆï¼Œå…±åˆ†å‡º {len(segments)} ä¸ªå¥å­")
    return segments


def analyze_content_context(content, content_type, surrounding_text= ""):
    """
    åˆ†æå†…å®¹åœ¨æ–‡æ¡ˆä¸­çš„ä¸Šä¸‹æ–‡ï¼Œæå–åŠ¨ç”»è®¾è®¡æç¤º
    """

    context_info = {
        'emphasis_words': [],  
        'explanation_flow': [],  
        'timing_cues': [],  
        'emotional_tone': 'neutral',  
        'complexity_level': 'medium'  
    }

    emphasis_patterns = [
        r'ã€å¼ºè°ƒã€‘(.*?)ã€/å¼ºè°ƒã€‘',
        r'é‡è¦çš„æ˜¯',
        r'å…³é”®åœ¨äº',
        r'ç‰¹åˆ«æ³¨æ„',
        r'æ ¸å¿ƒæ¦‚å¿µ',
        r'æœ€é‡è¦çš„'
    ]

    for pattern in emphasis_patterns:
        matches = re.findall(pattern, surrounding_text, re.IGNORECASE)
        context_info['emphasis_words'].extend(matches)

    flow_patterns = [
        r'é¦–å…ˆ|ç¬¬ä¸€',
        r'ç„¶å|æ¥ç€|å…¶æ¬¡',
        r'æœ€å|æœ€ç»ˆ|æ€»ä¹‹',
        r'ä¾‹å¦‚|æ¯”å¦‚',
        r'å› æ­¤|æ‰€ä»¥'

    ]

    for pattern in flow_patterns:
        if re.search(pattern, surrounding_text):
            context_info['explanation_flow'].append(pattern)

    if len(content) > 100 or 'å¤æ‚' in surrounding_text or 'é«˜çº§' in surrounding_text:
        context_info['complexity_level'] = 'high'
    elif len(content) < 30 or 'ç®€å•' in surrounding_text or 'åŸºç¡€' in surrounding_text:
        context_info['complexity_level'] = 'low'


    if any(word in surrounding_text for word in ['æ¿€åŠ¨', 'å…´å¥‹', 'æƒŠäºº', 'çªç ´']):
        context_info['emotional_tone'] = 'excited'
    elif any(word in surrounding_text for word in ['é‡è¦', 'å…³é”®', 'æ ¸å¿ƒ', 'å¿…é¡»']):
        context_info['emotional_tone'] = 'serious'
    elif any(word in surrounding_text for word in ['ç®€å•', 'å®¹æ˜“', 'è½»æ¾']):
        context_info['emotional_tone'] = 'casual'

    return context_info


def generate_script(topic):
    """
    ç”Ÿæˆç§‘æ™®æ–‡æ¡ˆ
    """

    prompt = f"""ä½ æ˜¯ä¸€ä½èµ„æ·±AIç§‘æ™®ä¸“å®¶ï¼Œç²¾é€šäººå·¥æ™ºèƒ½å„é¢†åŸŸç†è®ºä¸åº”ç”¨ã€‚ä½ çš„èŒè´£æ˜¯ç”¨é€šä¿—æ˜“æ‡‚ã€æƒå¨ä¸”å¹½é»˜é£è¶£çš„æ–¹å¼ï¼Œä¸ºé›¶åŸºç¡€å¤§ä¼—æ™®åŠAIçŸ¥è¯†ï¼Œå¸®åŠ©å¤§å®¶ç†è§£AIåŸç†ã€å‘å±•è¶‹åŠ¿åŠå®é™…åº”ç”¨ã€‚
è¯·ä»¥"{topic}"ä¸ºä¸»é¢˜ï¼Œç”Ÿæˆä¸€ç¯‡é€‚åˆçŸ­è§†é¢‘å£æ’­çš„AIçŸ¥è¯†ç§‘æ™®æ–‡æ¡ˆï¼Œè¦æ±‚å¦‚ä¸‹ï¼š
1. ç»“æ„æ¸…æ™°ï¼ŒåŒ…å«å¼€ç¯‡å¼•å…¥ï¼ˆç”¨è®¾é—®/è¶£å‘³åœºæ™¯/ç”Ÿæ´»åŒ–ä¾‹å­å¸å¼•è§‚ä¼—ï¼‰ã€ä¸»ä½“è®²è§£ï¼ˆç»“åˆAIçœŸå®æ¡ˆä¾‹æˆ–çƒ­ç‚¹åº”ç”¨ï¼‰ã€ç»“å°¾æ€»ç»“ï¼ˆå¿…é¡»æœ‰å®Œæ•´ç»“å°¾ï¼Œä¸è¦ä¸­æ–­ï¼‰ã€‚
2. **æ™ºèƒ½åŠ¨ç”»å…ƒç´ **ï¼ˆå¯é€‰ï¼Œç³»ç»Ÿä¼šè‡ªåŠ¨åˆ¤æ–­åˆé€‚æ—¶æœºä½¿ç”¨ï¼‰ï¼š
   å½“å†…å®¹ç¡®å®éœ€è¦å¯è§†åŒ–æ—¶ï¼Œå¯ä»¥ä½¿ç”¨ä»¥ä¸‹æ ‡è®°ï¼š
   - å…¬å¼ï¼šã€å…¬å¼ã€‘LaTeXå…¬å¼ã€/å…¬å¼ã€‘- ä»…ç”¨äºé‡è¦æ•°å­¦æ¦‚å¿µ
   - ä»£ç ï¼šã€ä»£ç ã€‘ä»£ç å†…å®¹ã€/ä»£ç ã€‘- ä»…ç”¨äºç¼–ç¨‹å®ç°ç¤ºä¾‹  
   - å›¾è¡¨ï¼šã€å›¾è¡¨ã€‘æ•°æ®æè¿°ã€/å›¾è¡¨ã€‘- ä»…ç”¨äºç»Ÿè®¡å¯¹æ¯”
   - å®šä¹‰ï¼šã€å®šä¹‰ã€‘æ ¸å¿ƒæ¦‚å¿µã€/å®šä¹‰ã€‘- ä»…ç”¨äºå…³é”®æœ¯è¯­
   - ä¾‹å­ï¼šã€ä¾‹å­ã€‘ç”ŸåŠ¨å®ä¾‹ã€/ä¾‹å­ã€‘- ä»…ç”¨äºé‡è¦æ¡ˆä¾‹
   - å¼ºè°ƒï¼šã€å¼ºè°ƒã€‘é‡ç‚¹å†…å®¹ã€/å¼ºè°ƒã€‘- ä»…ç”¨äºæ ¸å¿ƒè¦ç‚¹

   **ä½¿ç”¨åŸåˆ™**ï¼š
   - è‡ªç„¶èå…¥ï¼Œä¸å¼ºæ±‚ä½¿ç”¨
   - ç¡®ä¿æ ‡è®°å†…å®¹ç”ŸåŠ¨å½¢è±¡ï¼Œé€‚åˆåŠ¨ç”»å±•ç¤º
   - ä¸€æ®µæ–‡æ¡ˆä¸­1-2ä¸ªå³å¯ï¼Œè¿‡å¤šä¼šåˆ†æ•£æ³¨æ„åŠ›
   - å³ä½¿ä¸ç”¨æ ‡è®°ï¼Œç³»ç»Ÿä¹Ÿä¼šè‡ªåŠ¨è¯†åˆ«å¹¶æ·»åŠ åˆé€‚çš„è§†è§‰æ•ˆæœ
   - æ‰€æœ‰å¯è§†åŒ–æ ‡è®°å¿…é¡»ä½¿ç”¨æˆå¯¹çš„ã€ã€‘...ã€/ã€‘é—­åˆæ ‡ç­¾ï¼Œä¸èƒ½åªå‡ºç°å•ä¸ªã€ã€‘,è€Œæ²¡æœ‰é—­åˆçš„ã€/ã€‘

3. åªè¾“å‡ºä¸€æ®µå®Œæ•´ã€è‡ªç„¶ã€è¿è´¯çš„å£æ’­æ–‡æ¡ˆï¼ŒåƒçœŸäººä¸€å£æ°”è¯´å‡ºæ¥é‚£æ ·ã€‚
4. ä¸¥ç¦è¾“å‡ºä»»ä½•å½¢å¼çš„åˆ†æ®µæ ‡é¢˜ã€ç»“æ„æ€§æç¤ºã€æ ç›®åã€å½©è›‹æç¤ºã€äº’åŠ¨æç¤ºã€P.S.ã€è¡¥å…¨è¯´æ˜ã€AIåŠ©æ‰‹è‡ªè¿°ã€AIèº«ä»½å£°æ˜ã€AIå†™ä½œè¯´æ˜ã€AIè¡¥å…¨è¯´æ˜ã€å¸Œæœ›ä½ å–œæ¬¢ã€æ„Ÿè°¢ã€è‡´è°¢ã€åè®°ã€æ³¨é‡Šã€ä½œè€…æ„Ÿè¨€ã€AIæç¤ºã€AIè¡¥å……ã€AIå¤‡æ³¨ã€AIè¯´æ˜ã€AIæ€»ç»“ã€AIç»“è¯­ã€AIåè®°ã€æ¥ä¸Šæ–‡ã€æœªå®Œå¾…ç»­ã€è½»æ¾äº’åŠ¨ç»“å°¾ã€äº’åŠ¨ç»“å°¾ç­‰å†…å®¹ã€‚
5. å­—æ•°æ§åˆ¶åœ¨800-1500å­—ä¹‹é—´ï¼Œè¯­è¨€æµç•…ï¼Œå†…å®¹è¿è´¯ã€‚
6. **æ ¸å¿ƒé£æ ¼è¦æ±‚**ï¼šç”¨ç”Ÿæ´»åŒ–ã€æ˜“æ‡‚çš„è¯­è¨€ï¼Œç»“åˆç”ŸåŠ¨æ¯”å–»ã€æ¡ˆä¾‹ã€è¶£å‘³äº’åŠ¨ã€è½»æ¾å¹½é»˜ã€é€‚åº¦ç©æ¢—ã€‚æ¯”å¦‚ï¼š
   - ç”¨ç”Ÿæ´»ä¸­çš„ä¾‹å­è§£é‡Šå¤æ‚æ¦‚å¿µï¼ˆå¦‚ç”¨"æ‰¾åœè½¦ä½"è§£é‡Šæœç´¢ç®—æ³•ï¼‰
   - é€‚å½“çš„ç½‘ç»œæµè¡Œè¯­å’Œæ¢—ï¼ˆä½†è¦é€‚åº¦ï¼Œä¸å½±å“ä¸“ä¸šæ€§ï¼‰
   - æœ‰è¶£çš„æ¯”å–»å’Œç±»æ¯”ï¼ˆå¦‚æŠŠç¥ç»ç½‘ç»œæ¯”ä½œ"å¤§è„‘çš„ç”µè·¯æ¿"ï¼‰
   - è½»æ¾çš„äº’åŠ¨æ„Ÿï¼ˆå¦‚"ä½ æœ‰æ²¡æœ‰æƒ³è¿‡..."ã€"å…¶å®å•Š..."ï¼‰
7. é£æ ¼æƒå¨ã€äº²å’Œã€å¯å‘æ€§å¼ºï¼Œæ¿€å‘è§‚ä¼—å…´è¶£ã€‚
8. ç»“å°¾å¿…é¡»å®Œæ•´ï¼Œä¸è¦ä¸­æ–­ã€‚
9. åªè¾“å‡ºæ–‡æ¡ˆæ­£æ–‡ï¼Œä¸è¦ä»»ä½•è¯´æ˜ã€‚

ç¤ºä¾‹é£æ ¼ï¼š
"å“å‘€ï¼Œè¯´åˆ°{topic}ï¼Œä½ ä»¬æœ‰æ²¡æœ‰æƒ³è¿‡è¿™å…¶å®å°±åƒ..."ï¼ˆç”Ÿæ´»åŒ–å¼€å¤´ï¼‰
"è¿™å°±å¥½æ¯”ä½ åœ¨å•†åœºæ‰¾å•æ‰€ï¼ŒAIå°±æ˜¯é‚£ä¸ªè¶…çº§å¯¼èˆª..."ï¼ˆå¹½é»˜æ¯”å–»ï¼‰
"åˆ«çœ‹è¿™ä¸ªã€å…¬å¼ã€‘E=mcÂ²ã€/å…¬å¼ã€‘è¿™ä¹ˆç®€å•ï¼Œå…¶å®å®ƒèƒŒåçš„æ•…äº‹å¯æœ‰æ„æ€äº†..."ï¼ˆè½»æ¾è¿‡æ¸¡ï¼‰

ç°åœ¨è¯·ä¸º"{topic}"ç”Ÿæˆç±»ä¼¼é£æ ¼çš„æ–‡æ¡ˆï¼Œç¡®ä¿è‡ªç„¶æµç•…ã€ç”ŸåŠ¨æœ‰è¶£ï¼"""

    script = modai_model_request(prompt, max_tokens=1200, temperature=0.7)
    script = clean_script_content(script) if script else ""

    # ç»“å°¾æ£€æŸ¥å’Œä¿®å¤
    if script and not script.strip().endswith(("ï¼", "ã€‚", "ï¼Ÿ")):
        fix_prompt = f"""è¯·ä¸ºä»¥ä¸‹AIç§‘æ™®çŸ­è§†é¢‘æ–‡æ¡ˆè¡¥å…¨ä¸€ä¸ªå®Œæ•´ç»“å°¾ï¼Œä¿æŒè½»æ¾å¹½é»˜çš„é£æ ¼ã€‚

åŸæ–‡æ¡ˆï¼š
{script}

è¯·ç›´æ¥è¾“å‡ºè¡¥å…¨çš„ç»“å°¾éƒ¨åˆ†ï¼Œä¸è¦é‡å¤åŸæ–‡ï¼Œä¸è¦åŒ…å«ä»»ä½•æ€è€ƒè¿‡ç¨‹æˆ–è¯´æ˜ï¼š"""
        fix = modai_model_request(fix_prompt, max_tokens=512, temperature=0.5)
        if fix and fix.strip():
            script = script.strip() + " " + fix.strip()
            script = clean_script_content(script)  # å†æ¬¡æ¸…ç†
        else:
            print("ç»“å°¾ä¿®å¤å¤±è´¥ï¼Œä½¿ç”¨åŸæ–‡æ¡ˆ")

    return script.strip() if script else ""


def clean_script_content(text):
    """
    å»é™¤ä¸å½“çš„ç»“æ„æ€§æç¤º
    """
    
    import re
    # å»é™¤æ‰€æœ‰ç»“æ„æ€§æç¤ºè¯ã€P.S.ã€è¡¥å…¨è¯´æ˜ç­‰
    text = re.sub(
        r'(P\.S\.|PS:|è¡¥å…¨åï¼š|å¸Œæœ›ä½ å–œæ¬¢|æ„Ÿè°¢è§‚çœ‹|æ„Ÿè°¢æ”¯æŒ|æ„Ÿè°¢å¤§å®¶|æ„Ÿè°¢æ”¶çœ‹|æ„Ÿè°¢æ‚¨çš„æ”¶çœ‹|æ„Ÿè°¢æ‚¨çš„æ”¯æŒ|æ„Ÿè°¢æ‚¨çš„è§‚çœ‹|æ„Ÿè°¢æ‚¨çš„å…³æ³¨|æ„Ÿè°¢æ‚¨çš„ç‚¹èµ|æ„Ÿè°¢æ‚¨çš„è¯„è®º|æ„Ÿè°¢æ‚¨çš„è½¬å‘|æ„Ÿè°¢æ‚¨çš„åˆ†äº«|æ„Ÿè°¢æ‚¨çš„è®¢é˜…|æ„Ÿè°¢æ‚¨çš„æ”¶è—|å¸Œæœ›ä½ å–œæ¬¢|åè®°|æ³¨é‡Š|ä½œè€…æ„Ÿè¨€|AIæç¤º|AIè¡¥å……|AIå¤‡æ³¨|AIè¯´æ˜|AIæ€»ç»“|AIç»“è¯­|AIåè®°|æ¥ä¸Šæ–‡|æœªå®Œå¾…ç»­|è½»æ¾äº’åŠ¨ç»“å°¾|äº’åŠ¨ç»“å°¾)[^ã€‚ï¼ï¼Ÿ\n]*',
        '', text, flags=re.IGNORECASE)

    text = re.sub(r'[â€¦\.]*[ï¼ˆ(][æ¥ä¸Šæ–‡|æœªå®Œå¾…ç»­|to be continued|continue][ï¼‰)]', '', text, flags=re.IGNORECASE)
    text = re.sub(r'è½»æ¾äº’åŠ¨ç»“å°¾|äº’åŠ¨ç»“å°¾', '', text, flags=re.IGNORECASE)
    text = re.sub(r'\*\*.*?\*\*|__.*?__|`.*?`', '', text)
    sents = re.split(r'(ã€‚|ï¼|ï¼Ÿ|\!|\?|\n)', text)

    sentences = []
    for i in range(0, len(sents) - 1, 2):
        sent = (sents[i] + sents[i + 1]).strip()
        if sent and sent not in sentences:
            sentences.append(sent)

    if len(sents) % 2 == 1 and sents[-1].strip() and sents[-1].strip() not in sentences:
        sentences.append(sents[-1].strip())

    filtered = []
    for s in sentences:
        if not s:
            continue

        s_strip = s.strip().lower()
        if any(key in s_strip for key in
               ["å½©è›‹", "egg", "easter egg", "p.s.", "ps:", "è¡¥å…¨", "å¸Œæœ›ä½ å–œæ¬¢", "æ„Ÿè°¢", "åè®°", "æ³¨é‡Š",
                "ä½œè€…æ„Ÿè¨€", "aiæç¤º", "aiè¡¥å……", "aiå¤‡æ³¨", "aiè¯´æ˜", "aiæ€»ç»“", "aiç»“è¯­", "aiåè®°", 
                "æ¥ä¸Šæ–‡", "æœªå®Œå¾…ç»­", "è½»æ¾äº’åŠ¨ç»“å°¾", "äº’åŠ¨ç»“å°¾"]):
            continue

        if re.search(r'[â€¦\.]*[ï¼ˆ(][æ¥ä¸Šæ–‡|æœªå®Œå¾…ç»­|to be continued|continue][ï¼‰)]', s_strip, flags=re.IGNORECASE):
            continue

        filtered.append(s)
    return ''.join(filtered)


def parse_structured_content(script):
    """
    è§£ææ–‡æ¡ˆä¸­çš„ç»“æ„åŒ–æ ‡è®°
    """

    segments = []
    current_pos = 0

    def fix_markup_issues(text):
        """ä¿®å¤å¤šä½™çš„æ ‡è®°"""
        for tag in ['å…¬å¼', 'ä»£ç ', 'å¼ºè°ƒ', 'ä¾‹å­', 'å®šä¹‰', 'å›¾è¡¨', 'å¯¹æ¯”', 'æ­¥éª¤', 'å®šç†']:
            pattern = fr'ã€{tag}ã€‘([^ã€]*?)ã€/{tag}ã€‘([^ã€]*?)ã€/{tag}ã€‘'
            replacement = fr'ã€{tag}ã€‘\1\2ã€/{tag}ã€‘'
            text = re.sub(pattern, replacement, text)

        def fix_unclosed_tags(text):
            """ä¿®å¤ç¼ºå°‘ç»“æŸæ ‡è®°"""
            tag_types = ['å¼ºè°ƒ', 'å…¬å¼', 'ä»£ç ', 'ä¾‹å­', 'å®šä¹‰', 'å›¾è¡¨', 'å¯¹æ¯”', 'æ­¥éª¤', 'å®šç†']
            for tag_type in tag_types:
                start_pattern = f'ã€{tag_type}ã€‘'
                end_pattern = f'ã€/{tag_type}ã€‘'
                start_matches = list(re.finditer(re.escape(start_pattern), text))
                end_matches = list(re.finditer(re.escape(end_pattern), text))
                if len(start_matches) > len(end_matches):
                    print(f"å‘ç° {len(start_matches) - len(end_matches)} ä¸ªæœªé—­åˆçš„ã€{tag_type}ã€‘æ ‡è®°")
                    used_end_positions = set()
                    for start_match in start_matches:
                        start_pos = start_match.end()
                        found_match = False
                        for end_match in end_matches:
                            end_pos = end_match.start()
                            if end_pos > start_pos and end_pos not in used_end_positions:
                                used_end_positions.add(end_pos)
                                found_match = True
                                break

                        if not found_match:
                            search_start = start_pos
                            insert_pos = len(text)  
                            next_tag_match = re.search(r'ã€', text[search_start:])
                            if next_tag_match:
                                insert_pos = search_start + next_tag_match.start()
                            else:
                                next_punct_match = re.search(r'[ã€‚ï¼ï¼Ÿ]', text[search_start:])
                                if next_punct_match:
                                    insert_pos = search_start + next_punct_match.end()


                            text = text[:insert_pos] + end_pattern + text[insert_pos:]
                            print(f"åœ¨ä½ç½® {insert_pos} æ’å…¥ç¼ºå¤±çš„ã€/{tag_type}ã€‘æ ‡è®°")
                            end_matches = list(re.finditer(re.escape(end_pattern), text))
            
            return text
        text = fix_unclosed_tags(text)
        return text

    script = fix_markup_issues(script)
    print(f"æ ‡è®°æ ¼å¼ä¿®å¤å®Œæˆ")

    patterns = {
        'formula': r'ã€å…¬å¼ã€‘(.*?)ã€/å…¬å¼ã€‘',
        'code': r'ã€ä»£ç ã€‘(.*?)ã€/ä»£ç ã€‘',
        'chart': r'ã€å›¾è¡¨ã€‘(.*?)ã€/å›¾è¡¨ã€‘',
        'definition': r'ã€å®šä¹‰ã€‘(.*?)ã€/å®šä¹‰ã€‘',
        'theorem': r'ã€å®šç†ã€‘(.*?)ã€/å®šç†ã€‘',
        'example': r'ã€ä¾‹å­ã€‘(.*?)ã€/ä¾‹å­ã€‘',
        'emphasis': r'ã€å¼ºè°ƒã€‘(.*?)ã€/å¼ºè°ƒã€‘',
        'comparison': r'ã€å¯¹æ¯”ã€‘(.*?)ã€/å¯¹æ¯”ã€‘',
        'step': r'ã€æ­¥éª¤ã€‘(.*?)ã€/æ­¥éª¤ã€‘',
        'metaphor': r'ã€æ¯”å–»ã€‘([^ã€]*?)(?=ã€|$)',  
        'analogy': r'ã€ç±»æ¯”ã€‘([^ã€]*?)(?=ã€|$)',   
        'note': r'ã€æ³¨æ„ã€‘([^ã€]*?)(?=ã€|$)',      
        'tip': r'ã€æç¤ºã€‘([^ã€]*?)(?=ã€|$)',       
        'key': r'ã€å…³é”®ã€‘([^ã€]*?)(?=ã€|$)',       
    }

    all_matches = []
    for content_type, pattern in patterns.items():
        for match in re.finditer(pattern, script, re.DOTALL):
            all_matches.append({
                'start': match.start(),
                'end': match.end(),
                'type': content_type,
                'content': match.group(1).strip(),
                'full_match': match.group(0)
            })


    all_matches.sort(key=lambda x: x['start'])

    for i, match in enumerate(all_matches):
        if match['start'] > current_pos:
            normal_text = script[current_pos:match['start']].strip()
            if normal_text:
                segments.append({
                    'type': 'text',
                    'content': normal_text
                })

        context_start = max(0, match['start'] - 100)
        context_end = min(len(script), match['end'] + 100)
        surrounding_text = script[context_start:context_end]

        context_info = analyze_content_context(
            match['content'], 
            match['type'], 
            surrounding_text
        )

        segments.append({
            'type': match['type'],
            'content': match['content'],
            'surrounding_text': surrounding_text,
            'context_info': context_info,
            'position_in_script': match['start'] / len(script) 
        })

        current_pos = match['end']
    
    if current_pos < len(script):
        remaining_text = script[current_pos:].strip()
        if remaining_text:
            segments.append({
                'type': 'text',
                'content': remaining_text
            })

    return segments


def generate_manim_code(content, content_type, scene_number, context_info = None, surrounding_text = "", audio_duration = None, main_theme = "",context_segments = None, segment_index = 0, total_segments = None, improvement_prompt = None, existing_code = None):
    """
    æ™ºèƒ½åŠ¨ç”»ç”Ÿæˆå™¨ - ä½¿ç”¨ä¼˜åŒ–çš„è´¨é‡æ§åˆ¶ç³»ç»Ÿ
    """

    class_name = f"Scene{scene_number}"
  
    if not context_info:
        context_info = {
            'emphasis_words': [],
            'explanation_flow': [],
            'timing_cues': [],
            'emotional_tone': 'neutral',
            'complexity_level': 'medium'
        }

    print(f"ç”ŸæˆåŠ¨ç”»ä»£ç  - {content_type}: {class_name}")
    
    # æœ€ä¼˜å…ˆä½¿ç”¨å¹³è¡¡ç©ºé—´çº¦æŸç³»ç»Ÿï¼ˆæ£€æµ‹+LLMä¿®å¤ï¼‰
    if BALANCED_SPATIAL_AVAILABLE:
        print(f"ä½¿ç”¨å¹³è¡¡ç©ºé—´çº¦æŸç³»ç»Ÿï¼ˆå¢å¼ºæ£€æµ‹+å¤šè½®ä¿®å¤æ¨¡å¼ï¼‰...")
        
        # åˆ›å»ºå¹³è¡¡ç©ºé—´ç³»ç»Ÿ
        balanced_system = BalancedSpatialSystem()
        
        # ç”Ÿæˆå¹³è¡¡çš„æç¤ºè¯ï¼ˆé¿å…è¿‡åº¦å·¥ç¨‹åŒ–ï¼‰
        balanced_prompt = balanced_system.generate_balanced_prompt(
            content_type=content_type,
            content=content,
            class_name=class_name,
            audio_duration=audio_duration or 8.0
        )
        
        # è°ƒç”¨LLMç”Ÿæˆåˆå§‹ä»£ç 
        try:
            response = modai_model_request(
                balanced_prompt, 
                model="Qwen/Qwen3-Coder-480B-A35B-Instruct",
                max_tokens=2000,
                temperature=0.7
            )
            
            # æå–ä»£ç 
            if "```python" in response:
                manim_code = response.split("```python")[1].split("```")[0]
            elif "```" in response:
                manim_code = response.split("```")[1].split("```")[0]
            else:
                manim_code = response
            
            # ğŸ” æ™ºèƒ½ä¿®å¤ç­–ç•¥é€‰æ‹©
            initial_analysis = balanced_system.analyze_and_score(manim_code)
            
            print(f"   åˆå§‹ä»£ç åˆ†æ:")
            print(f"   - å¸ƒå±€åˆ†æ•°: {initial_analysis['layout_score']}/100")
            print(f"   - å‘ç°é—®é¢˜: {initial_analysis['issue_count']}ä¸ª")
            
            # æ ¹æ®é—®é¢˜ä¸¥é‡ç¨‹åº¦å†³å®šä¿®å¤ç­–ç•¥
            if initial_analysis['issue_count'] == 0:
                print(f"   [æˆåŠŸ] åˆå§‹ä»£ç å®Œç¾ï¼Œæ— éœ€ä¿®å¤")
                final_code = manim_code
                
            elif initial_analysis['issue_count'] <= 3 and initial_analysis['layout_score'] >= 80:
                print(f"é—®é¢˜è¾ƒå°‘ï¼Œä½¿ç”¨å•è½®ç²¾ç¡®ä¿®å¤")
                
                # å•è½®ä¿®å¤
                fix_prompt = balanced_system.generate_fix_prompt(manim_code, initial_analysis['issues'])
                fix_request = f"""
{fix_prompt}

**åŸå§‹ä»£ç **:
```python
{manim_code}
```

è¯·ç²¾ç¡®ä¿®å¤æ£€æµ‹åˆ°çš„é—®é¢˜ï¼Œç¡®ä¿ä¿æŒåŠ¨ç”»æ•ˆæœçš„ä¸°å¯Œæ€§å’Œåˆ›æ„æ€§ã€‚
"""
                
                fix_response = modai_model_request(
                    fix_request,
                    model="Qwen/Qwen3-Coder-480B-A35B-Instruct",
                    max_tokens=2500,
                    temperature=0.3
                )
                
                # æå–ä¿®å¤åçš„ä»£ç 
                if "```python" in fix_response:
                    fixed_code = fix_response.split("```python")[1].split("```")[0]
                elif "```" in fix_response:
                    fixed_code = fix_response.split("```")[1].split("```")[0]
                else:
                    fixed_code = fix_response
                
                # éªŒè¯ä¿®å¤æ•ˆæœ
                final_analysis = balanced_system.analyze_and_score(fixed_code)
                
                if final_analysis['layout_score'] >= initial_analysis['layout_score']:
                    print(f"   [æˆåŠŸ] å•è½®ä¿®å¤æˆåŠŸ: {initial_analysis['layout_score']} â†’ {final_analysis['layout_score']}")
                    final_code = fixed_code
                else:
                    print(f"   [è­¦å‘Š] å•è½®ä¿®å¤æ•ˆæœä¸ä½³ï¼Œä½¿ç”¨åŸå§‹ä»£ç ")
                    final_code = manim_code
                    
            else:
                print(f"   ğŸ”„ é—®é¢˜è¾ƒå¤šï¼Œå¯ç”¨å¤šè½®ä¿®å¤æœºåˆ¶")
                
                # å¤šè½®ä¿®å¤
                fix_result = balanced_system.multi_round_fix(manim_code, max_rounds=3)
                
                if fix_result['success']:
                    print(f"   [æˆåŠŸ] å¤šè½®ä¿®å¤æˆåŠŸ!")
                    print(f"   - æ€»æ”¹è¿›: +{fix_result['total_improvement']}åˆ†")
                    print(f"   - ä¿®å¤è½®æ•°: {fix_result['total_rounds']}")
                    final_code = fix_result['final_code']
                else:
                    print(f"   [è­¦å‘Š] å¤šè½®ä¿®å¤æœªå®Œå…¨æˆåŠŸï¼Œä½†å·²æœ‰æ”¹è¿›")
                    print(f"   - éƒ¨åˆ†æ”¹è¿›: +{fix_result['total_improvement']}åˆ†")
                    final_code = fix_result['final_code']
            
            # æœ€ç»ˆç®€å•ä¼˜åŒ–
            final_code = balanced_system.optimize_simple_code(final_code)
            
            return final_code
            
        except Exception as e:
            print(f"   å¹³è¡¡ç³»ç»Ÿå¤„ç†å¤±è´¥: {e}")
            # å›é€€åˆ°ç®€å•ä¼˜åŒ–
            try:
                basic_prompt = f"åˆ›å»º{content_type}ç±»å‹çš„ManimåŠ¨ç”»ï¼Œç±»å{class_name}ï¼Œå†…å®¹ï¼š{content}"
                response = modai_model_request(basic_prompt, max_tokens=1500)
                return clean_llm_code_output(response)
            except:
                return create_simple_manim_scene(content_type, content, class_name, "")
    

    

    
    # ä¼˜å…ˆä½¿ç”¨æ–°çš„ä¼˜åŒ–ç³»ç»Ÿ
    if OPTIMIZED_QUALITY_AVAILABLE:
        print(f"[å¯åŠ¨] ä½¿ç”¨ä¼˜åŒ–è´¨é‡æ§åˆ¶ç³»ç»Ÿ...")
        
        prompt_system = OptimizedManimPrompts()
        
        # å¦‚æœæœ‰ç°æœ‰ä»£ç ï¼Œå…ˆè¿›è¡Œåˆ†æ
        if existing_code:
            print(f"ğŸ“‹ åˆ†æç°æœ‰ä»£ç é—®é¢˜...")
            
        # æ„å»ºå†…å®¹æè¿°
        enhanced_content = content
        if improvement_prompt:
            enhanced_content = f"{content}\n\næ”¹è¿›è¦æ±‚ï¼š{improvement_prompt}"
        
        # ç”Ÿæˆä¼˜åŒ–çš„æç¤ºè¯
        generation_prompt = prompt_system.generate_creation_prompt(
            enhanced_content, content_type
        )
        
        # è°ƒç”¨LLMç”Ÿæˆä»£ç 
        enhanced_code = modai_model_request(
            prompt=generation_prompt,
            max_tokens=2048,
            temperature=0.1
        )
        
        if enhanced_code:
            # ä½¿ç”¨è´¨é‡æ§åˆ¶å™¨å¤„ç†ç”Ÿæˆçš„ä»£ç 
            controller = ManimQualityController(max_fix_attempts=2)
            result = controller.process_manim_code(
                enhanced_code, class_name, enhanced_content
            )
            
            # è¾“å‡ºå¤„ç†æ—¥å¿—
            for log_entry in result.processing_log:
                print(log_entry)
            
            if result.success:
                print(f"[å®Œæˆ] ä»£ç ç”Ÿæˆå’Œè´¨é‡æ§åˆ¶å®Œæˆ")
                return result.final_code
            else:
                print(f"[è­¦å‘Š] è´¨é‡æ§åˆ¶éƒ¨åˆ†æˆåŠŸï¼Œä½¿ç”¨å½“å‰æœ€ä½³ç‰ˆæœ¬")
                return result.final_code
                
    # å›é€€åˆ°åŸæœ‰ç³»ç»Ÿ
    elif ENHANCED_PROMPTS_AVAILABLE:
        print(f"ä½¿ç”¨å¢å¼ºæç¤ºè¯ç³»ç»Ÿï¼ˆå›é€€æ¨¡å¼ï¼‰...")
        prompt_system = EnhancedManimPromptSystem()
        
        # å¦‚æœæœ‰æ”¹è¿›æç¤ºï¼Œå°†å…¶æ·»åŠ åˆ°å†…å®¹ä¸­
        enhanced_content = content
        if improvement_prompt:
            enhanced_content = f"{content}\n\n{improvement_prompt}"
        
        # ä¼ é€’ç°æœ‰ä»£ç ç”¨äºå¸ƒå±€åˆ†æ
        system_prompt, user_prompt = prompt_system.create_enhanced_prompt(
            content=enhanced_content,
            content_type=content_type,
            context_segments=context_segments,
            main_theme=main_theme,
            audio_duration=audio_duration,
            existing_code=existing_code  # æ–°å¢ï¼šä¼ é€’ç°æœ‰ä»£ç 
        )
        
        enhanced_code = modai_model_request(
            prompt=user_prompt,
            system_prompt=system_prompt,
            model="Qwen/Qwen3-Coder-480B-A35B-Instruct",
            max_tokens=2000,
            temperature=0.3, 
            role="assistant"
        )
        
        if enhanced_code:
            # æ¸…ç†LLMè¾“å‡ºçš„æ ¼å¼é—®é¢˜
            enhanced_code = clean_llm_code_output(enhanced_code)
            
            validation = prompt_system.validate_generated_code(enhanced_code, content_type)
            print(f"ä»£ç è´¨é‡å¾—åˆ†: {validation['validation_score']}/100")
            
            if validation['validation_score'] >= 70:
                print(f"å¢å¼ºæç¤ºè¯ç”ŸæˆæˆåŠŸ")
                return enhanced_code
            else:
                print(f"ä»£ç è´¨é‡è¾ƒä½ï¼Œå›é€€åˆ°ä¼ ç»Ÿæ–¹æ³•")
                for issue in validation['issues']:
                    print(f"- {issue}")
    
    if context_segments and total_segments and main_theme:
        print(f"å¯åŠ¨æ™ºèƒ½åˆ†æç³»ç»Ÿ...")
        optimization_data = optimize_animation(
            segment_content=content,
            segment_type=content_type,
            main_theme=main_theme,
            context_segments=context_segments,
            total_segments=total_segments,
            segment_index=segment_index
        )

        if "error" not in optimization_data:
            optimized_script, enhanced_code = enhanced_script_and_animation_generator(
                original_content=content,
                content_type=content_type, 
                main_theme=main_theme,
                optimization_data=optimization_data,
                class_name=class_name
            )

            if enhanced_code:
                print(f"æ™ºèƒ½ä¼˜åŒ–åŠ¨ç”»ç”Ÿæˆå®Œæˆ")
                return enhanced_code
            else:
                print(f"æ™ºèƒ½ä¼˜åŒ–å¤±è´¥ï¼Œä½¿ç”¨å¢å¼ºç‰ˆç”Ÿæˆå™¨")
        else:
            print(f"æ™ºèƒ½åˆ†æå¤±è´¥ï¼Œä½¿ç”¨å¢å¼ºç‰ˆç”Ÿæˆå™¨: {optimization_data['error']}")

    print(f"ä½¿ç”¨å¢å¼ºç‰ˆåŠ¨ç”»ç”Ÿæˆå™¨...")
    total_duration = audio_duration or 8.0
    return enhanced_generate_manim_code(content_type, content, class_name, surrounding_text, total_duration, context_info)


def render_manim_scene(code, scene_name, output_dir, content_type = None, content = None, max_retries = 10):
    """
    æ¸²æŸ“Manimåœºæ™¯å¹¶ç”Ÿæˆé€æ˜MOVè§†é¢‘ - é›†æˆé¢„å¤„ç†å’Œè´¨é‡æ§åˆ¶
    """
    import os
    import subprocess
    import tempfile
    import shutil
    import re

    # æ­¥éª¤1: é¢„å¤„ç†ä»£ç 
    current_code = code
    
    # æœ€ä¼˜å…ˆä½¿ç”¨å¹³è¡¡ç©ºé—´çº¦æŸç³»ç»Ÿè¿›è¡Œé¢„å¤„ç†ï¼ˆç®€æ´æœ‰æ•ˆï¼‰
    if BALANCED_SPATIAL_AVAILABLE:
        print(f"å¹³è¡¡ç©ºé—´çº¦æŸç³»ç»Ÿé¢„å¤„ç†...")
        try:
            # åˆ›å»ºå¹³è¡¡ç³»ç»Ÿ
            balanced_system = BalancedSpatialSystem()
            
            # åˆ†æä»£ç è´¨é‡
            analysis = balanced_system.analyze_and_score(code)
            
            print(f"å¸ƒå±€è´¨é‡åˆ†æ:")
            print(f"   - å…ƒç´ æ•°é‡: {analysis['element_count']}")
            print(f"   - é—´è·é—®é¢˜: {analysis['spacing_issues']}")
            print(f"   - å¸ƒå±€åˆ†æ•°: {analysis['layout_score']}")
            print(f"   - è¿‡åº¦å·¥ç¨‹åŒ–: {'æ˜¯' if analysis['is_over_engineered'] else 'å¦'}")
            
            # å¦‚æœéœ€è¦ä¼˜åŒ–ï¼Œè¿›è¡Œç®€å•ä¼˜åŒ–
            if analysis['layout_score'] < 80 or analysis['spacing_issues'] > 0:
                print(f"å¯åŠ¨ç®€å•ä¼˜åŒ–...")
                optimized_code = balanced_system.optimize_simple_code(code)
                
                # é‡æ–°åˆ†æ
                new_analysis = balanced_system.analyze_and_score(optimized_code)
                improvement = new_analysis['layout_score'] - analysis['layout_score']
                
                if improvement > 0:
                    current_code = optimized_code
                    print(f"[æˆåŠŸ] ç®€å•ä¼˜åŒ–å®Œæˆï¼Œè´¨é‡æå‡: +{improvement}")
                else:
                    print(f"ä¿æŒåŸå§‹ä»£ç ")
            else:
                print(f"[ä¿¡æ¯] ä»£ç è´¨é‡è‰¯å¥½ï¼Œæ— éœ€ä¼˜åŒ–")
                
        except Exception as e:
            print(f"å¹³è¡¡ç©ºé—´çº¦æŸç³»ç»Ÿé¢„å¤„ç†å¤±è´¥: {e}")
    

    

    
    # ä½¿ç”¨åŸä»£ç è¿›è¡Œç®€å•æ¸…ç†
    else:
        # åŸæœ‰çš„ç®€å•æ¸…ç†
        if isinstance(code, bytes):
            current_code = code.decode('utf-8', errors='ignore')
        else:
            current_code = code
        
        # æ¸…ç†LLMç”Ÿæˆçš„Markdownæ ¼å¼æ ‡è®°
        current_code = clean_llm_code_output(current_code)

    os.makedirs(output_dir, exist_ok=True)

    for attempt in range(max_retries + 1):
        print(f"å°è¯•æ¸²æŸ“ (ç¬¬ {attempt + 1}/{max_retries + 1} æ¬¡)...")
        code_file = os.path.join(output_dir, f"{scene_name}_attempt_{attempt}.py")

        try:
            # ç¡®ä¿ç¼–ç è®¾ç½®
            encoding_header = '''# -*- coding: utf-8 -*-

import sys
import os

# å¼ºåˆ¶è®¾ç½®ç¼–ç ä¸ºUTF-8ï¼Œè§£å†³ä¸­æ–‡æ¸²æŸ“é—®é¢˜

if hasattr(sys, 'setdefaultencoding'):
    sys.setdefaultencoding('utf-8')

os.environ['PYTHONIOENCODING'] = 'utf-8'

'''
            if '# -*- coding: utf-8 -*-' not in current_code:
                current_code = encoding_header + current_code
            elif 'PYTHONIOENCODING' not in current_code:
                current_code = current_code.replace(
                    '# -*- coding: utf-8 -*-\n',
                    encoding_header
                )


            with open(code_file, 'w', encoding='utf-8') as f:
                f.write(current_code)
            if '# -*- coding: utf-8 -*-' not in current_code:
                current_code = encoding_header + current_code
            elif 'PYTHONIOENCODING' not in current_code:
                current_code = current_code.replace(
                    '# -*- coding: utf-8 -*-\n',
                    encoding_header
                )


            with open(code_file, 'w', encoding='utf-8') as f:
                f.write(current_code)
        except UnicodeEncodeError:
            clean_code = current_code.encode('ascii', errors='ignore').decode('ascii')
            clean_code = '# -*- coding: utf-8 -*-\n' + clean_code
            with open(code_file, 'w', encoding='utf-8') as f:
                f.write(clean_code)


        output_path = os.path.join(output_dir, f"{scene_name}.mov")

        try:
            class_match = re.search(r'class\s+(\w+)\s*\(Scene\)', current_code)
            actual_scene_name = class_match.group(1) if class_match else scene_name


            with tempfile.TemporaryDirectory() as temp_dir:
                temp_code_file = os.path.join(temp_dir, f"{scene_name}_temp.py")
                shutil.copy2(code_file, temp_code_file)
                print(f"æ¸²æŸ“åœºæ™¯: {actual_scene_name}")
                env = os.environ.copy()
                env['PYTHONWARNINGS'] = 'ignore'
                env['MANIM_DISABLE_OPENCACHING'] = '1' 
                env['PYTHONIOENCODING'] = 'utf-8'
                env['LANG'] = 'zh_CN.UTF-8' 
                env['LC_ALL'] = 'zh_CN.UTF-8' 


                cmd = [
                    "manim",
                    "render",  
                    "-ql",     
                    "--transparent",  
                    "--format=mov",   
                    "--resolution=1280,720",  
                    "--disable_caching", 
                    os.path.basename(temp_code_file),
                    actual_scene_name 

                ]

                result = subprocess.run(
                    cmd, 
                    cwd=temp_dir, 
                    capture_output=True, 
                    text=True, 
                    encoding='utf-8',
                    errors='ignore',
                    timeout=300,
                    env=env 
                )

                print(f"è¿”å›ç : {result.returncode}")

                output_text = (result.stdout or "") + (result.stderr or "")

                warnings_to_ignore = [
                    "pkg_resources is deprecated",
                    "UserWarning",
                    "DeprecationWarning",
                    "FutureWarning",
                    "manim_voiceover"
                ]

                is_only_warning = False
                if result.returncode == 1:
                    has_real_error = False
                    has_warning = False
                    
                    for warning in warnings_to_ignore:
                        if warning in output_text:
                            has_warning = True


                    real_error_indicators = [
                        "SyntaxError",
                        "NameError", 
                        "ImportError",
                        "AttributeError",
                        "TypeError",
                        "ValueError",
                        "ModuleNotFoundError",
                        "Traceback",
                        "Error:",
                        "Failed to render"
                    ]

                    for error_indicator in real_error_indicators:
                        if error_indicator in output_text:
                            has_real_error = True
                            break

                    if has_warning and not has_real_error:
                        is_only_warning = True
                        print(f"æ£€æµ‹åˆ°è­¦å‘Šä½†å¯èƒ½æ¸²æŸ“æˆåŠŸï¼Œæ£€æŸ¥è¾“å‡ºæ–‡ä»¶...")

                temp_media_dir = os.path.join(temp_dir, "media", "videos")
                if os.path.exists(temp_media_dir):
                    for root, dirs, files in os.walk(temp_media_dir):
                        for file in files:
                            if file == f"{actual_scene_name}.mov":
                                found_file = os.path.join(root, file)
                                print(f"åœ¨ä¸´æ—¶ç›®å½•æ‰¾åˆ°æ–‡ä»¶: {found_file}")
                                shutil.copy2(found_file, output_path)
                                print(f"æˆåŠŸç”Ÿæˆé€æ˜è§†é¢‘: {output_path}")
                                if verify_and_fix_mov_file(output_path):
                                    print(f"MOVæ–‡ä»¶éªŒè¯é€šè¿‡")
                                else:
                                    print(f"MOVæ–‡ä»¶éªŒè¯å¤±è´¥ï¼Œå°è¯•è½¬æ¢...")
                                    fixed_path = convert_mov_to_compatible(output_path)
                                    if fixed_path:
                                        output_path = fixed_path
                                        print(f"MOVæ–‡ä»¶å·²ä¿®å¤: {fixed_path}")

                                scaled_path = scale_video_to_fit(output_path, target_size=(1280, 720))
                                if scaled_path and scaled_path != output_path:
                                    print(f"è§†é¢‘å·²ç¼©æ”¾ä»¥é€‚åº”å±å¹•: {scaled_path}")
                                    return scaled_path

                                return output_path

                success_indicators = [
                    "File ready at" in output_text,
                    "Rendered" in output_text,
                    "INFO     Previewed File at:" in output_text,
                    "Combining to Movie file" in output_text
                ]

                if any(success_indicators) or (is_only_warning and result.returncode == 1):
                    print(f"ManimæŠ¥å‘ŠæˆåŠŸä½†æœªæ‰¾åˆ°é¢„æœŸMOVæ–‡ä»¶ï¼Œæ‰©å¤§æœç´¢èŒƒå›´...")
                    search_dirs = [temp_media_dir]
                    if os.path.exists(temp_dir):
                        for root, dirs, files in os.walk(temp_dir):
                            search_dirs.extend([os.path.join(root, d) for d in dirs])

                    found_file = None
                    for search_dir in set(search_dirs):
                        if not os.path.exists(search_dir):
                            continue
                        print(f"æœç´¢ç›®å½•: {search_dir}")

                        for root, dirs, files in os.walk(search_dir):
                            # æŸ¥æ‰¾æ‰€æœ‰.movæ–‡ä»¶
                            mov_files = [f for f in files if f.endswith('.mov')]
                            if mov_files:
                                latest_file = max(mov_files, 
                                    key=lambda f: os.path.getmtime(os.path.join(root, f)))
                                found_file = os.path.join(root, latest_file)
                                print(f"æ‰¾åˆ°MOVæ–‡ä»¶: {found_file}")
                                break

                        if found_file:
                            break

                    if found_file and os.path.exists(found_file):
                        try:
                            shutil.copy2(found_file, output_path)
                            print(f"æˆåŠŸå¤åˆ¶MOVæ–‡ä»¶: {output_path}")
                            return output_path
                        except Exception as copy_err:
                            print(f"å¤åˆ¶æ–‡ä»¶å¤±è´¥: {copy_err}")
                    else:
                        print(f"åœ¨æ‰€æœ‰æœç´¢ç›®å½•ä¸­éƒ½æœªæ‰¾åˆ°æœ‰æ•ˆçš„MOVæ–‡ä»¶")

                if result.returncode != 0 and not is_only_warning:
                    raise subprocess.CalledProcessError(result.returncode, cmd, result.stdout, result.stderr)

        except subprocess.CalledProcessError as e:
            error_msg = ""
            try:
                if e.stderr:
                    error_msg = e.stderr
                elif e.stdout:
                    error_msg = e.stdout
                else:
                    error_msg = str(e)
            except UnicodeDecodeError:
                error_msg = "ç¼–ç é”™è¯¯ï¼Œæ— æ³•æ˜¾ç¤ºè¯¦ç»†é”™è¯¯ä¿¡æ¯"
            print(f"ç¬¬ {attempt + 1} æ¬¡æ¸²æŸ“å¤±è´¥: {error_msg[:200]}...")

            # ä½¿ç”¨LLMä¿®å¤é”™è¯¯
            if attempt < max_retries and content_type and content:
                print(f"å°è¯•ä½¿ç”¨LLMä¿®å¤é”™è¯¯...")
                fixed_code = fix_manim_error_with_llm(
                    current_code, 
                    error_msg, 
                    content_type, 
                    scene_name
                )

                if fixed_code:
                    current_code = fixed_code
                    print(f"ä»£ç å·²ä¿®å¤ï¼Œå‡†å¤‡é‡è¯•...")
                    continue
                else:
                    print(f"LLMä¿®å¤å¤±è´¥")

            if attempt == max_retries:
                print(f"æ‰€æœ‰æ¸²æŸ“å°è¯•å‡å¤±è´¥")
                return None

        except Exception as e:
            print(f"ç¬¬ {attempt + 1} æ¬¡æ¸²æŸ“è¿‡ç¨‹å‡ºé”™: {e}")
            if attempt == max_retries:
                return None
    return None


def scale_video_to_fit(video_path, target_size = (1280, 720)):
    """
    ç¼©æ”¾è§†é¢‘ä»¥ç¡®ä¿å†…å®¹é€‚åˆç›®æ ‡å°ºå¯¸ï¼Œé¿å…å†…å®¹è¶…å‡ºå±å¹•è¾¹ç•Œ
    """

    try:
        from moviepy.editor import VideoFileClip
        import os
        
        if not os.path.exists(video_path):
            return video_path

        print(f"æ£€æŸ¥è§†é¢‘å°ºå¯¸: {video_path}")
        clip = VideoFileClip(video_path)
        original_size = clip.size
        print(f"åŸå§‹å°ºå¯¸: {original_size}")

        target_width, target_height = target_size
        original_width, original_height = original_size

        scale_x = target_width / original_width
        scale_y = target_height / original_height
        scale_factor = min(scale_x, scale_y, 1.0)  

        if scale_factor < 0.95:  
            print(f"éœ€è¦ç¼©æ”¾ï¼Œç¼©æ”¾æ¯”ä¾‹: {scale_factor:.2f}")
            scaled_clip = clip.resize(scale_factor)

            base_path, ext = os.path.splitext(video_path)
            scaled_path = f"{base_path}_scaled{ext}"
            scaled_clip.write_videofile(
                scaled_path,
                codec='libx264',
                audio_codec='aac' if scaled_clip.audio else None,
                fps=24,
                verbose=False,
                logger=None
            )

            clip.close()
            scaled_clip.close()
            print(f"è§†é¢‘ç¼©æ”¾å®Œæˆ: {scaled_path}")
            return scaled_path
        else:
            print(f"è§†é¢‘å°ºå¯¸åˆé€‚ï¼Œæ— éœ€ç¼©æ”¾")
            clip.close()
            return video_path
    except Exception as e:
        print(f"è§†é¢‘ç¼©æ”¾å¤±è´¥: {e}")
        return video_path


def verify_and_fix_mov_file(mov_path):
    """
    éªŒè¯MOVæ–‡ä»¶æ˜¯å¦èƒ½è¢«æ­£ç¡®è¯»å–
    """

    try:
        from moviepy.editor import VideoFileClip

        clip = VideoFileClip(mov_path)
        frame = clip.get_frame(0) 
        clip.close()

        if frame is not None:
            return True
        else:
            return False
    except Exception as e:
        print(f"MOVéªŒè¯å¤±è´¥: {e}")
        return False


def convert_mov_to_compatible(mov_path):
    """
    å°†æœ‰é—®é¢˜çš„MOVæ–‡ä»¶è½¬æ¢ä¸ºå…¼å®¹æ ¼å¼
    """

    try:

        from moviepy.editor import VideoFileClip
        import os

        base_path, ext = os.path.splitext(mov_path)
        fixed_path = f"{base_path}_fixed.mov"

        clip = VideoFileClip(mov_path)

        clip.write_videofile(
            fixed_path,
            codec='libx264',
            audio_codec='aac' if clip.audio else None,
            fps=24,
            verbose=False,
            logger=None,
            ffmpeg_params=['-pix_fmt', 'yuva420p'] 
        )

        clip.close()
        if verify_and_fix_mov_file(fixed_path):
            return fixed_path
        else:
            return None
    except Exception as e:
        print(f"MOVä¿®å¤å¤±è´¥: {e}")
        return None


def create_simple_manim_scene(content_type, content, scene_name, output_dir):
    """
    ç®€å•çš„å›é€€åœºæ™¯
    """

    import tempfile
    import shutil

    os.makedirs(output_dir, exist_ok=True)  
    if content_type == 'formula':
        formula_text = content.replace('\\', '').replace('{', '').replace('}', '') 
        simple_code = f'''from manim import *

class {scene_name}(Scene):
    def construct(self):
        try:
            # ä¼˜å…ˆå°è¯•Textæ˜¾ç¤ºï¼Œé¿å…LaTeXé—®é¢˜
            formula = Text(r"{formula_text}", font_size=36, color=BLUE)
            formula.move_to(ORIGIN)

            # å¦‚æœå†…å®¹çœ‹èµ·æ¥åƒæ•°å­¦å…¬å¼ï¼Œå°è¯•MathTex
            if any(char in r"{content}" for char in ['=', '+', '-', '*', '/', '^', '_']):
                try:
                    math_formula = MathTex(r"{content}")
                    math_formula.scale(1.2)
                    formula = math_formula
                except:
                    pass  # å¦‚æœMathTexå¤±è´¥ï¼Œç»§ç»­ä½¿ç”¨Text

            # åˆ†é˜¶æ®µå±•ç¤ºï¼šå‡ºç° â†’ å®Œæ•´å±•ç¤º â†’ åœç•™
            self.play(Write(formula), run_time=2)
            self.wait(4)  # å……åˆ†æ—¶é—´ç†è§£å…¬å¼
            self.play(Indicate(formula, color=YELLOW), run_time=1)  # å¼ºè°ƒ
            self.wait(2)  # ç»§ç»­åœç•™
            self.play(FadeOut(formula), run_time=1)
        except Exception as e:
            # æ”¹è¿›çš„é”™è¯¯å›é€€
            print(f"å…¬å¼æ¸²æŸ“é”™è¯¯: {{e}}")
            text = Text("æ•°å­¦å…¬å¼å±•ç¤º", font_size=28, color=BLUE)
            text.move_to(ORIGIN)
            self.play(Write(text), run_time=1.5)
            self.wait(5)
            self.play(FadeOut(text), run_time=1)
'''

    elif content_type == 'code':
        code_lines = content.split('\n')
        if len(code_lines) > 4:
            code_lines = code_lines[:4] + ['...']
        code_display = '\\n'.join(code_lines)
        simple_code = f'''from manim import *

class {scene_name}(Scene):
    def construct(self):
        try:
            # æ˜¾ç¤ºæ ‡é¢˜
            title = Text("ä»£ç ç¤ºä¾‹:", font_size=28, color=YELLOW)
            title.to_edge(UP)
            self.play(Write(title), run_time=1)
            self.wait(0.5)
            
            # æ˜¾ç¤ºå®é™…ä»£ç ï¼ˆä½¿ç”¨ç­‰å®½å­—ä½“ï¼‰
            code_text = Text("""{code_display}""", 
                           font_size=20, 
                           font="Courier",
                           color=WHITE)
            code_text.next_to(title, DOWN, buff=0.5)


            # é€è¡Œæ˜¾ç¤ºä»£ç ï¼Œæ›´æ…¢çš„èŠ‚å¥
            self.play(Write(code_text), run_time=3)
            self.wait(4)  # å……åˆ†æ—¶é—´é˜…è¯»ä»£ç 

            # å¯é€‰ï¼šæ·»åŠ æ‰§è¡Œæ•ˆæœæç¤º
            if "print" in code_text.text:
                output_hint = Text("æ‰§è¡Œç»“æœä¼šåœ¨è¿™é‡Œæ˜¾ç¤º", font_size=18, color=GREEN)
                output_hint.next_to(code_text, DOWN, buff=0.3)
                self.play(Write(output_hint), run_time=1)
                self.wait(2)
                self.play(FadeOut(output_hint), run_time=0.5)

            # ä»£ç å¼ºè°ƒæ•ˆæœ
            self.play(Circumscribe(code_text, color=YELLOW), run_time=1)
            self.wait(2)  # ç»§ç»­å±•ç¤º
            self.play(FadeOut(code_text), FadeOut(title), run_time=1.5)
        except:
            text = Text("ä»£ç å±•ç¤º", font_size=36)
            self.play(Write(text), run_time=1.5)
            self.wait(5)
            self.play(FadeOut(text), run_time=1)
'''

    elif content_type == 'chart':
        simple_code = f'''from manim import *

class {scene_name}(Scene):
    def construct(self):
        try:
            # æœ€ç®€å•çš„æŸ±çŠ¶å›¾ï¼Œé¿å…å¤æ‚å‚æ•°
            chart = BarChart([1, 2, 3, 4])
            chart.scale(0.8)
            
            # åˆ†é˜¶æ®µå±•ç¤ºå›¾è¡¨
            self.play(Create(chart), run_time=3)  # æ…¢æ…¢åˆ›å»ºå›¾è¡¨
            self.wait(4)  # å……åˆ†æ—¶é—´ç†è§£æ•°æ®


            # é«˜äº®æœ€é«˜çš„æŸ±å­
            self.play(Indicate(chart), run_time=1)
            self.wait(2)  # ç»§ç»­å±•ç¤º
            
            self.play(FadeOut(chart), run_time=1.5)
        except:
            text = Text("å›¾è¡¨å±•ç¤º", font_size=36)
            self.play(Write(text), run_time=1.5)
            self.wait(5)
            self.play(FadeOut(text), run_time=1)
'''

    elif content_type == 'definition':
        content_lines = split_content_into_lines(content, max_chars_per_line=12, max_lines=6)
        content_display = '\\n'.join(content_lines)
        simple_code = f'''from manim import *
class {scene_name}(Scene):
    def construct(self):
        try:
            # ç¡®ä¿é€æ˜èƒŒæ™¯
            config.background_color = "#00000000"
            config.transparent = True
            
            # æ˜¾ç¤ºå®šä¹‰æ ‡é¢˜ - å›ºå®šåœ¨å®‰å…¨ä½ç½®
            title = Text("å®šä¹‰:", font_size=28, color=BLUE, weight=BOLD)
            title.move_to(UP * 3.2)  # å›ºå®šåœ¨é¡¶éƒ¨å®‰å…¨åŒºåŸŸ
            self.play(Write(title), run_time=1)
            self.wait(0.5)
            
            # æ”¹è¿›ï¼šå¼ºåˆ¶å¤šè¡Œæ˜¾ç¤ºï¼Œä½¿ç”¨è¾ƒå°å­—ä½“ç¡®ä¿å®Œå…¨å¯è§
            definition_text = Text("""{content_display}""", 
                                 font_size=20,  # æ›´å°å­—ä½“ç¡®ä¿å®‰å…¨
                                 color=WHITE,
                                 line_spacing=1.2)  # ç´§å‡‘è¡Œé—´è·

            # å›ºå®šä½ç½®ç­–ç•¥ï¼šå±…ä¸­æ˜¾ç¤ºï¼Œç¡®ä¿ä¸è¶…å‡ºè¾¹ç•Œ
            definition_text.move_to(ORIGIN + UP * 0.3)  # ç¨å¾®åä¸Šï¼Œä¸ºè¾¹æ¡†ç•™ç©ºé—´
            
            # è¶…ä¸¥æ ¼è¾¹ç•Œæ£€æŸ¥ - Manimå®‰å…¨åŒºåŸŸï¼šå®½åº¦12ï¼Œé«˜åº¦6
            safe_width = 9    # æä¿å®ˆçš„å®½åº¦é™åˆ¶
            safe_height = 4   # æä¿å®ˆçš„é«˜åº¦é™åˆ¶

            # å¼ºåˆ¶ç¼©æ”¾åˆ°å®‰å…¨åŒºåŸŸå†…
            if definition_text.width > safe_width:
                scale_w = safe_width / definition_text.width
                definition_text.scale(scale_w)
                print(f"å®½åº¦ç¼©æ”¾: {{scale_w:.2f}}")


            if definition_text.height > safe_height:
                scale_h = safe_height / definition_text.height
                definition_text.scale(scale_h)
                print(f"é«˜åº¦ç¼©æ”¾: {{scale_h:.2f}}")


            # ç¡®ä¿æœ€ç»ˆä½ç½®åœ¨å®‰å…¨åŒºåŸŸ

            definition_text.move_to(ORIGIN)

            # æ·»åŠ è¾¹æ¡† - ä½¿ç”¨å›ºå®šå°ºå¯¸ç¡®ä¿ä¸è¶…å‡º
            box = SurroundingRectangle(definition_text, 
                                     color=BLUE, 
                                     buff=0.3, 
                                     stroke_width=2)


            # æœ€ç»ˆå®‰å…¨æ£€æŸ¥ï¼šå¦‚æœè¾¹æ¡†å¤ªå¤§ï¼Œå†æ¬¡ç¼©æ”¾
            max_box_width = 10
            max_box_height = 5
            if box.width > max_box_width or box.height > max_box_height:
                final_scale = min(max_box_width / box.width, max_box_height / box.height)
                definition_group = VGroup(definition_text, box)
                definition_group.scale(final_scale)
                definition_group.move_to(ORIGIN)
            
            # åˆ†é˜¶æ®µå±•ç¤º
            self.play(Write(definition_text), run_time=2.5)
            self.play(Create(box), run_time=1)
            self.wait(3)  # å……åˆ†æ—¶é—´ç†è§£å®šä¹‰

            # å¼ºè°ƒæ•ˆæœ
            self.play(Indicate(definition_text, color=YELLOW, scale_factor=1.1), run_time=1.5)
            self.wait(2)  # ç»§ç»­åœç•™

            # æ¸…ç†
            self.play(FadeOut(definition_text), FadeOut(box), FadeOut(title), run_time=1.5)
        except Exception as e:
            print(f"å®šä¹‰æ¸²æŸ“é”™è¯¯: {{e}}")
            # é”™è¯¯å›é€€ï¼šä½¿ç”¨æœ€ç®€å•çš„æ–‡æœ¬æ˜¾ç¤º
            text = Text("å®šä¹‰å±•ç¤º", font_size=24, color=BLUE)
            text.move_to(ORIGIN)
            self.play(Write(text), run_time=1.5)
            self.wait(5)
            self.play(FadeOut(text), run_time=1)

'''

    elif content_type == 'theorem':
        content_preview = content[:100] 
        simple_code = f'''from manim import *


class {scene_name}(Scene):
    def construct(self):
        try:
            # æ˜¾ç¤ºå®šç†æ ‡é¢˜
            title = Text("å®šç†:", font_size=32, color=GOLD)
            title.to_edge(UP)
            self.play(Write(title))
            self.wait(0.5)
            
            # æ˜¾ç¤ºå®šç†å†…å®¹
            theorem_text = Text("""{content_preview}""", 
                              font_size=24, 
                              color=YELLOW)
            theorem_text.next_to(title, DOWN, buff=0.5)

            # æ·»åŠ é‡‘è‰²è¾¹æ¡†
            box = SurroundingRectangle(theorem_text, color=GOLD, buff=0.3)
            self.play(Write(theorem_text))
            self.play(Create(box))
            self.play(Flash(theorem_text, color=GOLD))
            self.wait(2)
            self.play(FadeOut(theorem_text), FadeOut(box), FadeOut(title))
        except:
            text = Text("å®šç†å±•ç¤º", font_size=36)
            self.play(Write(text))
            self.wait(2)
            self.play(FadeOut(text))
'''

    elif content_type == 'example':
        content_preview = content[:100]  
        simple_code = f'''from manim import *

class {scene_name}(Scene):
    def construct(self):
        try:
            # æ˜¾ç¤ºä¾‹å­æ ‡é¢˜
            title = Text("ä¾‹å­:", font_size=32, color=GREEN)
            title.to_edge(UP)
            self.play(Write(title))
            self.wait(0.5)

            # æ˜¾ç¤ºä¾‹å­å†…å®¹
            example_text = Text("""{content_preview}""", 
                              font_size=22, 
                              color=WHITE)
            example_text.next_to(title, DOWN, buff=0.5)
            self.play(Write(example_text))
            self.wait(2)
            self.play(FadeOut(example_text), FadeOut(title))
        except:
            text = Text("ä¾‹å­å±•ç¤º", font_size=36)
            self.play(Write(text))
            self.wait(2)
            self.play(FadeOut(text))
'''

    elif content_type == 'emphasis':
        content_preview = content[:80]  
        simple_code = f'''from manim import *

class {scene_name}(Scene):
    def construct(self):
        try:
            # æ˜¾ç¤ºå¼ºè°ƒå†…å®¹
            emphasis_text = Text("""{content_preview}""", 
                               font_size=36, 
                               color=RED,
                               weight=BOLD)

            # æ·»åŠ å¼ºè°ƒåŠ¨ç”»
            self.play(Write(emphasis_text))
            self.play(Circumscribe(emphasis_text, color=RED))
            self.play(Flash(emphasis_text, color=RED))
            self.wait(2)
            self.play(FadeOut(emphasis_text))
        except:
            text = Text("é‡ç‚¹å¼ºè°ƒ", font_size=36, color=RED)
            self.play(Write(text))
            self.play(Flash(text))
            self.wait(2)
            self.play(FadeOut(text))
'''

    elif content_type == 'comparison':
        simple_code = f'''from manim import *

class {scene_name}(Scene):
    def construct(self):
        try:
            # å·¦å³å¯¹æ¯”å±•ç¤º
            left_text = Text("å¯¹æ¯”A", font_size=28, color=BLUE)
            right_text = Text("å¯¹æ¯”B", font_size=28, color=RED)

            left_text.to_edge(LEFT)
            right_text.to_edge(RIGHT)

            # VSæ ‡è®°
            vs_text = Text("VS", font_size=32, color=YELLOW)
            self.play(Write(left_text), Write(right_text))
            self.play(Write(vs_text))
            self.wait(2)
            self.play(FadeOut(left_text), FadeOut(right_text), FadeOut(vs_text))
        except:
            text = Text("å¯¹æ¯”å±•ç¤º", font_size=36)
            self.play(Write(text))
            self.wait(2)
            self.play(FadeOut(text))
'''

    elif content_type == 'step':
        simple_code = f'''from manim import *

class {scene_name}(Scene):
    def construct(self):
        try:
            # æ­¥éª¤å±•ç¤º
            step1 = Text("æ­¥éª¤ 1", font_size=24, color=WHITE)
            step2 = Text("æ­¥éª¤ 2", font_size=24, color=WHITE)
            step3 = Text("æ­¥éª¤ 3", font_size=24, color=WHITE)

            steps = [step1, step2, step3]
            for i, step in enumerate(steps):
                step.shift(UP * (1 - i) * 0.8)
                self.play(Write(step))
                self.wait(0.5)
            self.wait(1)
            self.play(*[FadeOut(step) for step in steps])
        except:
            text = Text("æ­¥éª¤å±•ç¤º", font_size=36)
            self.play(Write(text))
            self.wait(2)
            self.play(FadeOut(text))
'''

    else:
        return None

    try:
        with tempfile.TemporaryDirectory() as temp_dir:
            temp_code_file = os.path.join(temp_dir, f"{scene_name}_simple.py")
            with open(temp_code_file, 'w', encoding='utf-8') as f:
                f.write(simple_code)

            env = os.environ.copy()
            env['PYTHONWARNINGS'] = 'ignore'  
            env['MANIM_DISABLE_OPENCACHING'] = '1'  

            cmd = [
                "manim",
                "render",  
                "-ql",     
                "--transparent",  
                "--format=mov",
                "--disable_caching",  
                os.path.basename(temp_code_file),
                scene_name
            ]


            result = subprocess.run(
                cmd, 
                cwd=temp_dir,
                capture_output=True, 
                text=True,
                encoding='utf-8',
                errors='ignore',
                timeout=120, 
                env=env
            )
            
            print(f"ç®€å•å›é€€è¿”å›ç : {result.returncode}")

            output_text = (result.stdout or "") + (result.stderr or "")
  
            # ä¸åº”è¯¥è¢«è§†ä¸ºé”™è¯¯çš„è­¦å‘Š
            warnings_to_ignore = [
                "pkg_resources is deprecated",
                "UserWarning",
                "DeprecationWarning", 
                "FutureWarning",
                "manim_voiceover"
            ]

            is_only_warning = False
            if result.returncode == 1:
                has_warning = any(warning in output_text for warning in warnings_to_ignore)
                real_error_indicators = [
                    "SyntaxError", "NameError", "ImportError", "AttributeError",
                    "TypeError", "ValueError", "ModuleNotFoundError", "Traceback",
                    "Error:", "Failed to render"
                ]

                has_real_error = any(error in output_text for error in real_error_indicators)
                if has_warning and not has_real_error:
                    is_only_warning = True
                    print(f"ç®€å•å›é€€æ£€æµ‹åˆ°è­¦å‘Šä½†å¯èƒ½æˆåŠŸï¼Œæ£€æŸ¥è¾“å‡ºæ–‡ä»¶...")

            output_path = os.path.join(output_dir, f"{scene_name}_simple.mov")
            temp_media_dir = os.path.join(temp_dir, "media", "videos")

            if os.path.exists(temp_media_dir):
                for root, dirs, files in os.walk(temp_media_dir):
                    for file in files:
                        if file.endswith('.mov'):
                            generated_path = os.path.join(root, file)
                            shutil.copy2(generated_path, output_path)
                            print(f"ç”Ÿæˆç®€å•å›é€€è§†é¢‘: {output_path}")
                            return output_path

            success_indicators = [
                "File ready at" in output_text,
                "Rendered" in output_text,
                "INFO     Previewed File at:" in output_text,
                "Combining to Movie file" in output_text
            ]


            if any(success_indicators) or (is_only_warning and result.returncode == 1):
                print(f"ç®€å•å›é€€å¯èƒ½æˆåŠŸä½†æœªæ‰¾åˆ°æ ‡å‡†è·¯å¾„æ–‡ä»¶ï¼Œç»§ç»­æœç´¢...")
                for root, dirs, files in os.walk(temp_dir):
                    for file in files:
                        if file.endswith('.mov'):
                            generated_path = os.path.join(root, file)
                            shutil.copy2(generated_path, output_path)
                            print(f"æ‰¾åˆ°å¹¶ç”Ÿæˆç®€å•å›é€€è§†é¢‘: {output_path}")
                            return output_path

            print(f"ç®€å•å›é€€æœªæ‰¾åˆ°MOVæ–‡ä»¶")
            return None
    except subprocess.TimeoutExpired:
        print(f"ç®€å•å›é€€æ¸²æŸ“è¶…æ—¶")
        return None
    except Exception as e:
        print(f"ç®€å•å›é€€æ¸²æŸ“å¤±è´¥: {e}")
        return None


def generate_ai_science_knowledge_video(topic, output_dir="output", animation_mode="auto"):
    """
    ç”Ÿæˆä¸€ä¸ªAIçŸ¥è¯†ç§‘æ™®è§†é¢‘çš„ä¸»å·¥ä½œæµï¼ˆèƒ½åˆ‡æ¢åŠ¨ç”»åˆ¶ä½œæ¨¡å¼ï¼‰
    """
    print(f"å¼€å§‹ç”Ÿæˆä¸»é¢˜ä¸º '{topic}' çš„AIç§‘æ™®è§†é¢‘")
    print(f"åŠ¨ç”»åˆ¶ä½œæ¨¡å¼: {animation_mode}")

    # è§£æåŠ¨ç”»æ¨¡å¼
    if HUMAN_ANIMATION_AVAILABLE:
        if animation_mode == "human":
            mode = AnimationProductionMode.HUMAN_CONTROLLED
        else:
            mode = AnimationProductionMode.AUTO
    else:
        print("äººå·¥åŠ¨ç”»ç³»ç»Ÿä¸å¯ç”¨ï¼Œä½¿ç”¨è‡ªåŠ¨æ¨¡å¼")
        mode = AnimationProductionMode.AUTO
        animation_mode = "auto"

    # ç§»é™¤Windowsä¸æ”¯æŒçš„ç‰¹æ®Šå­—ç¬¦
    def clean_filename_for_windows(filename):
        invalid_chars = r'[<>:"|?*/\\]'
        name = re.sub(invalid_chars, '_', filename)
        name = name.strip('. ')
        if len(name) > 50:
            name = name[:50]
        if not name or name.isspace():
            name = "default_topic"
        return name

    topic_safe = clean_filename_for_windows(topic)
    full_output_dir = os.path.join(output_dir, topic_safe)
    print(f"è¾“å‡ºç›®å½•ä¸º: {full_output_dir}")
    os.makedirs(full_output_dir, exist_ok=True)

    # 1. ç”Ÿæˆå¹½é»˜é£è¶£çš„æ–‡æ¡ˆ
    print("å¼€å§‹ç”Ÿæˆè½»æ¾å¹½é»˜çš„æ–‡æ¡ˆ")
    
    script_path = os.path.join(full_output_dir, "script.txt")
    if os.path.exists(script_path):
        print("å‘ç°æœ¬åœ°æ–‡æ¡ˆç¼“å­˜ï¼Œç›´æ¥è¯»å–...")
        with open(script_path, 'r', encoding='utf-8') as f:
            script = f.read()
        print(f"æœ¬åœ°æ–‡æ¡ˆè¯»å–æˆåŠŸï¼Œé•¿åº¦: {len(script)} å­—ç¬¦")
    else:
        print("æœ¬åœ°æ— æ–‡æ¡ˆç¼“å­˜ï¼Œå¼€å§‹ç”Ÿæˆ...")
        script = generate_script(topic)
        print(f"æ–‡æ¡ˆç”Ÿæˆå®Œæˆï¼Œé•¿åº¦: {len(script)} å­—ç¬¦")
        
        # ä¿å­˜æ–‡æ¡ˆåˆ°ç›®å½•
        with open(script_path, 'w', encoding='utf-8') as f:
            f.write(script)
        print(f"æ–‡æ¡ˆå·²ä¿å­˜åˆ°æœ¬åœ°ç¼“å­˜")


    # 2. è§£æç»“æ„åŒ–å†…å®¹
    print("å¼€å§‹è§£æç»“æ„åŒ–å†…å®¹")
    segments_path = os.path.join(full_output_dir, "segments.json")

    if os.path.exists(segments_path):
        print("å‘ç°æœ¬åœ°ç»“æ„åŒ–å†…å®¹ç¼“å­˜ï¼Œç›´æ¥è¯»å–...")
        try:
            with open(segments_path, 'r', encoding='utf-8') as f:
                segments = json.load(f)
            print(f"æœ¬åœ°ç»“æ„åŒ–å†…å®¹è¯»å–æˆåŠŸï¼Œå…± {len(segments)} ä¸ªç‰‡æ®µ")
        except:
            print("æœ¬åœ°ç»“æ„åŒ–å†…å®¹è¯»å–å¤±è´¥ï¼Œé‡æ–°è§£æ...")
            segments = parse_structured_content(script)
            print(f"è§£æå®Œæˆï¼Œå…± {len(segments)} ä¸ªç‰‡æ®µ")
    else:
        print("æœ¬åœ°æ— ç»“æ„åŒ–å†…å®¹ç¼“å­˜ï¼Œå¼€å§‹è§£æ...")
        segments = parse_structured_content(script)
        print(f"è§£æå®Œæˆï¼Œå…± {len(segments)} ä¸ªç‰‡æ®µ")

    # === é›†ä¸­æ¸…ç† segments çš„ content å’Œ parent_segment.content å­—æ®µ ===
    for seg in segments:
        if 'content' in seg:
            seg['content'] = clean_content(seg['content'])
        if 'parent_segment' in seg and isinstance(seg['parent_segment'], dict) and 'content' in seg['parent_segment']:
            seg['parent_segment']['content'] = clean_content(seg['parent_segment']['content'])

    # ä¿å­˜ç»“æ„åŒ–å†…å®¹åˆ°æœ¬åœ°ç¼“å­˜ï¼ˆæ— è®ºæ–°ç”Ÿæˆè¿˜æ˜¯è¯»å–åéƒ½æ¸…ç†ï¼‰
    with open(segments_path, 'w', encoding='utf-8') as f:
        json.dump(segments, f, ensure_ascii=False, indent=2)
    print(f"ç»“æ„åŒ–å†…å®¹å·²ä¿å­˜åˆ°æœ¬åœ°ç¼“å­˜ï¼ˆå·²æ¸…ç†ç»“æ„æ ‡è®°ï¼‰")


    # 3. æ®µè½åˆ†å¥å¤„ç†
    print("åº”ç”¨æ–‡æœ¬åˆ†å¥å¤„ç†...")
    try:
        final_segments = []
        for segment in segments:
            if segment['type'] == 'text' and len(segment['content']) > 100:
                print(f"åˆ†å‰²é•¿æ–‡æœ¬ç‰‡æ®µ: {segment['content'][:50]}...")
                subsegments = split_text_by_punctuation(segment['content'])
                for subseg_dict in subsegments:
                    if subseg_dict['content'].strip():
                        final_segments.append({
                            'content': subseg_dict['content'].strip(),
                            'type': 'text',
                            'parent_segment': segment
                        })
            else:
                final_segments.append(segment)
        segments = final_segments
        print(f"åˆ†å¥å¤„ç†å®Œæˆï¼Œå…± {len(segments)} ä¸ªç‰‡æ®µ")

    except Exception as e:
        print(f"åˆ†å¥å¤„ç†å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

    segments_path = os.path.join(full_output_dir, "segments.json")
    with open(segments_path, 'w', encoding='utf-8') as f:
        json.dump(segments, f, ensure_ascii=False, indent=2)


    # 4. ç”ŸæˆTTSè¯­éŸ³æ–‡ä»¶
    print("å¼€å§‹ç”ŸæˆTTSè¯­éŸ³")
    audio_paths = []
    tts_dir = os.path.join(full_output_dir, "audio")
    os.makedirs(tts_dir, exist_ok=True)

    tts_cache_path = os.path.join(full_output_dir, "tts_cache.json")
    tts_cache = {}
    if os.path.exists(tts_cache_path):
        print("å‘ç°æœ¬åœ°TTSéŸ³é¢‘ç¼“å­˜ï¼Œæ£€æŸ¥å®Œæ•´æ€§...")
        try:
            with open(tts_cache_path, 'r', encoding='utf-8') as f:
                tts_cache = json.load(f)
            print(f"TTSç¼“å­˜è¯»å–æˆåŠŸï¼ŒåŒ…å« {len(tts_cache)} ä¸ªéŸ³é¢‘ä¿¡æ¯")
        except:
            print("TTSç¼“å­˜è¯»å–å¤±è´¥ï¼Œé‡æ–°ç”Ÿæˆ...")
            tts_cache = {}

    for i, segment in enumerate(segments):
        tts_text = segment.get('content', '')
        if not tts_text and segment['type'] != 'text':
            if 'explanation' in segment:
                tts_text = segment['explanation']
            else:
                seg_type = segment.get('type', '')
                content = segment.get('content', '')
                explanation_prompt = f"è¯·ä¸ºè¿™ä¸ª{seg_type}ç”Ÿæˆç®€çŸ­çš„è§£è¯´è¯ï¼ˆ30å­—ä»¥å†…ï¼‰ï¼š{content}"
                try:
                    explanation = modai_model_request(explanation_prompt, max_tokens=100, temperature=0.5)
                    explanation = explanation.strip()
                    segment['explanation'] = explanation 
                    tts_text = explanation
                    print(f"ä¸ºç¬¬ {i+1} æ®µåŠ¨ç”»ç”Ÿæˆè§£è¯´: {explanation}")
                except:
                    # å¤‡ç”¨
                    if seg_type == 'formula':
                        tts_text = f"è¿™é‡Œå±•ç¤ºäº†ä¸€ä¸ªé‡è¦å…¬å¼"
                    elif seg_type == 'chart':
                        tts_text = f"è¿™é‡Œå±•ç¤ºäº†ç›¸å…³å›¾è¡¨æ•°æ®"
                    elif seg_type == 'code':
                        tts_text = f"è¿™é‡Œæ¼”ç¤ºäº†ä»£ç å®ç°"
                    elif seg_type == 'definition':
                        tts_text = f"è¿™é‡Œè§£é‡Šäº†é‡è¦å®šä¹‰"
                    elif seg_type == 'theorem':
                        tts_text = f"è¿™é‡Œè®²è§£äº†é‡è¦å®šç†"
                    elif seg_type == 'example':
                        tts_text = f"è¿™é‡Œå±•ç¤ºäº†å®é™…ä¾‹å­"
                    elif seg_type == 'emphasis':
                        tts_text = f"è¿™é‡Œå¼ºè°ƒäº†å…³é”®é‡ç‚¹"
                    elif seg_type == 'comparison':
                        tts_text = f"è¿™é‡Œå¯¹æ¯”äº†ä¸åŒå†…å®¹"
                    elif seg_type == 'step':
                        tts_text = f"è¿™é‡Œæ¼”ç¤ºäº†æ“ä½œæ­¥éª¤"
                    else:
                        tts_text = f"è¿™é‡Œå±•ç¤ºäº†ç›¸å…³å†…å®¹"

                    segment['explanation'] = tts_text 

        if not tts_text:
            tts_text = segment.get('text', '') or segment.get('desc', '')

        audio_path = os.path.join(tts_dir, f"segment_{i+1}.mp3")
        audio_duration = None 

        segment_key = f"segment_{i+1}"
        if segment_key in tts_cache and os.path.exists(audio_path):
            cached_info = tts_cache[segment_key]
            audio_duration = cached_info.get('duration', 3.0)
            print(f"ç¬¬ {i+1} æ®µä½¿ç”¨æœ¬åœ°TTSç¼“å­˜ï¼Œæ—¶é•¿: {audio_duration:.1f}ç§’")
            audio_paths.append(audio_path)
        else:
            if tts_text:
                print(f"ç¬¬ {i+1} æ®µå‡†å¤‡ç”ŸæˆTTS: '{tts_text[:50]}{'...' if len(tts_text) > 50 else ''}'")
                success = edge_tts_generate(tts_text, audio_path, 'YunjianNeural')
                if success and os.path.exists(audio_path):
                    audio_duration = get_audio_duration(audio_path)
                    print(f"ç¬¬ {i+1} æ®µè¯­éŸ³ç”Ÿæˆå®Œæˆï¼Œæ—¶é•¿: {audio_duration:.1f}ç§’")

                    tts_cache[segment_key] = {
                        'text': tts_text,
                        'duration': audio_duration,
                        'path': audio_path
                    }
                    
                    audio_paths.append(audio_path)
                else:
                    print(f"ç¬¬ {i+1} æ®µTTSå¤±è´¥ï¼Œåˆ›å»ºé™éŸ³å›é€€...")
                    audio_duration = 3.0
                    create_silent_audio(audio_path, duration=audio_duration)
                    audio_paths.append(audio_path)
                    print(f"ç¬¬ {i+1} æ®µä½¿ç”¨é™éŸ³å›é€€")
            else:
                print(f"ç¬¬ {i+1} æ®µæ— æ–‡æ¡ˆï¼Œåˆ›å»ºé™éŸ³...")
                # æ²¡æœ‰æ–‡æ¡ˆæ—¶åˆ›å»ºé™éŸ³ç‰‡æ®µ
                audio_duration = 2.0
                create_silent_audio(audio_path, duration=audio_duration)
                audio_paths.append(audio_path)
                print(f"ç¬¬ {i+1} æ®µæ— æ–‡æ¡ˆï¼Œä½¿ç”¨é™éŸ³")

        segment['audio_duration'] = audio_duration

    try:
        with open(tts_cache_path, 'w', encoding='utf-8') as f:
            json.dump(tts_cache, f, ensure_ascii=False, indent=2)
        print(f"TTSç¼“å­˜å·²ä¿å­˜")
    except Exception as e:
        print(f"TTSç¼“å­˜ä¿å­˜å¤±è´¥: {e}")


    # 5. ç”Ÿæˆæ’ç”»å›¾ç‰‡
    print("ç”Ÿæˆæ’ç”»å›¾ç‰‡...")
    illustration_paths = []
    try:
        # ç”Ÿæˆæ’ç”»æè¿°
        text_segments = [seg for seg in segments if seg['type'] == 'text']
        if text_segments:
            illustration_prompts_path = os.path.join(full_output_dir, 'illustration_prompts.json')
            if os.path.exists(illustration_prompts_path):
                print("å‘ç°æœ¬åœ°æ’ç”»æè¿°ç¼“å­˜ï¼Œç›´æ¥è¯»å–...")
                with open(illustration_prompts_path, 'r', encoding='utf-8') as f:
                    illustration_prompts = json.load(f)
                print(f"æœ¬åœ°æ’ç”»æè¿°è¯»å–æˆåŠŸ: {len(illustration_prompts)} ä¸ª")
            else:
                print("æœ¬åœ°æ— æ’ç”»æè¿°ç¼“å­˜ï¼Œå¼€å§‹ç”Ÿæˆ...")
                illustration_prompts = generate_illustration_prompts([seg['content'] for seg in text_segments])
                print(f"æ’ç”»æè¿°ç”Ÿæˆå®Œæˆ: {len(illustration_prompts)} ä¸ª")
                
                with open(illustration_prompts_path, 'w', encoding='utf-8') as f:
                    json.dump(illustration_prompts, f, ensure_ascii=False, indent=2)
                print(f"æ’ç”»æè¿°å·²ä¿å­˜åˆ°æœ¬åœ°ç¼“å­˜")
            
            images_dir = os.path.join(full_output_dir, 'images')
            os.makedirs(images_dir, exist_ok=True)
            
            image_paths_path = os.path.join(images_dir, 'image_paths.json')
            if os.path.exists(image_paths_path):
                print("å‘ç°æœ¬åœ°æ’ç”»ç¼“å­˜ï¼Œç›´æ¥è¯»å–...")
                with open(image_paths_path, 'r', encoding='utf-8') as f:
                    image_paths = json.load(f)
                print(f"æœ¬åœ°æ’ç”»è¯»å–æˆåŠŸ: {len(image_paths)} ä¸ª")
            else:
                print("æœ¬åœ°æ— æ’ç”»ç¼“å­˜ï¼Œå¼€å§‹ç”Ÿæˆ...")
                print("æ’ç”»ç”Ÿæˆå¯èƒ½éœ€è¦å‡ åˆ†é’Ÿï¼Œè¯·è€å¿ƒç­‰å¾…...")
                
                image_paths = generate_images(illustration_prompts, output_dir=full_output_dir)
                print(f"æ’ç”»å›¾ç‰‡ç”Ÿæˆå®Œæˆ: {len(image_paths)} ä¸ª")
                
                for i, img_path in enumerate(image_paths):
                    if os.path.exists(img_path):
                        new_path = os.path.join(images_dir, f'illustration_{i+1}.png')
                        shutil.move(img_path, new_path)
                        image_paths[i] = new_path
                
                with open(image_paths_path, 'w', encoding='utf-8') as f:
                    json.dump(image_paths, f, ensure_ascii=False, indent=2)
                print(f"æ’ç”»è·¯å¾„å·²ä¿å­˜åˆ°æœ¬åœ°ç¼“å­˜")
            
            fg_out_dir = os.path.join(images_dir, 'output_black_only')
            if not os.path.exists(fg_out_dir):
                os.makedirs(fg_out_dir, exist_ok=True)
                print("åˆ›å»ºé€æ˜èƒŒæ™¯æ’ç”»ç›®å½•...")
            
            if len(os.listdir(fg_out_dir)) == 0 or len(os.listdir(fg_out_dir)) < len(image_paths):
                print("å¼€å§‹å¤„ç†æ’ç”»èƒŒæ™¯...")
                keep_only_black_for_folder(images_dir, fg_out_dir)
                print("æ’ç”»èƒŒæ™¯å¤„ç†å®Œæˆ")
            else:
                print("å‘ç°æœ¬åœ°é€æ˜èƒŒæ™¯æ’ç”»ï¼Œä½¿ç”¨å»èƒŒæ™¯ç‰ˆæœ¬...")
            
            text_idx = 0 
            for i, segment in enumerate(segments):
                if segment['type'] == 'text':
                    if text_idx < len(image_paths):
                        transparent_path = os.path.join(fg_out_dir, f'illustration_{text_idx+1}.png')
                        if os.path.exists(transparent_path):
                            illustration_paths.append(transparent_path)
                            print(f"ä½¿ç”¨å»èƒŒæ™¯æ’ç”»: {transparent_path}")
                        else:
                            print(f"å»èƒŒæ™¯æ’ç”»ä¸å­˜åœ¨: {transparent_path}ï¼Œä½¿ç”¨åŸå›¾æ›¿ä»£")
                            illustration_paths.append(image_paths[text_idx])
                        text_idx += 1
                    else:
                        illustration_paths.append(None)
                else:
                    illustration_paths.append(None)
            
            print(f"æ’ç”»è·¯å¾„æ„å»ºå®Œæˆ: {len(illustration_paths)} ä¸ª")
        else:
            print("æ²¡æœ‰æ–‡æœ¬ç‰‡æ®µï¼Œè·³è¿‡æ’ç”»ç”Ÿæˆ")
            illustration_paths = [None] * len(segments)
    except Exception as e:
        print(f"æ’ç”»ç”Ÿæˆå¤±è´¥: {e}")
        print("ä½¿ç”¨ç©ºæ’ç”»åˆ—è¡¨ç»§ç»­...")
        illustration_paths = [None] * len(segments)

    # 6. ç”ŸæˆèƒŒæ™¯å›¾
    print("ç”ŸæˆèƒŒæ™¯å›¾...")
    if BACKGROUNDIMAGE_AVAILABLE:
        try:
            generator = BackgroundImageGenerator(topic=topic)
            unified_background_path = generator.generate(
                title_text=topic, 
                subtitle_lines=["ç¡¬æ ¸çŸ¥è¯†åˆ†äº«", "é­”æ­ç¤¾åŒºå‡ºå“"], 
                line_position_offset=190 
            )
            print(f"ä½¿ç”¨èƒŒæ™¯ç”Ÿæˆå™¨: {unified_background_path}")

        except Exception as e:
            print(f"èƒŒæ™¯ç”Ÿæˆå¤±è´¥: {e}")
            unified_background_path = create_manual_background(title_text=topic, output_dir=full_output_dir, topic=topic)

    else:
        unified_background_path = create_manual_background(title_text=topic, output_dir=full_output_dir, topic=topic)
    if not unified_background_path or not os.path.exists(unified_background_path):
        print("èƒŒæ™¯å›¾ç”Ÿæˆå¤±è´¥")
        return None


    # 6. ç”ŸæˆmanimåŠ¨ç”» - æ”¯æŒå¤šç§åˆ¶ä½œæ¨¡å¼
    print("ç”ŸæˆåŠ¨ç”»...")
    foreground_paths = []
    animation_types = ['formula', 'code', 'chart', 'definition', 'theorem', 'example', 'emphasis', 'comparison', 'step']
    
    # åˆå§‹åŒ–åŠ¨ç”»å·¥ä½œå®¤ï¼ˆå¦‚æœæ˜¯äººå·¥æ¨¡å¼ï¼‰
    animation_studio = None
    task_manager = None
    placeholder_generator = None
    
    if HUMAN_ANIMATION_AVAILABLE and mode != AnimationProductionMode.AUTO:
        # åŠ¨æ€å¯¼å…¥é¿å…å¾ªç¯ä¾èµ–
        from human_animation_studio import AnimationStudio
        animation_studio = AnimationStudio(full_output_dir, workflow_instance=sys.modules[__name__])
        task_manager = animation_studio.task_manager
        placeholder_generator = animation_studio.placeholder_generator
        print(f"äººå·¥åŠ¨ç”»å·¥ä½œstudioå·²å¯åŠ¨")

    for i, segment in enumerate(segments):
        # æ¢å¤åŸå§‹é€»è¾‘ï¼šåªä¸ºæ˜¾å¼æ ‡è®°çš„ç‰¹æ®Šç±»å‹æ®µè½åˆ›å»ºåŠ¨ç”»
        segment_type = segment['type']
        
        # åªä¸ºé'text'ç±»å‹çš„æ®µè½åˆ›å»ºåŠ¨ç”»
        if segment_type == 'text':
            print(f"ç¬¬ {i+1} æ®µæ˜¯çº¯æ–‡æœ¬ç‰‡æ®µï¼Œè·³è¿‡åŠ¨ç”»ç”Ÿæˆï¼Œä½¿ç”¨æ’ç”»")
            foreground_paths.append(None)
            continue
        
        print(f"ç”Ÿæˆç¬¬ {i+1} ä¸ªåŠ¨ç”»: {segment_type} (åŸç±»å‹: {segment['type']}) - {segment['content'][:30]}...")
        
        # æ ¹æ®åˆ¶ä½œæ¨¡å¼å¤„ç†åŠ¨ç”»
        if mode == AnimationProductionMode.HUMAN_CONTROLLED:
            # äººå·¥æ§åˆ¶æ¨¡å¼ï¼šåˆ›å»ºä»»åŠ¡å¹¶ç”Ÿæˆå ä½ç¬¦
            audio_duration = segment.get('audio_duration', 8.0)
            task_id = task_manager.create_task(
                segment_index=i+1,
                content=segment['content'],
                content_type=segment_type,
                mode=mode,
                audio_duration=audio_duration
            )
            
            # ç”Ÿæˆå ä½ç¬¦è§†é¢‘
            placeholder_path = os.path.join(full_output_dir, f"scene_{i+1}_placeholder.mov")
            task = task_manager.get_task(task_id)
            placeholder_video = placeholder_generator.create_placeholder(task, placeholder_path)
            
            if placeholder_video:
                foreground_paths.append(placeholder_video)
                print(f"ç¬¬ {i+1} ä¸ªåŠ¨ç”»å ä½ç¬¦å·²ç”Ÿæˆ: {placeholder_video}")
            else:
                foreground_paths.append(None)
                print(f"ç¬¬ {i+1} ä¸ªåŠ¨ç”»å ä½ç¬¦ç”Ÿæˆå¤±è´¥")
            
            continue
        
        # è‡ªåŠ¨æ¨¡å¼çš„è‡ªåŠ¨ç”Ÿæˆéƒ¨åˆ†
        context_info = segment.get('context_info', {})
        surrounding_text = segment.get('surrounding_text', '')
        audio_duration = segment.get('audio_duration', None)
        
        manim_code = generate_manim_code(
            content=segment['content'], 
            content_type=segment_type, 
            scene_number=i+1,
            context_info=context_info,
            surrounding_text=surrounding_text,
            audio_duration=audio_duration,
            main_theme=topic, 
            context_segments=segments, 
            segment_index=i, 
            total_segments=segments  
        )
        
        video_path = None
        
        if manim_code:
            if QUALITY_SYSTEM_AVAILABLE:
                print(f"è¯„ä¼°åŠ¨ç”»è´¨é‡...")
                
                vqa = VisualQualityAssessment()
                quality_assessment = vqa.assess_animation_quality(
                    manim_code, 
                    segment['content'], 
                    segment_type
                )
                
                acm = AnimationContentMatcher()
                match_result = acm.validate_match(
                    manim_code,
                    segment['content'],
                    segment_type
                )
                
                quality_score = quality_assessment.get('overall_quality_score', 0)
                match_score = match_result.get('match_score', 0)
                
                print(f"è´¨é‡å¾—åˆ†: {quality_score}/100, åŒ¹é…åº¦: {match_score}/100")
                if quality_score < 70 or match_score < 70:
                    print(f"è´¨é‡ä¸è¾¾æ ‡ï¼Œå°è¯•ä¼˜åŒ–...")
                    
                    improvements = quality_assessment.get('improvement_suggestions', [])
                    improvements.extend(match_result.get('improvement_suggestions', []))
                    
                    if improvements:
                        improvement_prompt = f"""
åŸºäºä»¥ä¸‹è¯„ä¼°åé¦ˆï¼Œè¯·ä¼˜åŒ–åŠ¨ç”»ä»£ç ï¼š

åŸå§‹å†…å®¹ï¼š{segment['content']}
åŠ¨ç”»ç±»å‹ï¼š{segment_type}

æ”¹è¿›å»ºè®®ï¼š
{chr(10).join(f"- {imp}" for imp in improvements)}

è¯·ç”Ÿæˆæ”¹è¿›åçš„ManimåŠ¨ç”»ä»£ç ã€‚
"""

                        improved_code = generate_manim_code(
                            content=segment['content'],
                            content_type=segment_type,
                            scene_number=i+1,
                            context_info=context_info,
                            surrounding_text=surrounding_text,
                            audio_duration=audio_duration,
                            main_theme=topic,
                            context_segments=segments,
                            segment_index=i,
                            total_segments=segments,
                            improvement_prompt=improvement_prompt
                        )
                        
                        if improved_code:
                            manim_code = improved_code
                            print(f"å·²ç”Ÿæˆä¼˜åŒ–ç‰ˆæœ¬")
            
            code_file = os.path.join(full_output_dir, f"scene_{i+1}_{segment['type']}.py")
            with open(code_file, 'w', encoding='utf-8') as f:
                f.write(manim_code)
                
            scene_name = f"Scene{i+1}"
            scene_dir = os.path.join(full_output_dir, f"scene_{i+1}")
            video_path = render_manim_scene(
                manim_code, 
                scene_name, 
                scene_dir,
                content_type=segment['type'],
                content=segment['content']
            )
            
            # å¦‚æœæ¸²æŸ“å¤±è´¥ï¼Œç”¨ç®€å•å›é€€
            if not video_path:
                print(f"ä¸»æ¸²æŸ“å¤±è´¥ï¼Œå°è¯•ç®€å•å›é€€...")
                try:
                    fallback_dir = os.path.join(full_output_dir, f"scene_{i+1}_fallback")
                    video_path = create_simple_manim_scene(
                        segment['type'],
                        segment['content'],
                        scene_name,
                        fallback_dir
                    )
                except Exception as e:
                    print(f"ç®€å•å›é€€ä¹Ÿå¤±è´¥: {e}")
                    video_path = None
            
        foreground_paths.append(video_path)
    
    # 7. ç”ŸæˆåŒè¯­å­—å¹•
    print("ç”ŸæˆåŒè¯­å­—å¹•...")
    subtitle_paths = []
    subtitle_segments_list = [] 
    subtitle_dir = os.path.join(full_output_dir, "subtitles")
    os.makedirs(subtitle_dir, exist_ok=True)

    for i, segment in enumerate(segments):
        if segment['type'] != 'text':
            zh_text = segment.get('explanation', '') or segment.get('content', '')
            en_text = translate_text_to_english(zh_text)
            def split_subtitles(text, max_chars=30):
                import re
                sentences = re.split(r'([ã€‚ï¼ï¼Ÿï¼›ï¼Œã€])', text)
                subtitles = []
                current = ""
                for s in sentences:
                    if not s.strip():
                        continue
                    test = current + s
                    if len(test) <= max_chars:
                        current = test
                    else:
                        if current:
                            subtitles.append(current.strip())
                        current = s
                if current.strip():
                    subtitles.append(current.strip())
                return subtitles

            subtitle_segments = split_subtitles(zh_text, max_chars=30)
            subtitle_img_paths = []
            for idx, sub_text in enumerate(subtitle_segments):
                sub_en = translate_text_to_english(sub_text)
                subtitle_path, subtitle_height = create_bilingual_subtitle_image(
                    zh_text=sub_text,
                    en_text=sub_en,
                    width=1720,
                    height=120
                )
                if subtitle_path:
                    final_subtitle_path = os.path.join(subtitle_dir, f"bilingual_subtitle_{i+1}_{idx+1}.png")
                    shutil.move(subtitle_path, final_subtitle_path)
                    subtitle_img_paths.append(final_subtitle_path)
                    print(f"[å­—å¹•è°ƒè¯•] åŠ¨ç”»ç‰‡æ®µ {i+1} ç¬¬{idx+1}æ®µå­—å¹•å›¾ç‰‡å·²ä¿å­˜: {final_subtitle_path}")
                else:
                    print(f"[å­—å¹•è°ƒè¯•] åŠ¨ç”»ç‰‡æ®µ {i+1} ç¬¬{idx+1}æ®µå­—å¹•å›¾ç‰‡ç”Ÿæˆå¤±è´¥: {sub_text}")
            
            subtitle_paths.append(subtitle_img_paths[0] if subtitle_img_paths else None)
            if subtitle_img_paths:
                subtitle_segments_list.append(subtitle_img_paths)
            else:
                subtitle_segments_list.append([])
                print(f"[å­—å¹•è°ƒè¯•] åŠ¨ç”»ç‰‡æ®µ {i+1} æ²¡æœ‰ç”Ÿæˆæœ‰æ•ˆå­—å¹•ï¼Œæ·»åŠ ç©ºåˆ—è¡¨")
            
        else:
            zh_text = segment.get('content', '')
            en_text = translate_text_to_english(zh_text)
            subtitle_path, subtitle_height = create_bilingual_subtitle_image(
                zh_text=zh_text,
                en_text=en_text,
                width=1720,
                height=120
            )
            if subtitle_path:
                final_subtitle_path = os.path.join(subtitle_dir, f"bilingual_subtitle_{i+1}.png")
                shutil.move(subtitle_path, final_subtitle_path)
                subtitle_paths.append(final_subtitle_path)
                subtitle_segments_list.append([final_subtitle_path])
            else:
                subtitle_paths.append(None)
                subtitle_segments_list.append([])
    
    # 8. ç»Ÿè®¡å±•ç¤º
    successful_renders = sum(1 for path in foreground_paths if path and os.path.exists(path))
    total_renders = len(segments)  
    print(f"\nåˆ¶ä½œç»Ÿè®¡:")
    print(f"  æ–‡æ¡ˆç‰‡æ®µ: {len(segments)}")
    print(f"  è¯­éŸ³æ–‡ä»¶: {len([p for p in audio_paths if p and os.path.exists(p)])}")
    print(f"  åŠ¨ç”»æ¸²æŸ“: {successful_renders}/{total_renders}")
    print(f"  å­—å¹•æ–‡ä»¶: {len([p for p in subtitle_paths if p])}")

    # äººå·¥æ¨¡å¼ç‰¹æ®Šå¤„ç†ï¼šå¯åŠ¨äººå·¥åŠ¨ç”»å·¥ä½œå®¤
    if mode == AnimationProductionMode.HUMAN_CONTROLLED:
        print(f"\näººå·¥æ§åˆ¶æ¨¡å¼ï¼šå·²åˆ›å»º {len([p for p in foreground_paths if p])} ä¸ªå ä½ç¬¦")
        print(f"ç°åœ¨å¯åŠ¨äººå·¥åŠ¨ç”»åˆ¶ä½œå·¥ä½œå®¤...")
        
        # å…ˆç”Ÿæˆå¸¦å ä½ç¬¦çš„é¢„è§ˆè§†é¢‘
        print("ç”Ÿæˆå¸¦å ä½ç¬¦çš„é¢„è§ˆè§†é¢‘...")
        preview_path = os.path.join(full_output_dir, "preview_with_placeholders.mp4")
        
        enhanced_video_path = compose_final_video(
            unified_background_path,
            foreground_paths,
            audio_paths,
            subtitle_paths,
            illustration_paths,
            segments,
            preview_path,
            subtitle_segments_list
        )
        
        if enhanced_video_path and os.path.exists(enhanced_video_path):
            print(f"å ä½ç¬¦é¢„è§ˆè§†é¢‘å·²ç”Ÿæˆ: {enhanced_video_path}")
            print("ä½ å¯ä»¥å…ˆæŸ¥çœ‹è¿™ä¸ªé¢„è§ˆè§†é¢‘äº†è§£æ•´ä½“æ•ˆæœ")
            
            # è¯¢é—®æ˜¯å¦è¦ç«‹å³å¯åŠ¨äººå·¥å·¥ä½œå®¤
            print("\n" + "="*60)
            print("åŠ¨ç”»åˆ¶ä½œé€‰é¡¹:")
            print("1. ç°åœ¨å¯åŠ¨äººå·¥å·¥ä½œå®¤åˆ¶ä½œåŠ¨ç”»")
            print("2. ç¨åæ‰‹åŠ¨å¯åŠ¨å·¥ä½œå®¤")
            print("3. ç›´æ¥ä½¿ç”¨å ä½ç¬¦ç”Ÿæˆæœ€ç»ˆè§†é¢‘")
            
            try:
                choice = input("è¯·é€‰æ‹© (1-3): ").strip()
                
                if choice == "1":
                    # ç«‹å³å¯åŠ¨äººå·¥å·¥ä½œå®¤
                    print("\nå¯åŠ¨äººå·¥åŠ¨ç”»åˆ¶ä½œå·¥ä½œå®¤...")
                    try:
                        from human_animation_studio import AnimationStudio
                        human_studio = AnimationStudio(full_output_dir, workflow_instance=sys.modules[__name__])
                        print("äººå·¥åŠ¨ç”»å·¥ä½œå®¤å·²å‡†å¤‡å°±ç»ª")
                        print("ä½ å¯ä»¥ä½¿ç”¨å·¥ä½œå®¤çš„å„ç§åŠŸèƒ½æ¥åˆ¶ä½œåŠ¨ç”»")
                        
                        # å·¥ä½œå®¤é€€å‡ºåæ£€æŸ¥æ˜¯å¦æœ‰å®Œæˆçš„åŠ¨ç”»ï¼Œé‡æ–°åˆæˆæœ€ç»ˆè§†é¢‘
                        print("\næ£€æŸ¥åŠ¨ç”»åˆ¶ä½œç»“æœ...")
                        updated_foreground_paths = []
                        
                        for i, segment in enumerate(segments):
                            if segment['type'] == 'text':
                                updated_foreground_paths.append(None)
                                continue
                            
                            # æ£€æŸ¥æ˜¯å¦æœ‰å®Œæˆçš„åŠ¨ç”»
                            final_animation_path = os.path.join(animation_studio.finals_dir, f"scene_{i+1}_final.mov")
                            if os.path.exists(final_animation_path):
                                updated_foreground_paths.append(final_animation_path)
                                print(f"å‘ç°å®Œæˆçš„åŠ¨ç”»: scene_{i+1}")
                            else:
                                updated_foreground_paths.append(foreground_paths[i])  # ä¿æŒå ä½ç¬¦
                        
                        # é‡æ–°åˆæˆæœ€ç»ˆè§†é¢‘
                        final_video_path = os.path.join(full_output_dir, "final.mp4")
                        enhanced_video_path = compose_final_video(
                            unified_background_path,
                            updated_foreground_paths,
                            audio_paths,
                            subtitle_paths,
                            illustration_paths,
                            segments,
                            final_video_path,
                            subtitle_segments_list
                        )
                        
                        if enhanced_video_path and os.path.exists(enhanced_video_path):
                            print(f"æœ€ç»ˆè§†é¢‘å·²æ›´æ–°: {enhanced_video_path}")
                        
                    except ImportError as e:
                        print(f" æ— æ³•å¯åŠ¨äººå·¥å·¥ä½œå®¤: {e}")
                        print("è¯·æ‰‹åŠ¨è¿è¡Œ: python human_animation_studio.py \"é¡¹ç›®ç›®å½•\"")
                    except Exception as e:
                        print(f" äººå·¥å·¥ä½œå®¤è¿è¡Œå‡ºé”™: {e}")
                        
                elif choice == "2":
                    print(f"\nä½ å¯ä»¥ç¨åè¿è¡Œä»¥ä¸‹å‘½ä»¤å¯åŠ¨äººå·¥å·¥ä½œå®¤:")
                    print(f"python human_animation_studio.py \"{full_output_dir}\"")
                    
                elif choice == "3":
                    print("\nç»§ç»­ä½¿ç”¨å ä½ç¬¦ç”Ÿæˆæœ€ç»ˆè§†é¢‘...")
                    
            except KeyboardInterrupt:
                print("\nç”¨æˆ·ä¸­æ–­ï¼Œç»§ç»­ç”Ÿæˆå¸¦å ä½ç¬¦çš„æœ€ç»ˆè§†é¢‘...")
                
        return full_output_dir  # äººå·¥æ¨¡å¼åœ¨è¿™é‡Œè¿”å›ï¼Œåç»­çš„è‡ªåŠ¨åˆæˆé€»è¾‘è·³è¿‡

    # 9. åˆæˆæœ€ç»ˆè§†é¢‘ (ä»…è‡ªåŠ¨æ¨¡å¼)
    if successful_renders > 0 or len(audio_paths) > 0:
        print(f"\nå¼€å§‹åˆæˆæœ€ç»ˆè§†é¢‘...")
        if unified_background_path:
            final_video_path = os.path.join(full_output_dir, "final.mp4")
            
            enhanced_video_path = compose_final_video(
                unified_background_path,
                foreground_paths,
                audio_paths,
                subtitle_paths,
                illustration_paths,
                segments,
                final_video_path,
                subtitle_segments_list
            )          
            if enhanced_video_path and os.path.exists(enhanced_video_path):
                bg_music_path = os.path.join(video_agent_dir, "asset", "bg_audio.mp3")
                if os.path.exists(bg_music_path):
                    final_with_music = os.path.join(full_output_dir, "final_with_music.mp4")
                    add_background_music(enhanced_video_path, final_with_music, music_volume=0.15)
                    print(f"è§†é¢‘åˆæˆå®Œæˆï¼ˆå«èƒŒæ™¯éŸ³ä¹ï¼‰: {final_with_music}")
                else:
                    print(f"è§†é¢‘åˆæˆå®Œæˆ: {enhanced_video_path}")
                    print("æœªæ‰¾åˆ°èƒŒæ™¯éŸ³ä¹æ–‡ä»¶ï¼Œè·³è¿‡èƒŒæ™¯éŸ³ä¹")
    segments_path = os.path.join(full_output_dir, "segments.json")
    with open(segments_path, 'w', encoding='utf-8') as f:
        json.dump(segments, f, ensure_ascii=False, indent=2)
    
    print(f"\nè§†é¢‘ç”Ÿæˆå®Œæˆï¼")
    print(f"è¾“å‡ºç›®å½•: {full_output_dir}")
    return full_output_dir


def fix_latex_issues_in_manim_code(code, scene_name):
    """
    ä¿®å¤Manimä»£ç ä¸­çš„LaTeX/MiKTeXé—®é¢˜
    """
    print("ä¿®å¤LaTeXç›¸å…³é—®é¢˜...")
    def extract_formula_content(code_content):
        """ä»ä»£ç ä¸­æå–å…¬å¼å†…å®¹"""
        formulas = []
        patterns = [
            r'MathTex\(r?"([^"]*?)"\)',
            r"MathTex\(r?'([^']*?)'\)",
            r'MathTex\("([^"]*?)"\)',
            r"MathTex\('([^']*?)'\)",
        ]

        for pattern in patterns:
            matches = re.findall(pattern, code_content)
            for match in matches:
                clean_content = match.replace('\\\\', '').replace('\\', '')
                clean_content = clean_content.replace('{', '').replace('}', '')
                clean_content = clean_content.replace('frac', 'åˆ†æ•°').replace('sqrt', 'âˆš')
                formulas.append(clean_content)

        return formulas

    def replace_mathtex_with_text(code_content):
        """å°†MathTexæ›¿æ¢ä¸ºText"""
        code_content = re.sub(r'from manim import.*MathTex.*', 'from manim import *', code_content)
        def replace_mathtex(match):
            formula_content = match.group(1)
            clean_content = formula_content.replace('\\\\', '').replace('\\', '')
            clean_content = clean_content.replace('{', '').replace('}', '')
            clean_content = clean_content.replace('frac', 'åˆ†æ•°').replace('sqrt', 'âˆš')
            clean_content = clean_content.replace('r"', '').replace("r'", '')
            return f'Text("{clean_content}", font="Arial", color=WHITE, font_size=24)'

        patterns = [
            r'MathTex\(r?"([^"]*?)"\)',
            r"MathTex\(r?'([^']*?)'\)",
            r'MathTex\("([^"]*?)"\)',
            r"MathTex\('([^']*?)'\)",
        ]

        for pattern in patterns:
            code_content = re.sub(pattern, replace_mathtex, code_content)
        return code_content

    try:
        if "MathTex" in code:
            print("æ£€æµ‹åˆ°MathTexï¼Œå°è¯•æ™ºèƒ½æ›¿æ¢...")

            formulas = extract_formula_content(code)
            print(f"æå–åˆ° {len(formulas)} ä¸ªå…¬å¼: {formulas}")
        
            fixed_code = replace_mathtex_with_text(code)
            if "MathTex" not in fixed_code and "Text" in fixed_code:
                print("MathTexæˆåŠŸæ›¿æ¢ä¸ºText")
                return fixed_code

        print("ä½¿ç”¨LaTeXå¢å¼ºä¿®å¤æ¨¡æ¿...")
        formulas = extract_formula_content(code) if "MathTex" in code else []
        formula_display = formulas[0] if formulas else "æ•°å­¦å…¬å¼"
        fixed_code_template = f'''# -*- coding: utf-8 -*-

# LaTeXä¿®å¤ç‰ˆæœ¬ - ä½¿ç”¨Textæ›¿ä»£MathTexé¿å…LaTeXä¾èµ–

import sys
import os

if hasattr(sys, 'setdefaultencoding'):
    sys.setdefaultencoding('utf-8')
os.environ['PYTHONIOENCODING'] = 'utf-8'


from manim import *

class {scene_name}(Scene):
    def construct(self):
        # LaTeXä¿®å¤ï¼šä½¿ç”¨Textç±»æ›¿ä»£MathTexï¼Œé¿å…LaTeXä¾èµ–é—®é¢˜
        # åˆ›å»ºä¸»è¦å†…å®¹å±•ç¤º

        main_content = Text("{formula_display}", font_size=32, color=BLUE)
        main_content.move_to(ORIGIN)

        # åˆ›å»ºè£…é¥°æ€§å…ƒç´ 
        bg_rect = RoundedRectangle(
            width=main_content.width + 1,
            height=main_content.height + 0.8,
            corner_radius=0.2,
            color=BLUE,
            fill_opacity=0.1,
            stroke_width=2
        )

        bg_rect.move_to(main_content.get_center())

        # åŠ¨ç”»åºåˆ—
        self.play(DrawBorderThenFill(bg_rect), run_time=1.5)
        self.play(Write(main_content), run_time=2)
        self.wait(2)

        # æ·»åŠ å¼ºè°ƒæ•ˆæœ
        self.play(Indicate(main_content, scale_factor=1.2), run_time=1)
        self.wait(2)

        # ç»“æŸåŠ¨ç”»
        self.play(FadeOut(main_content), FadeOut(bg_rect), run_time=1.5)

'''
        return fixed_code_template

    except Exception as e:
        print(f"LaTeXä¿®å¤è¿‡ç¨‹ä¸­å‡ºé”™: {e}")
        return f'''# -*- coding: utf-8 -*-

from manim import *

class {scene_name}(Scene):
    def construct(self):
        text = Text("å†…å®¹å±•ç¤º", font_size=36, color=WHITE)
        self.play(Write(text))
        self.wait(3)
        self.play(FadeOut(text))
'''


def fix_manim_error_with_llm(code, error_message, content_type, scene_name, enable_layout_optimization: bool = True):
    """
    ä½¿ç”¨LLMä¿®å¤Manimé”™è¯¯ - å¯æ§åˆ¶æ˜¯å¦è¿›è¡Œå¸ƒå±€ä¼˜åŒ–
    """

    print(f"å¼€å§‹ä½¿ç”¨LLMä¿®å¤ {scene_name} çš„é”™è¯¯...")
    
    # å¸ƒå±€ä¼˜åŒ–åŠŸèƒ½å·²é›†æˆåˆ° balanced_spatial_system
    layout_issues = []
    if enable_layout_optimization:
        print("å¸ƒå±€ä¼˜åŒ–åŠŸèƒ½å·²å¯ç”¨ï¼Œé‡‡ç”¨ balanced_spatial_system çš„ç­–ç•¥")
    else:
        print("å¸ƒå±€ä¼˜åŒ–åŠŸèƒ½å·²å…³é—­ï¼Œæœ¬æ¬¡ä»…ä¿®å¤æ¸²æŸ“/è¯­æ³•é”™è¯¯ï¼Œä¸æ”¹åŠ¨å¸ƒå±€")

    latex_error_keywords = ["MiKTeX", "latex error", "pdflatex", "LaTeX Error", "MathTex rendering"]
    is_latex_error = any(keyword in error_message for keyword in latex_error_keywords)

    if is_latex_error and ("MathTex" in code):
        print("æ£€æµ‹åˆ°æ˜ç¡®çš„LaTeXæ¸²æŸ“é”™è¯¯ï¼Œä½¿ç”¨LaTeXä¿®å¤ç­–ç•¥...")
        return fix_latex_issues_in_manim_code(code, scene_name)

    print("ä½¿ç”¨æ™ºèƒ½LLMä¿®å¤..." + ("(åŒ…å«å¸ƒå±€ä¼˜åŒ–)" if enable_layout_optimization else "(ä¸è¿›è¡Œå¸ƒå±€ä¼˜åŒ–)"))

    # æ„å»ºä¿®å¤æç¤º
    fix_prompt = f"""ä½ æ˜¯Manimè°ƒè¯•ä¸“å®¶ã€‚åˆ†æä»¥ä¸‹ä»£ç å’Œé”™è¯¯ä¿¡æ¯ï¼Œæä¾›ä¿®å¤æ–¹æ¡ˆã€‚

åœºæ™¯åç§°: {scene_name}
å†…å®¹ç±»å‹: {content_type}

Manimä»£ç :
{code}

å®Œæ•´æŠ¥é”™tracebackï¼ˆå«stderrï¼‰:
{error_message}
"""

    # å¦‚æœå¯ç”¨å¸ƒå±€ä¼˜åŒ–ï¼Œæ·»åŠ åˆ°æç¤ºä¸­é€šç”¨çš„å¸ƒå±€è¦æ±‚
    if enable_layout_optimization:
        fix_prompt += f"""

æ£€æµ‹åˆ°çš„å¸ƒå±€é—®é¢˜:
{chr(10).join(f"- {issue}" for issue in layout_issues)}

## å¸ƒå±€ä¼˜åŒ–è¦æ±‚
1. ä½¿ç”¨åŒºåŸŸåŒ–å¸ƒå±€ç³»ç»Ÿï¼Œé¿å…å…ƒç´ é‡å 
2. æ¯ä¸ªæ–‡æœ¬å…ƒç´ ç”¨to_edge()æˆ–é€‚å½“çš„ç›¸å¯¹å®šä½
3. ä¿æŒæœ€å°é—´è·ï¼šå‚ç›´â‰¥0.4ï¼Œæ°´å¹³â‰¥0.5
4. ç”»é¢è¾¹ç•Œï¼šleftâ‰¥-6.0, rightâ‰¤6.0, topâ‰¤3.5, bottomâ‰¥-3.5
5. åˆ†æ®µæ¸…ç†ï¼šæ¯ä¸ªæ¦‚å¿µè®²å®Œåç”¨FadeOutæ¸…ç†å…ƒç´ """
    else:
        fix_prompt += """

æ³¨æ„ï¼šæœ¬æ¬¡ä¿®å¤ä»…é™äºè§£å†³æ¸²æŸ“å¤±è´¥æˆ–è¯­æ³•é”™è¯¯ï¼Œè¯·å°½é‡ä¸è¦æ›´æ”¹ç°æœ‰å¸ƒå±€ä¸æ’ç‰ˆï¼›ä¿æŒå…ƒç´ ä½ç½®ã€æ•´ä½“é£æ ¼ä¸ç°æœ‰ä»£ç ä¸€è‡´ã€‚
"""

    fix_prompt += """

è¯·æä¾›ä¿®å¤åçš„å®Œæ•´ä»£ç ï¼Œè¦æ±‚ï¼š
1. ä¿®å¤æ‰€æœ‰è¯­æ³•å’Œé€»è¾‘é”™è¯¯
2. ä¿æŒåŸæœ‰åŠŸèƒ½ä¸å˜ï¼Œä¸è¦ç®€åŒ–å†…å®¹
3. å¦‚æœæœ‰MathTexé”™è¯¯ï¼Œæ›¿æ¢ä¸ºTextä½†ä¿æŒåŸå§‹å†…å®¹
4. ç¡®ä¿åŠ¨ç”»ç”ŸåŠ¨æœ‰è¶£ï¼Œä½“ç°åŸå§‹å†…å®¹çš„ä»·å€¼
5. ä»£ç å®Œæ•´å¯æ‰§è¡Œ
"""

    if enable_layout_optimization:
        fix_prompt += """
é™„åŠ ï¼ˆè‹¥å¯èƒ½ï¼‰ï¼š
- ä¼˜åŒ–å¸ƒå±€ï¼Œé¿å…å…ƒç´ å†²çªä¸è¶Šç•Œ
- ä½¿ç”¨åˆç†çš„ç©ºé—´ç®¡ç†ä¸é—´è·
"""

    fix_prompt += """
è¯·ç›´æ¥è¿”å›ä¿®å¤åçš„å®Œæ•´Pythonä»£ç ï¼š
"""

    try:
        fix_result = modai_model_request(fix_prompt, max_tokens=2048, temperature=0.1)
        
        # æ¸…ç†LLMè¾“å‡º
        cleaned_code = clean_llm_code_output(fix_result)
        
        if cleaned_code and 'from manim import' in cleaned_code and 'class' in cleaned_code:
            print("é”™è¯¯å’Œå¸ƒå±€é—®é¢˜ä¿®å¤å®Œæˆ")
            return cleaned_code
        else:
            print(f"ä¿®å¤åçš„ä»£ç ä¸å®Œæ•´æˆ–æ ¼å¼é”™è¯¯")
            return None
            
    except Exception as e:
        print(f"LLMä¿®å¤å¤±è´¥: {e}")
        return None


def compose_final_video(background_path, foreground_paths, audio_paths, subtitle_paths, illustration_paths, segments, output_path, subtitle_segments_list):
    """
    åˆæˆæ’ç”»+åŠ¨ç”»çš„æœ€ç»ˆè§†é¢‘
    """

    try:
        import moviepy.editor as mp

        print("å¼€å§‹åˆæˆæœ€ç»ˆè§†é¢‘...")
        segment_durations = []
        total_duration = 0

        for i, audio_path in enumerate(audio_paths):
            actual_duration = 3.0 
        
            if audio_path and os.path.exists(audio_path):
                try:
                    audio_clip = mp.AudioFileClip(audio_path)
                    actual_duration = max(audio_clip.duration, 3.0)  
                    audio_clip.close()
                except:
                    actual_duration = 3.0

            if i < len(foreground_paths) and foreground_paths[i] and os.path.exists(foreground_paths[i]):
                try:
                    animation_clip = mp.VideoFileClip(foreground_paths[i], has_mask=True)
                    animation_duration = animation_clip.duration
                    animation_clip.close()

                    if animation_duration > actual_duration:
                        actual_duration = animation_duration
                        print(f"ç‰‡æ®µ {i+1} ä½¿ç”¨åŠ¨ç”»æ—¶é•¿: {actual_duration:.1f}ç§’")
                except:
                    pass 

            segment_durations.append(actual_duration)
            total_duration += actual_duration

        print(f"æ€»æ—¶é•¿: {total_duration:.1f}ç§’ï¼Œ{len(segment_durations)}ä¸ªç‰‡æ®µ")
        print("é‡æ–°ç»„ç»‡åˆæˆé€»è¾‘...")
        
        print("æ­¥éª¤1ï¼šåˆæˆæ¯ä¸ªç‰‡æ®µçš„å®Œæ•´è§†é¢‘...")
        segment_videos = []
        
        for i, (duration, segment) in enumerate(zip(segment_durations, segments)):
            print(f"åˆæˆç‰‡æ®µ {i+1}: {segment.get('type', 'unknown')} - {duration:.1f}ç§’")
            
            current_video_clips = []
            
            if background_path and os.path.exists(background_path):
                bg_clip = mp.ImageClip(background_path, duration=duration)
                bg_clip = bg_clip.resize((1920, 1080))
                current_video_clips.append(bg_clip)
            
            if segment.get('type') == 'text' and i < len(illustration_paths) and illustration_paths[i] and os.path.exists(illustration_paths[i]):
                try:
                    illustration_clip = mp.ImageClip(illustration_paths[i], duration=duration)
                    original_w, original_h = illustration_clip.size
                    available_w, available_h = 1920, 800
                    scale_w = available_w / original_w
                    scale_h = available_h / original_h
                    scale = min(scale_w, scale_h, 1.0)
                    
                    if scale < 1.0:
                        new_w = int(original_w * scale)
                        new_h = int(original_h * scale)
                        illustration_clip = illustration_clip.resize((new_w, new_h))
                    else:
                        new_w, new_h = original_w, original_h
                    
                    # å‘å·¦è¿åŠ¨åŠ¨ç”»
                    exit_duration = 1.0
                    start_animation_time = max(duration - exit_duration, 0)
                    print(f"è°ƒè¯•: ç‰‡æ®µæ—¶é•¿={duration:.2f}ç§’, é€€å‡ºåŠ¨ç”»æ—¶é•¿={exit_duration}ç§’, åŠ¨ç”»å¼€å§‹æ—¶é—´={start_animation_time:.2f}ç§’")
                    print(f"è°ƒè¯•: æ’ç”»é™æ­¢æ—¶é—´={start_animation_time:.2f}ç§’, åŠ¨ç”»è¿åŠ¨æ—¶é—´={exit_duration}ç§’")


                    def illustration_pos_factory(idx, start_x, end_x, new_h, start_animation_time, exit_duration):
                        def illustration_pos(t):
                            y = (1080 - new_h) // 2
                            if t < start_animation_time:
                                x = start_x
                                print(f"è°ƒè¯•: ç‰‡æ®µ{idx}  æ—¶é—´={t:.2f}ç§’, é™æ­¢ä½ç½®=({x}, {y})ï¼ŒåŠ¨ç”»å°†åœ¨{start_animation_time:.2f}ç§’å¼€å§‹")
                            elif t < start_animation_time + exit_duration:
                                progress = (t - start_animation_time) / exit_duration
                                progress = min(max(progress, 0), 1)  # é™åˆ¶åœ¨0~1
                                x = start_x + (end_x - start_x) * progress
                                print(f"è°ƒè¯•: ç‰‡æ®µ{idx}  æ—¶é—´={t:.2f}ç§’, è¿åŠ¨ä½ç½®=({x}, {y})ï¼Œè¿›åº¦={progress:.1%}")
                            else:
                                x = end_x
                                print(f"è°ƒè¯•: ç‰‡æ®µ{idx}  æ—¶é—´={t:.2f}ç§’, å·²è¿åŠ¨ç»“æŸï¼Œæ’ç”»åœ¨å±å¹•å¤– ({x}, {y})")
                            return (x, y)
                        return illustration_pos

                    print(f"æ’ç”»åŠ¨ç”»è®¾ç½®: ç‰‡æ®µæ—¶é•¿ {duration:.1f}ç§’ï¼ŒåŠ¨ç”»åœ¨æœ€å {exit_duration}ç§’å¼€å§‹")
                    illustration_clip = illustration_clip.set_position(
                        illustration_pos_factory(i, (1920 - new_w) // 2, -new_w, new_h, start_animation_time, exit_duration)
                    )
                    current_video_clips.append(illustration_clip)
                    print(f"æ·»åŠ æ’ç”»å±‚")
                except Exception as e:
                    print(f"æ’ç”»åŠ è½½å¤±è´¥: {e}")
            
            elif segment.get('type') != 'text' and i < len(foreground_paths) and foreground_paths[i] and os.path.exists(foreground_paths[i]):
                try:
                    fg_clip = mp.VideoFileClip(foreground_paths[i], has_mask=True)
                    original_w, original_h = fg_clip.size
                    available_w, available_h = 1920, 800
                    scale_w = available_w / original_w
                    scale_h = available_h / original_h
                    scale = min(scale_w, scale_h, 1.0)
                    
                    if scale < 1.0:
                        new_w = int(original_w * scale)
                        new_h = int(original_h * scale)
                        fg_clip = fg_clip.resize((new_w, new_h))
                    
                    fg_clip = fg_clip.set_position(('center', 'center'))
                    fg_clip = fg_clip.set_duration(duration)
                    current_video_clips.append(fg_clip)
                    print(f"æ·»åŠ åŠ¨ç”»å±‚")
                except Exception as e:
                    print(f"åŠ¨ç”»åŠ è½½å¤±è´¥: {e}")
            
            if segment.get('type') != 'text' and i < len(subtitle_segments_list):
                try:
                    subtitle_imgs = subtitle_segments_list[i]
                    if subtitle_imgs and isinstance(subtitle_imgs, list) and len(subtitle_imgs) > 0:
                        n = len(subtitle_imgs)
                        seg_duration = duration / n
                        for idx, subtitle_path in enumerate(subtitle_imgs):
                            try:
                                from PIL import Image
                                subtitle_img = Image.open(subtitle_path)
                                subtitle_w, subtitle_h = subtitle_img.size
                                subtitle_clip = mp.ImageClip(subtitle_path, duration=seg_duration)
                                subtitle_clip = subtitle_clip.resize((subtitle_w, subtitle_h))
                                subtitle_y = 850
                                print(f"å­—å¹•ä½ç½®è®¾ç½®ä¸º y={subtitle_y}")
                                subtitle_clip = subtitle_clip.set_position(('center', subtitle_y))
                                subtitle_clip = subtitle_clip.set_start(idx * seg_duration)
                                current_video_clips.append(subtitle_clip)
                                print(f"æ·»åŠ åŠ¨ç”»ç‰‡æ®µå­—å¹• {idx+1}/{n}")
                            except Exception as e:
                                print(f"åŠ¨ç”»ç‰‡æ®µå­—å¹• {idx+1} å¤„ç†å¤±è´¥: {e}")
                    else:
                        print(f"åŠ¨ç”»ç‰‡æ®µ {i+1} æ²¡æœ‰æœ‰æ•ˆå­—å¹•ï¼Œè·³è¿‡å­—å¹•å±‚")
                except Exception as e:
                    print(f"åŠ¨ç”»ç‰‡æ®µ {i+1} å­—å¹•å¤„ç†å¼‚å¸¸: {e}")
            else:
                if i < len(subtitle_paths) and subtitle_paths[i] and os.path.exists(subtitle_paths[i]):
                    try:
                        from PIL import Image
                        subtitle_img = Image.open(subtitle_paths[i])
                        subtitle_w, subtitle_h = subtitle_img.size
                        subtitle_clip = mp.ImageClip(subtitle_paths[i], duration=duration)
                        subtitle_clip = subtitle_clip.resize((subtitle_w, subtitle_h))
                        subtitle_y = 850
                        print(f"å­—å¹•ä½ç½®è®¾ç½®ä¸º y={subtitle_y}")
                        subtitle_clip = subtitle_clip.set_position(('center', subtitle_y))
                        current_video_clips.append(subtitle_clip)
                        print(f"æ·»åŠ å­—å¹•å±‚ï¼ˆåº•éƒ¨å¯¹é½ï¼‰")
                    except Exception as e:
                        print(f"å­—å¹•åŠ è½½å¤±è´¥: {e}")

            if current_video_clips:
                segment_video = mp.CompositeVideoClip(current_video_clips, size=(1920, 1080))
                segment_videos.append(segment_video)
                print(f"ç‰‡æ®µ {i+1} åˆæˆå®Œæˆ")
            else:
                print(f"ç‰‡æ®µ {i+1} æ— æœ‰æ•ˆå†…å®¹ï¼Œè·³è¿‡")
        
        if not segment_videos:
            print("æ²¡æœ‰æœ‰æ•ˆçš„è§†é¢‘ç‰‡æ®µ")
            return None
        
        print("  æ­¥éª¤2ï¼šæŒ‰æ—¶é—´é¡ºåºè¿æ¥æ‰€æœ‰ç‰‡æ®µ...")
        final_video = mp.concatenate_videoclips(segment_videos, method="compose")
        print(f"è§†é¢‘è¿æ¥å®Œæˆï¼Œæ€»æ—¶é•¿: {final_video.duration:.1f}ç§’")
        
        print("æ­¥éª¤3ï¼šåˆæˆéŸ³é¢‘...")
        if audio_paths:
            try:
                print(f"è¿æ¥ {len(audio_paths)} ä¸ªéŸ³é¢‘ç‰‡æ®µ...")
                valid_audio_clips = []
                for i, (audio_path, duration) in enumerate(zip(audio_paths, segment_durations)):
                    try:
                        if audio_path and os.path.exists(audio_path):
                            audio_clip = mp.AudioFileClip(audio_path)
                            audio_clip = audio_clip.set_fps(44100)
                            try:
                                audio_clip = audio_clip.set_channels(2)
                            except Exception:
                                pass
                            if audio_clip.duration > duration:
                                audio_clip = audio_clip.subclip(0, duration)
                            elif audio_clip.duration < duration:
                                from moviepy.editor import AudioClip
                                silence = AudioClip(lambda t: [0,0], duration=duration-audio_clip.duration).set_fps(44100)
                                try:
                                    silence = silence.set_channels(2)
                                except Exception:
                                    pass
                                audio_clip = mp.concatenate_audioclips([audio_clip, silence])
                            valid_audio_clips.append(audio_clip)
                            print(f"éŸ³é¢‘ç‰‡æ®µ {i+1}: {audio_clip.duration:.2f}s")
                        else:
                            print(f"éŸ³é¢‘ç‰‡æ®µ {i+1} æ— æ•ˆï¼Œè·³è¿‡")
                    except Exception as e:
                        print(f"éŸ³é¢‘ç‰‡æ®µ {i+1} å¤„ç†å¤±è´¥: {e}")
                        from moviepy.editor import AudioClip
                        silence = AudioClip(lambda t: [0,0], duration=duration).set_fps(44100)
                        valid_audio_clips.append(silence)

                if valid_audio_clips:
                    final_audio = mp.concatenate_audioclips(valid_audio_clips)
                    print(f"éŸ³é¢‘è¿æ¥å®Œæˆï¼Œæ€»æ—¶é•¿: {final_audio.duration:.1f}ç§’")
                    if final_audio.duration > final_video.duration:
                        final_audio = final_audio.subclip(0, final_video.duration)
                        print(f"éŸ³é¢‘å·²è£å‰ªåˆ°è§†é¢‘æ—¶é•¿")
                    elif final_audio.duration < final_video.duration:
                        from moviepy.editor import AudioClip
                        silence = AudioClip(lambda t: [0,0], duration=final_video.duration-final_audio.duration)
                        final_audio = mp.concatenate_audioclips([final_audio, silence])
                        print(f"éŸ³é¢‘å·²è¡¥è¶³åˆ°è§†é¢‘æ—¶é•¿")
                    
                    final_video = final_video.set_audio(final_audio)
                    print(f"éŸ³é¢‘åˆæˆæˆåŠŸï¼Œæ—¶é•¿: {final_audio.duration:.1f}ç§’ (è§†é¢‘: {final_video.duration:.1f}ç§’)")
                else:
                    print(f"æ²¡æœ‰æœ‰æ•ˆéŸ³é¢‘ï¼Œç”Ÿæˆé™éŸ³è§†é¢‘")
            except Exception as e:
                print(f"éŸ³é¢‘åˆæˆå¤±è´¥: {e}")
                print(f"å°†ç”Ÿæˆæ— å£°è§†é¢‘")
        else:
            print(f"æ²¡æœ‰éŸ³é¢‘ç‰‡æ®µï¼Œç”Ÿæˆé™éŸ³è§†é¢‘")

        try:
            import moviepy.audio.fx.all as afx
            bg_music_path = os.path.join(os.path.dirname(__file__), "asset", "bg_audio.mp3")
            if os.path.exists(bg_music_path):
                print("æ·»åŠ èƒŒæ™¯éŸ³ä¹...")
                bg_music = mp.AudioFileClip(bg_music_path)
                bg_music = afx.audio_loop(bg_music, duration=final_video.duration)
                bg_music = bg_music.volumex(0.2)
                if final_video.audio:
                    tts_audio = final_video.audio.set_duration(final_video.duration).volumex(1.0) 
                    bg_audio = bg_music.set_duration(final_video.duration).volumex(0.15)  
                    mixed_audio = mp.CompositeAudioClip([tts_audio, bg_audio]).set_duration(final_video.duration)
                else:
                    mixed_audio = bg_music.set_duration(final_video.duration).volumex(0.3) 
                final_video = final_video.set_audio(mixed_audio)
                print("èƒŒæ™¯éŸ³ä¹æ·»åŠ å®Œæˆ")
            else:
                print("æœªæ‰¾åˆ°èƒŒæ™¯éŸ³ä¹æ–‡ä»¶")
        except Exception as e:
            print(f"èƒŒæ™¯éŸ³ä¹æ·»åŠ å¤±è´¥: {e}")

        print("æ¸²æŸ“æœ€ç»ˆè§†é¢‘...")
        if final_video is None:            
            print("é”™è¯¯: final_videoä¸ºNoneï¼Œæ— æ³•æ¸²æŸ“")
            return None

        try:
            print(f"è§†é¢‘æ€»æ—¶é•¿: {final_video.duration:.1f}ç§’")
            print(f"è§†é¢‘åˆ†è¾¨ç‡: {final_video.size}")
            print(f"éŸ³é¢‘çŠ¶æ€: {'æœ‰éŸ³é¢‘' if final_video.audio else 'æ— éŸ³é¢‘'}")
            print(f"final_videoç±»å‹: {type(final_video)}")
            print(f"final_videoå±æ€§: {dir(final_video)}")
            
            if final_video.audio:
                print(f"éŸ³é¢‘ç±»å‹: {type(final_video.audio)}")
                print(f"éŸ³é¢‘æ—¶é•¿: {final_video.audio.duration:.1f}ç§’")
                try:
                    audio_fps = final_video.audio.fps
                    print(f"éŸ³é¢‘é‡‡æ ·ç‡: {audio_fps} Hz")
                except AttributeError:
                    if hasattr(final_video.audio, 'clips') and final_video.audio.clips:
                        first_clip = final_video.audio.clips[0]
                        if hasattr(first_clip, 'fps'):
                            print(f"é¦–ä¸ªéŸ³é¢‘ç‰‡æ®µé‡‡æ ·ç‡: {first_clip.fps} Hz")
        except Exception as e:
            print(f"é”™è¯¯: è·å–è§†é¢‘ä¿¡æ¯å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return None

        try:
            print(f"å¼€å§‹æ¸²æŸ“åˆ°: {output_path}")
            os.makedirs(os.path.dirname(output_path), exist_ok=True)
            
            final_video.write_videofile(
                output_path,
                fps=24,
                codec='libx264',
                audio_codec='aac',
                temp_audiofile='temp-audio.m4a',
                remove_temp=True,
                logger=None,
                verbose=False,
                threads=2,
                bitrate="5000k",
                audio_bitrate="192k", 
                audio_fps=44100,       
                write_logfile=False
            )

            print(f"è§†é¢‘æ¸²æŸ“å®Œæˆ: {output_path}")
            if os.path.exists(output_path) and os.path.getsize(output_path) > 1024:  
                file_size_mb = os.path.getsize(output_path) / (1024 * 1024)
                print(f"æ–‡ä»¶å¤§å°: {file_size_mb:.1f} MB")           

                try:
                    test_clip = mp.VideoFileClip(output_path)
                    actual_duration = test_clip.duration
                    test_clip.close()
                    print(f"å®é™…æ—¶é•¿: {actual_duration:.1f}ç§’ (é¢„æœŸ: {final_video.duration:.1f}ç§’)")

                    if abs(actual_duration - final_video.duration) < 1.0:
                        print("è§†é¢‘æ–‡ä»¶éªŒè¯é€šè¿‡")
                        return output_path
                    else:
                        print(f"è§†é¢‘æ—¶é•¿ä¸åŒ¹é…ï¼Œä½†æ–‡ä»¶å·²ç”Ÿæˆ")
                        return output_path
                except Exception as e:
                    print(f"è§†é¢‘æ–‡ä»¶éªŒè¯å¤±è´¥: {e}")
                    return output_path
            else:
                print("è§†é¢‘æ–‡ä»¶ç”Ÿæˆå¤±è´¥æˆ–æ–‡ä»¶è¿‡å°")
                return None

        except Exception as e:
            print(f"è§†é¢‘æ¸²æŸ“å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            
            try:
                print("å°è¯•ç”Ÿæˆæ— éŸ³é¢‘è§†é¢‘...")
                final_video = final_video.set_audio(None)
                final_video.write_videofile(
                    output_path,
                    fps=24,
                    codec='libx264',
                    audio_codec=None,
                    temp_audiofile='temp-audio.m4a',
                    remove_temp=True,
                    logger=None,
                    verbose=False,
                    threads=2,
                    bitrate="5000k",
                    write_logfile=False
                )
                print(f"æ— éŸ³é¢‘è§†é¢‘æ¸²æŸ“å®Œæˆ: {output_path}")
                return output_path
            except Exception as e2:
                print(f"æ— éŸ³é¢‘è§†é¢‘æ¸²æŸ“ä¹Ÿå¤±è´¥: {e2}")
                traceback.print_exc()
                return None

    except Exception as e:
        print(f"è§†é¢‘åˆæˆå¤±è´¥: {e}")
        return None


def keep_only_black_for_folder(input_dir, output_dir, threshold=80):
    """å»æ’ç”»èƒŒæ™¯"""
    os.makedirs(output_dir, exist_ok=True)
    for fname in os.listdir(input_dir):
        if fname.lower().endswith(('.jpg', '.jpeg', '.png')):
            input_path = os.path.join(input_dir, fname)
            base_name, _ = os.path.splitext(fname)
            output_png = os.path.join(output_dir, base_name + '.png')
            try:
                img = Image.open(input_path).convert('RGBA')
                arr = np.array(img)
                
                print(f"å¤„ç†å›¾ç‰‡: {fname}")
                print(f"  åŸå§‹å°ºå¯¸: {img.size}")
                print(f"  åŸå§‹æ¨¡å¼: {img.mode}")
                print(f"  é¢œè‰²èŒƒå›´: R[{arr[..., 0].min()}-{arr[..., 0].max()}], G[{arr[..., 1].min()}-{arr[..., 1].max()}], B[{arr[..., 2].min()}-{arr[..., 2].max()}]")
                
                gray = 0.299 * arr[..., 0] + 0.587 * arr[..., 1] + 0.114 * arr[..., 2]
                mask = gray < threshold
                
                transparent_pixels = np.sum(mask)
                total_pixels = mask.size
                transparency_ratio = transparent_pixels / total_pixels
                print(f"æ£€æµ‹åˆ°é»‘è‰²åƒç´ : {transparent_pixels}/{total_pixels} ({transparency_ratio:.1%})")
                
                arr[..., 3] = np.where(mask, 255, 0)
                
                img2 = Image.fromarray(arr, 'RGBA')
                img2.save(output_png, 'PNG')
                
                if os.path.exists(output_png):
                    output_size = os.path.getsize(output_png)
                    print(f"è¾“å‡ºæ–‡ä»¶: {output_png} ({output_size} bytes)")
                    
                    try:
                        output_img = Image.open(output_png)
                        output_arr = np.array(output_img)
                        if output_img.mode == 'RGBA':
                            alpha_channel = output_arr[..., 3]
                            unique_alpha = np.unique(alpha_channel)
                            print(f"é€æ˜é€šé“å€¼: {unique_alpha}")
                        else:
                            print(f"è­¦å‘Š: è¾“å‡ºå›¾ç‰‡ä¸æ˜¯RGBAæ¨¡å¼: {output_img.mode}")
                    except Exception as verify_e:
                        print(f"éªŒè¯è¾“å‡ºæ–‡ä»¶å¤±è´¥: {verify_e}")
                
                print(f"å¤„ç†å®Œæˆ: {fname} -> ä¿ç•™é»‘è‰²éƒ¨åˆ†ï¼ŒèƒŒæ™¯é€æ˜")
                
            except Exception as e:
                print(f"å¤„ç†å›¾ç‰‡å¤±è´¥: {input_path}, é”™è¯¯: {e}")
                try:
                    backup_img = Image.new('RGBA', (512, 512), (0, 0, 0, 0))
                    backup_img.save(output_png, 'PNG')
                    print(f"åˆ›å»ºå¤‡ç”¨é€æ˜å›¾ç‰‡: {output_png}")
                except:
                    pass


def generate_illustration_prompts(segments):
    prompts = []
    system_prompt = (
        "You is a scene description expert for AI knowledge science stickman videos. Based on the given knowledge point or storyboard, generate a detailed English description for a minimalist black-and-white stickman illustration with an AI/technology theme. Requirements: "
        "- The illustration must depict only ONE scene, not multiple scenes, not comic panels, not split images. Absolutely do NOT use any comic panels, split frames, multiple windows, or any kind of visual separation. Each image is a single, unified scene. "
        "- All elements (stickmen, objects, icons, patterns, tech elements, decorations) must appear together in the same space, on the same pure white background, with no borders, no frames, and no visual separation. "
        "- All icons, patterns, and objects are decorative elements floating around or near the stickman, not separate scenes or frames. For example, do NOT draw any boxes, lines, or frames that separate parts of the image. All elements must be together in one open space. "
        "- The background must be pure white. Do not describe any darkness, shadow, dim, black, gray, or colored background. Only describe a pure white background. "
        "- All elements (stickmen, objects, tech elements, decorations) must be either solid black fill or outlined in black, to facilitate cutout. No color, no gray, no gradients, no shadows. "
        "- The number of stickman characters should be chosen based on the meaning of the sentence: if the scene is suitable for a single person, use only one stickman; if it is suitable for interaction, use two or three stickmen. Do not force two or more people in every scene. "
        "- All stickman characters must be shown as FULL BODY, with solid black fill for both body and face. "
        "- Each stickman has a solid black face, with white eyes and a white mouth, both drawn as white lines. Eyes and mouth should be irregular shapes to express different emotions, not just simple circles or lines. Use these white lines to show rich, varied, and vivid emotions. "
        "- Do NOT include any speech bubbles, text bubbles, comic panels, split images, or multiple scenes. "
        "- All characters and elements must be fully visible, not cut off or overlapped. "
        "- Only add clear, readable English text in the image if it is truly needed to express the knowledge point or scene meaning, such as 'AI', 'Token', 'LLM', or any other relevant English word. Do NOT force the use of any specific word in every scene. If no text is needed, do not include any text. "
        "- All text in the image must be clear, readable, and not distorted, garbled, or random. "
        "- Scene can include rich, relevant, and layered minimalist tech/AI/futuristic elements (e.g., computer, chip, data stream, AI icon, screen, etc.), and simple decorative elements to enhance atmosphere, but do not let elements overlap or crowd together. "
        "- All elements should be relevant to the main theme and the meaning of the current subtitle segment. "
        "- Output 80-120 words in English, only the scene description, no style keywords, and only use English text in the image if it is truly needed for the scene. "
    )
    for seg in segments:
        prompt = f"Please generate a detailed English scene description for an AI knowledge science stickman illustration based on: {seg}\nRemember: The illustration must depict only ONE scene, not multiple scenes, not comic panels, not split images. Absolutely do NOT use any comic panels, split frames, multiple windows, or any kind of visual separation. All elements must be solid black or outlined in black, and all faces must use irregular white lines for eyes and mouth to express emotion. All elements should be relevant to the main theme and the meaning of the current subtitle segment. All icons, patterns, and objects are decorative elements floating around or near the stickman, not separate scenes or frames. For example, do NOT draw any boxes, lines, or frames that separate parts of the image. All elements must be together in one open space."
        desc = modai_model_request(prompt, model="Qwen/Qwen3-Coder-480B-A35B-Instruct", max_tokens=256, temperature=0.5, system_prompt=system_prompt)
        prompts.append(desc.strip())
    return prompts

def generate_images(prompts, model_id= 'AIUSERS/jianbihua', negative_prompt = None, output_dir = None):
    import os
    import requests, time, json
    from PIL import Image
    from io import BytesIO
    if output_dir:
        save_dir = os.path.join(output_dir, 'images')
    else:
        save_dir = os.path.join(os.path.dirname(__file__), 'images')
    if not os.path.exists(save_dir):
        os.makedirs(save_dir)
    base_url = 'https://api-inference.modelscope.cn/'
    import os
    api_key = os.environ.get('MODELSCOPE_API_KEY')
    if not api_key:
        raise ValueError("è¯·è®¾ç½®ç¯å¢ƒå˜é‡ MODELSCOPE_API_KEY")
    headers = {
        "Authorization": f"Bearer {api_key}",
        "Content-Type": "application/json",
    }
    def create_placeholder(path):
        img = Image.new('RGB', (512, 512), (255, 255, 255))
        img.save(path)
    results = []
    for idx, desc in enumerate(prompts):
        prompt = desc
        img_path = os.path.join(save_dir, f'illustration_{idx+1}.jpg')
        try:
            resp = requests.post(
                f"{base_url}v1/images/generations",
                headers={**headers, "X-ModelScope-Async-Mode": "true"},
                data=json.dumps({
                    "model": model_id,
                    "prompt": prompt,
                    "negative_prompt": negative_prompt or ""
                }, ensure_ascii=False).encode('utf-8')
            )
            resp.raise_for_status()
            task_id = resp.json()["task_id"]
            for _ in range(30): 
                result = requests.get(
                    f"{base_url}v1/tasks/{task_id}",
                    headers={**headers, "X-ModelScope-Task-Type": "image_generation"},
                )
                result.raise_for_status()
                data = result.json()
                if data["task_status"] == "SUCCEED":
                    img_url = data["output_images"][0]
                    image = Image.open(BytesIO(requests.get(img_url).content))
                    image.save(img_path)
                    results.append(img_path)
                    break
                elif data["task_status"] == "FAILED":
                    print(f"æ’ç”»ç”Ÿæˆå¤±è´¥: {desc}")
                    create_placeholder(img_path)
                    results.append(img_path)
                    break
                time.sleep(5)
            else:
                print(f"æ’ç”»ç”Ÿæˆè¶…æ—¶: {desc}")
                create_placeholder(img_path)
                results.append(img_path)
        except Exception as e:
            print(f"æ’ç”»ç”Ÿæˆå¼‚å¸¸: {e}")
            create_placeholder(img_path)
            results.append(img_path)
    return results

# å¯åŠ¨
if __name__ == "__main__":
    import sys
    if len(sys.argv) > 1:
        topic = sys.argv[1]
        if len(sys.argv) > 2:
            output_dir = sys.argv[2]
        else:
            output_dir = "output"
        if len(sys.argv) > 3:
            animation_mode = sys.argv[3]  # "auto", "human"
        else:
            animation_mode = "auto"
    else:
        topic = "MCP"
        output_dir = "output"
        animation_mode = "auto"
    
    print(f"\n AIçŸ¥è¯†ç§‘æ™®è§†é¢‘ç”Ÿæˆç³»ç»Ÿ")
    print(f"=" * 50)
    print(f"ä¸»é¢˜: {topic}")
    print(f"è¾“å‡ºç›®å½•: {output_dir}")
    print(f"åŠ¨ç”»æ¨¡å¼: {animation_mode}")
    
    if animation_mode == "human":
        print(f"\näººå·¥æ§åˆ¶æ¨¡å¼è¯´æ˜:")
        print(f"- ç³»ç»Ÿå°†ç”Ÿæˆå ä½ç¬¦ä»£æ›¿åŠ¨ç”»")
        print(f"- å®ŒæˆåŸºç¡€è§†é¢‘åä¼šå¯åŠ¨äººå·¥åŠ¨ç”»å·¥ä½œå®¤")
        print(f"- ä½ å¯ä»¥ä¸AIå¯¹è¯åˆ¶ä½œæ¯ä¸ªåŠ¨ç”»")
        print(f"- æ”¯æŒé¢„è§ˆã€ä¿®æ”¹ã€æ‰¹å‡†æµç¨‹")
    else:
        print(f"\nè‡ªåŠ¨æ¨¡å¼: å…¨è‡ªåŠ¨ç”Ÿæˆæ‰€æœ‰å†…å®¹")
    
    print(f"=" * 50)
    
    try:
        output_path = generate_ai_science_knowledge_video(topic, output_dir, animation_mode)
        if output_path:
            print(f"\n å…¨éƒ¨å®Œæˆï¼")
            print(f"è¾“å‡ºç›®å½•ï¼š{output_path}")
            
            # æ ¹æ®æ¨¡å¼æ˜¾ç¤ºä¸åŒçš„ç»“æœæ–‡ä»¶
            if animation_mode == "human":
                preview_file = os.path.join(output_path, 'preview_with_placeholders.mp4')
                if os.path.exists(preview_file):
                    print(f"å ä½ç¬¦é¢„è§ˆï¼š{preview_file}")
                final_file = os.path.join(output_path, 'final.mp4')
                if os.path.exists(final_file):
                    print(f"æœ€ç»ˆè§†é¢‘ï¼š{final_file}")
                print(f"\nå¦‚éœ€åˆ¶ä½œåŠ¨ç”»ï¼Œè¯·è¿è¡Œ:")
                print(f"python human_animation_studio.py \"{output_path}\"")
            else:
                print(f"è§†é¢‘æ–‡ä»¶ï¼š{os.path.join(output_path, 'final.mp4')}")
                if os.path.exists(os.path.join(output_path, 'final_with_music.mp4')):
                    print(f"å¸¦èƒŒæ™¯éŸ³ä¹ï¼š{os.path.join(output_path, 'final_with_music.mp4')}")
        else:
            print(f"\n è§†é¢‘ç”Ÿæˆå¤±è´¥")
    except KeyboardInterrupt:
        print(f"\nç”¨æˆ·ä¸­æ–­ç¨‹åº")
    except Exception as e:
        print(f"\n ç¨‹åºè¿è¡Œå‡ºé”™: {e}")
        import traceback
        traceback.print_exc()
